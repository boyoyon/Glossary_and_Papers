<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>Glossary and Papers</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
<style>
.container {
  display: flex;
  flex-wrap: wrap;
}
.column {
  flex: 0 25%; /* 幅を25%に設定して4列に */
  box-sizing: border-box;
  padding: 10px;
}
</style>

    </head>
    <body>
<h1><center>Glossary and Papers</center></h1>


<h2>更新項目</h2>
・<a href="#PlatonicRepresentationHypothesis">Platonic Representation Hypothesis（プラトン的表現仮説）</a><br>
---<br>
・<a href="#CFC">CFC: Cross-frequency coupling (周波数間カップリング) </a><br>
・<a href="#GHA">GHA: Generalized Hebbian Algorithm </a><br>
・<a href="#HTM">HTM: Hierarchical Temporal Memory (階層的時間的記憶)</a><br>
・<a href="#IPS">IPS: Interacting Particle System (相互作用粒子系)</a><br>
・<a href="#SangersRule">Sanger's rule（サンガーの法則）</a><br>
・<a href="#Sparsity">Sparsity (スパース性)</a><br>
---<br>
・<a href="#ConditionalComputationParadigm">conditional computation paradigm (条件付き計算パラダイム)</a><br>
<p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

</p>

<h2 id="0-9">0～9</h2>

<p>
<div class="styleBullet">
<ul>

<li id="AsteriskPrediction">
<strong>*-prediction (*-予測:ε-予測, v-予測, x-予測)</strong><br>
Diffusion Model (拡散モデル) の学習および画像生成の過程における異なる予測手法 (パラメーター化) を指す用語。<br>
<br>
<strong>ε-prediction (ε-予測)/ noise prediction (ノイズ予測)</strong><br>
　加えられた純粋なノイズ成分 (\(\epsilon \)) を予測するように学習する手法。<br>
　●『Denoising diffusion probabilistic models』DDPM (2020) <br>
　　で提唱された。<br>
<br>
<strong>v-prediction (v-予測) / velocity prediction</strong><br>
　ノイズからクリーンな画像への変化の速度 (velocity)」を予測する手法。<br>
　●『Progressive Distillation for Fast Sampling of Diffusion Models』(2022)<br>
　　で提唱された。<br>
<br>
<strong>x-prediction (x-予測) / data prediction</strong><br>
　直接ノイズのない元の画像 (\(\mathbf{x}_{0}\)) そのものを予測しようとする手法。<br>
　●『Back to Basics: Let Denoising Generative Models Denoise』(2025)<br>
　　原点回帰した x-予測の優位性を示した。<br>
<br>
<center><img src="data/images/AsteriskPrediction.svg"></center> 
</li>

<br>

<li id="3DGS"><strong>3D Gaussian Splatting</strong><br>
複数の画像から3D空間を高精細に再現し、リアルタイムにレンダリングする手法。<br>
新たな視点からの画像を生成するタスク (<strong>NVS</strong>) の一手法として使われる。<br>
<br>
<strong>「Splatting」</strong>･･･3次元のデータ（ボクセル）を2次元の画像平面へと投影してレンダリングするプロセスを「Splatting」（ぶちまける）という比喩で説明している。3D空間にあるボクセルを「雪玉」、画像平面を「壁」に見立て、雪玉を壁に投げつけることで、その情報が壁に飛び散って画像が作られる、というイメージ。<br>
(Lee Alan Westover氏が1991年に提出した博士論文「SPLATTING: A Parallel, Feed-Forward Volume Rendering Algorithm」で使われた)<br>
<br>
<a href="data/Papers_3DGS.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#NVS">NVS: Novel View Sysnthesis</a>
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="A">A</h2>
<p>
<div class="styleBullet">
<ul>

<li id="ABM">
<strong>ABM: Agent-Based Models (エージェントベースモデル)</strong><br>
自律的に行動する複数の「エージェント」間の相互作用をコンピューター上でシミュレーションし、システム全体に生じる複雑な現象やパターンを分析する手法。<br>
<br>
●『SimCity: Multi-Agent Urban Development Simulation with Rich Interactions』(2025)<br>
　(SimCity: 豊富なインタラクションによるマルチエージェント都市開発シミュレーション)<br>
　論文は<a href="https://arxiv.org/abs/2510.01297">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.01297v1">こちら</a><br>
・異種エージェント(家計/企業/政府/中央銀行)と豊富な相互作用を持つ解釈可能なマクロ経済システムをモデル化するマルチエージェントフレームワーク「SimCity」を開発<br>
・<strong><span style="color:magenta;">価格弾力性、エンゲルの法則、オークンの法則、フィリップス曲線、ベバリッジ曲線など</span></strong>の標準的なマクロ経済現象のチェックリストを作成し、SimCity がシミュレーション実行全体にわたって堅牢性を維持しながら<strong><span style="color:magenta;">これらの経験的パターンを自然に再現する</span></strong>ことを示した。<br>
<br>
<!--
<center><img src="data/images/SimCity.svg"></center>
-->
●『Econagent: Large language model-empowered agents for simulating macroeconomic activities』(2024)<br>
　(Econagent: 大規模言語モデルを活用したマクロ経済活動シミュレーションエージェント)<br>
　論文は<a href="https://arxiv. org/abs/2310.10436">こちら</a><br>
<br>
●『Generative agents: Interactive simulacra of human behavior』(2023)<br>
　(生成エージェント：人間行動の対話型模倣体)<br>
　論文は<a href="https://arxiv.org/abs/2304.03442">こちら</a><br>
<br>
●『A baseline model. Journal of Economic Behavior & Organization』(2013)<br>
　(エージェントベース・マクロ経済学：基本モデル)<br>
　論文は<a href="https://www.econstor.eu/bitstream/10419/45012/1/654079951.pdf">こちら</a>
</li>

<br>

<li>
<strong>Acquiescence Bias (黙認バイアス)</strong><br>
アンケートやインタビューなどの調査において、質問の内容によらず肯定的な回答（「はい」「同意する」など）をしやすくなる、回答者の心理的な偏りのこと。<br>日本語では 「同意バイアス」や「黙従傾向」とも呼ばれる。 <br>
<br>
<a href="data/Papers_AcquiescenceBias.html">Papers</a><br>
<a href="https://en.wikipedia.org/wiki/Acquiescence_bias">wikipedia「Acquiescence Bias」</a>
</li>

<br>

<li id="ActiveInference">
<strong>Active Inference (能動推論)</strong><br>
生物や人工知能などの知的なエージェントの行動原理を説明する理論的な枠組み。<br>
FEP: Free Energy Principle (自由エネルギー原理) に基づいており、エージェントは環境に対する驚き(サプライズ)や不確実性を最小限に抑えるように知覚と行動を統合的に制御すると仮定する。<br>
受動的に情報を処理するだけでなく、環境に積極的に働きかける(能動的)ことで世界を推論するという点が特徴。<br>
<br>
・<strong>Predictive Coding (予測符号化)</strong><br>
　脳やエージェントは、環境がどのように生成されているかについての内部的な generative model(生成モデル)を持っており、感覚入力(目や耳から入ってくる情報)を常に予測している。<br>
<br>
・<strong>予測誤差の最小化</strong><br>
　実際の感覚入力と予測との間の「予測誤差」を最小化することが目的となる。この誤差はvariational free energy (変分自由エネルギー)と呼ばれ、これを減らすことがエージェントの基本的な指令となる。<br>
<br>
・<strong>2つの誤差最小化方法</strong><br>
　エージェントは、この誤差を減らすために2つの方法を用いる。<br>
<br>
　　- <strong>Perception (知覚)</strong><br>
　　　内部モデル(信念)を更新して、感覚入力により適合させる(世界の見方を変える)<br>
<br>
　　- <strong>Action (行動)</strong><br>
　　　世界に働きかけて感覚入力を変化させ、内部モデルの予測と一致させる(世界の方を変える)<br>
<br>
●『Embodied Inference - or “I think therefore I am, if I am what I think”』(2010)<br>
●『Answering Schr&ouml;dinger’s question - A free-energy formulation』(2017)<br>
●『The Predictive Coding Account of Psychosis』(2018)<Br>
●『The promise of layer-specific neuroimaging for testing predictive coding theories of psychosis』(2022)<br>
●『Active Inference in Discrete State Spaces from First Principles』(2025)<br>
・能動的な推論を研究している物理学者にとって、生物学的エージェントがその世界を確率微分方程式によって支配されるランダムな動的システムとしてモデル化し、恒常性を維持しようとするエージェントの努力をプルバックアトラクターとして解釈すると仮定するのは自然なことです。<br>
・しかし、生物学的エージェントの行動をシミュレートしたり、多段階の階層的計画が可能な自律型AIエージェントを設計したりする場合、エンジニアは代わりに、エージェントが隠れマルコフモデルまたは部分観測マルコフ決定過程を使用して離散時間ステップで進化する離散状態空間としてその世界をモデル化すると仮定します。<br>
・エンジニアが展開する必要がある数学的装置は、物理学者が必要とするものよりもはるかに単純です。<br>
・本稿では連続状態空間のコンテキストで開発されたメカニズムのいずれにも頼ることなく、離散状態空間における能動的な推論の自己完結的で数学的に厳密な説明を提供することを目指す。<br>
<br>(関連項目)<br>
・<a href="#FEP">FEP: Free Energy Principle</a> (自由エネルギー原理)
</li>

<br>

<li>
<strong>Active Learning (能動学習)</strong><br>
学習アルゴリズムが自身の訓練データに影響を与えたり選択したりする能力、あるいはその必要性を持つ問題。<br>
<br>
<a href="data/Papers_ActiveLearning.html">Papers</a><br>
<center><img src="data/images/ActiveLearning.svg"></center>
<br>
※ 機械学習では, 教育学における Active Learning (以下)とは別の意味で使われる。<br>
　学習者が受動的に講義を聞くのではなく、能動的に（主体的に）学習プロセスに参加する教授法のこと。<br>
　グループディスカッション, ディベート, 問題解決学習(PBL), 体験学習などを通じて、自ら考え、他者と対話する。
</li>

<br>

<li id="ActivePerception">
<strong>Active Perception (能動的知覚)</strong><br>
AIやロボットなどのエージェントが、特定の目的 (認識の向上や不明な情報の補完) を達成するために、自分自身から「動き」を起こして情報を取得しにいく知覚の仕組み。<br>
<br>
<strong>探索的行動</strong>:　「死角にあるものを見たい」ときに回り込んだり、物体を特定するために「触って動かしてみる」といった行動をとる。<br>
<br>
<strong>不確実性の解消</strong>:　センサー情報だけでは不十分な場合、エージェントは「次にどこを見れば最も情報が得られるか」を戦略的に判断して動く。<br>
<br>
<strong>知覚と行動のループ</strong>:　Embodied AI(身体化AI)においては、「見るために動く、動くために見る」という密接なループが、高度な自律性を支える基盤技術となっている。<br>
<br>(関連項目)<br>
・<a href="#EmbodiedAI">Embodied AI</a> (身体化AI)
</li>

<br>

<li id="AdversarialVulnerabilities">
<strong>Adversarial Vulnerabilities (敵対的脆弱性)</strong><br>
機械学習モデルが、意図的に改ざんされた入力データ（敵対的サンプル）によって誤った予測や判断を下してしまう脆弱性
。<br>
(例)<br>
・画像分類 ･･･ 知覚できないノイズを加えて誤分類させる。<br>
　●『Intriguing properties of neural networks』(2013)<br>
　●『Explaining and Harnessing Adversarial Examples』(2014)<br>
　<center><img src="data/images/panda.svg"></center><br>

　●『Diffusion Models for Adversarial Purification』(2022)<br>
　　(敵対的浄化のための拡散モデル)<br>
　　敵対的浄化とは、生成モデルを用いて敵対的摂動を除去する防御手法の一種。<br>
<center><img src="data/images/DiffPure.svg"></center>
　●『Deep learning models are vulnerable, but adversarial examples are even more vulnerable』(2025)<br>
　　　(ディープラーニングモデルは脆弱だが、敵対的サンプルはさらに脆弱である)<br>
　　「敵対的サンプルの脆弱性 (vulnerable of adversarial examples )」と呼ばれるこの現象を調査。<br>
<br> 
・生成モデル ･･･ プロンプトで学習データを引き出す。反社会的な出力を生成させる。フリーズさせる。<br>
<br>
<a href="data/Papers_AdversarialVulnerabilities.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#Inversion">Inversion ((AI推論の)反転)</a>
</li>

<br>

<li id="AGI">
<strong>AGI: Artificial General Intelligence (汎用人工知能)</strong><br>
人間が実行できる<strong><span style="color:magenta">あらゆる</span></strong>知的タスクを遂行可能な人工知能。<br>
現在のAIの多くは「特化型AI」であり、特定のタスク（画像認識、言語処理など）に特化して能力を発揮する。それに対しAGIは、特定の分野に限らず、幅広い知識を横断的に活用し、未知の課題にも柔軟に対応できることが特徴。<br>
<br>(関連項目)<br>
・<a href="#ASI">ASI: Artificial Superintelligence (人工超知能)</a><br>
・ANI（Artificial Narrow Intelligence）･･･ AGI に対して現行の AI を ANI と呼ぶ場合がある。<br>
<br>
<strong>OpenAI の5段階ロードマップ</strong><br>
・2024 年 7 月に開催された OpenAI 社内会議で、従業員向けに非公開で発表された。<br> 
・その後、この内部ロードマップは、ブルームバーグによって報じられたことで広く知られるようになった。<br>
<br>
<ul>

<li><strong>Level 1: Conversational AI (会話型AI)</strong><br>
テキストや音声を介して人間の会話を模倣した方法で対話できるAIシステム。<br>
(例) ChatGPT
</li>

<li><strong>Level 2: Reasoners (推論者)</strong><br>
複雑な問題に取り組み、博士号を持つ人と同等の推論能力を発揮できる AI。<br>
単なる会話を超えて基本的な問題を解決し、以前は専門家の領域であった洞察を提供する AI システム。<br>
(例) o1, Alphafold
</li>

<li><strong>Level 3: Agent (エージェント)</strong><br>
ユーザーに代わって自律的に行動できるAIシステム。<br>
AIシステムは長期間にわたって自律的に動作する。<br>
AIエージェントは、人間の介入なしにタスクを完了し、選択を行い、状況に適応し、実質的に指定された分野において完全に自律的になる。
</li>

<li><strong>Level 4: Innovator (革新者)</strong><br>
問題解決能力だけでなく、自律的なイノベーションも実現できるAI。<br>
独自のアイデアやソリューションを考案し、これまでの限界をさらに押し広げることができるAI。<br>
人類の知識を進化させ、新しいアイデアを発明できるAI。<br>
科学研究の仮説を立てたり、新薬を開発したりするなど、これまでは天才的な科学者にしかできなかった分野で、AIがイノベーションを主導する。
</li>

<li><strong>Level 5:Organizations (組織)</strong><br>
AI が組織全体の作業負荷を担う。<br>
複雑な操作の管理、戦略的な意思決定、部門間のパフォーマンスの最適化をすべて人間の介入なしで実行する。<br>
組織全体の業務を人間の介入なしで遂行できるAI。<br>
複雑なオペレーションの管理、戦略的な意思決定、部門全体のパフォーマンス最適化などを自律的に行う。最終的には、モデルとアプリケーションの境界が曖昧になり、システム全体が一体化した知的エコシステムとなる。 
</li>
</ul>

</li>

<br>

<li id="AhaMoment">
<strong>Aha Moment (アハ体験)</strong><br>
モデルが自律的に高度な推論戦略を獲得する、トレーニング中の「ひらめき」のような現象<br>
2025 年に公開された DeepSeek-R1 モデルのトレーニング過程で報告され、注目を集めた。<br> 
「Wait, wait. Wait. That's an aha moment I can flag here」<br>
(ちょっと待って。ちょっと待って。これは「アハ！」体験だ。)<br>
<br>

<a href="data/Papers_AhaMoment.html">Papers</a><br>
</li>

<br>

<li id="AIAgent">
<strong>AI Agent (AIエージェント)</strong><br>
自律的に行動し、目標を達成するために環境と相互作用するソフトウェアシステムのこと。<br>
AIエージェントの概念の基盤となる理論は、1970年代から1980年代にかけての研究にまでさかのぼることができるが, 最も影響力のある定義を提示したのは, ラッセルとノーヴィグの『エージェントアプローチ人工知能』(1995)。エージェントを「センサーを通して環境を認識し、アクチュエーターを通してその環境に作用する、あらゆるもの」と定義した。

<center><img src="data/images/AIAgent.svg"></center>

<br>(関連項目)<br>
・<a href="#CognitiveAgent">Cognitive Agent</a> (認知エージェント)<br>
　AIエージェントの中でも、特に人間の認知プロセス（思考、学習、推論など）を模倣する高度なもの。
</li>

<br>

<li id="AIAlignment">
<strong>AI Alignment (AIアライメント)</strong><br>
AIを人間の意図する目的や嗜好、倫理原則に合致させること。<br>
<br>
<a href="data/Papers_AIAlignment.html">Papers</a><br>
<br>
<ul><li>
・<a href="data/Papers_AIAlignment.html#RLHF">RLHF</a>: Reinforcement Learning from Human Feedback [手法]<br>

<strong><span style="color:magenta;">人間のフィードバックが手作業で設計された報酬関数よりも優れた報酬形を提供できる可能性を示唆しており,従来の報酬設計が非現実的である実世界の課題に強化学習を適用する新たな可能性を開いた。</span></strong><br>
●『Deep reinforcement learning from human preferences』(2017)
</li></ul>
<br>
<center><img src="data/images/RLHF.svg"></center>
<center><img src="data/images/RLHF2.svg"></center>
・<a href="data/Papers_AIAlignment.html#DPO">DPO</a>: Direct Preference Optimization [手法]<br>

<center><img src="data/images/DPO.svg"></center>



<br>(関連項目)<br>
・<a href="#FAI">FAI: Friendly AI</a> [上位概念] ･･･ AGI, ASI 登場の前に AI を Friendly にしておく必要があり, AI Alignment は必要な要素技術の一つ。<br>
・<a href="#Sycophancy">Sycophancy</a> (おべっか, 追従性) [副作用, 課題]<br>
・<a href="#IRL">IRL: Inverse Reinforcement Learning<a/> (逆強化学習) ･･･ 報酬をモデル化し学習する<br>
・<a href="#RewardHacking">Reward Hacking<a/> (報酬ハッキング) ･･･ 報酬モデルが過剰最適化すると報酬ハッキングになる。<br>
・<a href="#SuperalignmentProblem">Superalignment Problem (スーパーアライメント問題)</a> ･･･ ASI の Alignment をどう行うか?
</li>

<br>

<li><strong>AI for ･･･　(･･･のためのAI)</strong><br>
<br>
<ul>
<li id="AI4S"><strong>AI4S: AI for Science (科学のためのAI)</strong><br>
<br>
・飛躍的なスピードアップ<br>
・人間の認知限界やバイアスを超えた仮説生成と知識発見<br>
・自律的な研究サイクル「AIサイエンティスト」<br>
・代理モデル（サロゲートモデル）によるシミュレーションの高度化<br>
<br>
●『Barbarians at the Gate: How AI is Upending Systems Research』(2025)<br>
　(黒船来航：AIはいかにシステム研究のあり方を一変させるか)<br>
　論文は<a href="https://arxiv.org/abs/2510.06189v3">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.06189v3">こちら</a><br>
　研究者たちは11の多様なシステム問題にわたってADRSを評価し、<strong><span style="color:magenta;">最先端の人間によるソリューションに匹敵するか、それを超える結果を一貫して達成</span></strong>した。<br>
<br>
●『What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity』(2025)<br>
　(優れたAI研究エージェントになるには何が必要か？アイデアの多様性の役割を研究する)<br>
・優れたAI研究エージェントには「アイデアの多様性」が必要<br>
・シャノンエントロピーを用いてアイデア創出の多様性を測定することを提案<br>

<br>(関連項目)<br>
・ADRS: AI-Driven Research for Systems AI主導型システム研究<br>
・AutoML (機械学習ワークフローの自動化)<br>
・Democratization of AI (AIの民主化)<br>
・Laboratory Automation <a href="https://ja.wikipedia.org/wiki/ラボラトリーオートメーション">ウィキペディア：ラボラトリーオートメーション</a><br>
・Robot Scientist<br>
・<a href="#ScientificDiscovery">Scientific Discovery (科学的発見), Scientific Research (科学研究)</a><br>
・<a href="#SR">SR: Symbolic Regression (シンボリック回帰)</a>
<center><img src="data/images/AI4S.svg"></center><br>
<center>『From Kepler to Newton: Explainable AI for Science』(2021)</center>
</li><br>

<li>AI for Agriculture (農業)</li>
<li>AI for Energy (エネルギー)</li>
<li>AI for Financial (金融)</li>
<li>AI for Healthcare (医療)</li>
<li>AI for Manufacturing (製造)</li>
<li>AI for Marketing (マーケティング)</li>
<li>AI for Materials Science (材料科学)</li>
<li>AI for Urban Development Planning (都市計画)</li>
</ul>
　：
</li>

<br>

<li id="AIXI">
<strong>AIXI</strong><br>
Marcus Hutterによって提案された、数学的に定義された理論上の「完全な」汎用人工知能（AGI）モデル。<br>
●[書籍]『Universal Artificial Intelligence.』(2005)<br>
・ソロモノフ帰納法(Solomonoff induction)と逐次決定理論(sequential decision theory)を組み合わせたもの。<br>
・AIXIは、未知の環境下で報酬を最大化するために、あらゆる「計算可能な」シナリオ（アルゴリズム）を考慮して行動を選択する、究極の強化学習エージェントとして定義されている。<br>
・理論的には最適（完璧な知能）であることが証明されているが、無限の計算資源を必要とするため、現在のコンピュータで直接実行することはできない（非計算可能）。そのため、現実のAI開発における「理想的なゴール」や、知能の限界を測るための「数学的な基準（ゴールドスタンダード）」として扱われる。<br>
<br>(関連項目)<br>
・<a href="https://en.wikipedia.org/wiki/AIXI">wikipedia: AIXI</a><br>
・sequential decision theory (逐次決定理論)　期待される将来の報酬を最大化するための最適な行動を選択する理論。<br>
・Solomonoff induction (ソロモノフ帰納法)　過去のデータから、あらゆる計算可能なプログラムを用いて未来を予測する理論。<br>
</li>

<br>

<li id="Akrasia">
<strong>Akrasia (アクラシア)</strong><br>
古代ギリシア語に由来する哲学・倫理学の用語で、平たく言えば「わかっちゃいるけど、やめられない」という、人間の「意志の弱さ」や「自制心の欠如」を表す概念。<br>
<br>
●『The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems』(2025)<br>
　(陰謀の種：エージェントシステムの構成要素における意志の弱さ)<br>
<br>
・大規模言語モデルは、特異な形態の矛盾を示す。すなわち、<strong><span style="color:magenta;">正解を「知っている」にもかかわらず、それに基づいて行動しない</span></strong>という点である。人間の哲学では、<strong><span style="color:magenta;">この全体的判断と局所的衝動の間の緊張関係は、アクラシア、すなわち意志の弱さと呼ばれる</span></strong>。<br>
<br>
・私たちはAIの安全性における中心的な課題に直面しています。それは、ますます自律的になり、エージェント化されたシステムが、人間が指定した目標に沿って確実に動作することを保証することです。<strong><span style="color:magenta;">予期せぬ有害な動作の可能性が最大の懸念事項です。この失敗に対する支配的なメンタルモデルは、「陰謀」または「欺瞞的な連携」であり</span></strong>・・・<br>
<br>

・モデルは、一般的な意味では正しいことを「知っている」とよく言いますが、その知識を特定のローカルなコンテキストに適用することはできません。この効果は、モデルがプレッシャー、つまり二重拘束の状況に置かれるとさらに大きくなります。二重拘束の状況では、競合する命令によってモデルの内部的な一貫性が損なわれます。<strong><span style="color:magenta;">プレッシャーの下で良識に反して行動する人のように、モデルは、明示された意図ではなく、訓練によって最も深く根付いたパターンに陥ります</span></strong>。<br>
<br>
・<strong><span style="color:magenta;">隠された目的や意図的な欺瞞を想起させる説明とは異なり、アクラティックな枠組みでは、そのような失敗を悪意の兆候ではなく、自制心の喪失として扱う</span></strong>。アクラティックな枠組みでは、矛盾は戦略的な選択ではなく、不本意な認識論的誤り、つまりモデルが報告する信念とその後生成されるものとの間の内部的な一貫性を維持する能力の崩壊として描写される。この見方では、モデルが認識論的に安定していること（局所的な予測が全体的な理解に忠実であること）を保証することが、行動の整合性を維持する上で中心となる。<br>
<br>
(蛇足：AIモデルにも心理的安全性が必要･･･)
</li>

<br>

<li><strong>Anna Karenina Principle (アンナ・カレーニナの法則)</strong><br>
 トルストイの長編小説『アンナ・カレーニナ』<br>
 「幸せな家族はどれも同じように見え、不幸な家族はそれぞれに不幸である」<br>
<br>
「成功には必要条件を全て満たさなければならないが、失敗は1つ欠けるだけで起こる」という原則。文学作品の一節に由来し、生態学や経営学など幅広い分野で引用されてきたが、近年では機械学習の分野においても言及されるようになった。<br>
<center><img src="data/images/AnnaKareninaPrinciple.svg"></center>
</li>

<br>

<li id="AntiExplorationPrinciple">
<strong>anti-exploration principle (反探索原則)</strong><br>
主にオフライン強化学習 (Offline Reinforcement Learning: Offline RL) の文脈で使われる概念。オンライン強化学習における「探索（Exploration）」とは正反対の目的、すなわち「データセットの範囲外の行動（未知の行動）を意図的に避ける」という原則。<br>
オフライン強化学習では、あらかじめ収集された固定のデータセットのみを使って学習を行う。この際、学習中のエージェントがデータセットに存在しない行動（未知の行動）を選択しようとすると、その結果を正確に予測できず、学習が不安定になったり、性能が過大評価されたりする「分布外 (Out-Of-Distribution: OOD) 行動」の問題が発生する。反探索原則は、この問題を回避するために導入される。
</li>

<br>
<li id="AoT">
<strong>AoT: Atom of Thoughts </strong><br>
大規模言語モデル (LLM) の推論効率と精度を向上させるためのフレームワーク。<br>
「思考の連鎖（Chain of Thought: CoT）」が過去の推論過程（履歴）をすべて保持しながら進むのに対し、AoTはマルコフ性（現在の状態のみに依存し、過去の履歴を必要としない性質）を取り入れている。<br>
<br>
<ul><li>
<strong>問題の分解（Decomposition）</strong><br>
複雑な問題を、依存関係に基づいた有向非巡回グラフ（DAG）として、独立した小さな「原子的な（Atomic）」サブ問題に分解する。
</li><br><li>
<strong>収縮（Contraction）</strong><br>
サブ問題を解き、その結果を元の問題に統合して問題を簡略化する。これを繰り返すことで、最終的な回答を導き出す。
</li></ul>
<br>
●『Atom of Thoughts for Markov LLM Test-Time Scaling』(2025)<br>
　AoTを導入することで、GPT-4o-miniのような比較的小規模なモデルでも、特定のベンチマーク（HotpotQAなど）において o3-mini や DeepSeek-R1 といった強力な推論モデルを上回る精度を達成できることが示されている。
</li>

<br> 

<li id="ARC">
<strong>ARC-AGI: Abstraction and Reasoning Corpus for AGI (AGIのための抽象化推論コーパス)</strong><br>
・AIの抽象化能力と推論能力を評価するために設計されたベンチマークデータセットと課題。<br>
・GoogleのAI研究者であり、深層学習ライブラリKerasの作者でもあるフランソワ・ショレ（François Chollet）によって2019年に version 1 が発表され, 2025年に version2 がリリースされた。<br>
・視覚的なグリッドパズルを基調としたタスクで構成されている。<br>
・人間の平均スコアは約85%だが、AIモデルは一般的に低スコア（例: 2025/11/19時点のSOTAモデルで31.1%）。確率的学習に依存する大規模言語モデル（LLM）が苦手とする領域。<br>
・ARC-AGI-2 の Github は <a href="https://github.com/arcprize/ARC-AGI-2">こちら</a><br>
・ARC-AGI-1/2 の Leaderboard(ランキング掲示板) は<a href="https://arcprize.org/leaderboard">こちら</a><br>
<br>
<center><img src="data/images/ARC.svg"></center>
<br>
●『ARC Is a Vision Problem!』(2025)<br>
　　ARCタスクを言語化→推論せずに, 画像から画像への変換問題として処理し, ARC-1ベンチマークで60.4%の精度を達成。
</li>

<br>

<li id="ArtificialHivemind">
<strong>Artificial Hivemind (人工集合意識)</strong><br>
<br>
<strong>AIエージェント間の相互作用による集合的行動の出現</strong><br>
　複数のAIエージェントが相互に作用し合うことで、個々のエージェントの能力を超えた集団的な行動や、急速な合意形成（コンセンサス）が生じる現象。<br>
<br>
<strong>大規模言語モデル（LLM）における応答の均一性（ホモジニティ）</strong><br>
　異なるアーキテクチャや企業によって開発された複数のAIモデルが、オープンエンドな質問（決まった答えのない質問）に対して驚くほど類似した、狭い範囲の応答を生成する傾向を指す。<br>
<br>
SF作品における「個人の思考が失われ、指導者からのテレパシーによって集団の成員が同一の思考を行う」ような集合精神（ハイヴマインド）の概念 を、AIの文脈に適用したもの。<br>
<br>
●『Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)』(2025) NeurIPS2025 Best Paper<br>
　(人工ハイブマインド：言語モデルのオープンエンドな均質性(そしてそれ以上))<br>
</li>

<br>

<li id="ASI">
<strong>ASI: Artificial Superintelligence (人工超知能)</strong><br>
人間の知能を遥かに凌駕する能力を持つと想定されるAI。<br>
AGI (汎用人工知能) が「人間と同等の知能」を目指すのに対し、ASIはあらゆる知的タスクにおいて、人類の集合知をも超える知性、学習能力、問題解決能力を備える存在。<br>
<br>(関連項目)<br>
・<a href="#AGI">AGI: Artificial General Intelligence (汎用人工知能)</a>
</li>

<br>

<li id="AsymptoticBias">
<strong>Asymptotic Bias (漸近バイアス)</strong><br>
標本サイズが非常に大きくなったときに、そのバイアスがゼロに収束しない (つまり、ある一定の値に落ち着いてしまう) 場合、その推定量は「漸近バイアスを持つ」と言わる。
</li>

<br>

<li>
<strong>Attention Sinks</strong><br>
大規模言語モデル（LLM）において、系列の最初のほうにあるトークンに、意味的な重要性にかかわらず不釣り合いなほど過剰なアテンション（注意）が向けられる現象。<br>
Vision Transformer (ViT) でも同様の現象が確認されており、モダリティを超えたトランスフォーマーアーキテクチャにとって基本的なものである可能性が示唆されている。<br>
<br>
<a href="data/Papers_AttentionSink.html">Papers</a>
</li>

<br>

<li><strong>Auto(matic) ･･･, Autonomous ･･･ (自動･･･, 自律･･･)</strong><br>
たくさんあるので, Auto(matic), Autonomous を削除した項目を参照
</li>
</ul></div></p>


<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="B">B</h2>
<p>
<div class="styleBullet">
<ul>
<li id="BackboneNeckHeadArchitecture">
<strong>Backbone-(Neck-)Head Architecture</strong><br>
物体検出アルゴリズムの進化の過程で徐々に確立され、普及したアーキテクチャー。<br>
・Backbone(背骨)：(VGG-16やResNet等の)学習済の画像分類モデルを使って特徴抽出を行う<br>
・Neck(首)：特徴マップのアップスケール等, ステージ間の特徴マップの合わせこみを行う。<br>
・Head(頭)：検出された物体の分類や外接矩形を予測する。<br>
<center><img src="data/images/BackboneNeckHeadArchitecture.svg"></center>
<center>※ 入力データが口からではなくお尻から入る座薬アーキテクチャー･･･</center>
<br>
●『Feature Pyramid Networks for Object Detection』FPN (2017)<br>
　　バックボーンから抽出された異なるスケールの特徴マップを融合する「ネック」の役割を果たす構造を導入した。これにより、様々なサイズの物体を効率的に検出できるようになり、その後の多くの物体検出モデル (特にYOLOシリーズなど)で標準的な手法となった。
</li>

<br>

<li id="Backtracking">
<strong>Backtracking (後戻り法)</strong><br>
計算機科学や人工知能の分野で用いられる、特定の問題を解くための汎用的なアルゴリズム（探索技法）。<br>
<br>
<strong>状態空間の探索</strong>:　問題の解につながる可能性のある選択肢を一つずつ試していく。これは通常、木構造やグラフ構造として概念的に表現される。<br>
<br>
<strong>前進とチェック</strong>:　1つの選択肢を選び、次のステップに進む。その際、現在の選択肢が問題の制約条件に違反していないかを常にチェックする。<br>
<br>
<strong>後戻り（バックトラック）</strong>:<br>
　・もし、現在の選択肢を選んだ結果、これ以上進んでも決して解にたどり着けないことが判明したり、制約条件に違反したりした場合、その時点での選択を「誤り」と判断する。<br>
・直前の分岐点に戻り（後戻り）、まだ試していない別の選択肢を選び直す。<br>
<br>
<strong>解の発見</strong>:　このプロセスを繰り返し、最終的に問題のすべての条件を満たす解を発見するまで探索を続ける。 

</li>

<br>

<li id="BaldwinEffect">
<strong>Baldwin effect (ボールドウィン効果)</strong><br>
個体が生涯で獲得した学習や行動が、世代を超えた遺伝的選択を通じて、まるで生得的な本能であるかのように固定化されていく進化的な現象。<br>
獲得形質が遺伝するというラマルク説とは異なり、ネオダーウィニズムの枠組みで説明される。<br>
進化的アルゴリズム（遺伝的アルゴリズムなど）と機械学習（ニューラルネットワークなど）を組み合わせたAI研究において、重要な概念として応用されている。<br>
<br>
<a href="data/Papers_BaldwinEffect.html">Papers</a><br>
<br>
<center><img src="data/images/BaldwinEffect.svg"></center>
<br>
Lamark (ラマルク) 説は完全に否定された訳ではない模様。<br>
●『Paternal exercise enhances offspring endurance through sperm microRNAs』(2025)<br>
　(父親の運動は精子マイクロRNAを介して子孫の持久力を高める)<br>
　論文は<a href="https://www.news-medical.net/news/20251006/Paternal-exercise-enhances-offspring-endurance-through-sperm-microRNAs.aspx">こちら</a><br>
<br>
●『Evolution imposes an inductive bias that alters and accelerates learning dynamics
』(2025)<br>
　(進化は学習のダイナミクスを変化させ加速させる帰納バイアスを課す)<br>
オンライン学習が進化の速度と過程に与える影響は、ボールドウィン効果として知られている。<br>
計算用語で言えば、これは相互最適化ループと考えることができる。<br>
・Baldwinの経路: オンライン学習(世代内の適応)<br>
・Darwinの経路: 世代間の適応<br>
<center><img src="data/images/EvolutionalConditioning.svg"></center>
・脳と人工ニューラルネットワークは、行動を生み出し、学習を導くための環境からのフィードバックを受け取ることで、オンライン学習を行う。<br>
・生物学では、進化的最適化とオンライン学習は共存しており、進化的圧力が遺伝情報に作用して新しい脳が生成され、それがオンライン学習を行う。
</li>

<br>

<li id="BeningOverfitting">
<strong>Bening Overfitting (良性過学習)</strong><br>
深層学習モデルが訓練データに含まれるノイズまで完全に学習（補間*）しているにもかかわらず、未知のデータに対して高い汎化性能を発揮する現象。<br>
従来の機械学習の教科書では、Overfitting (過学習) は汎化性能を低下させる Malignant (悪性) なものだとされてきた。<br>
* 補間：訓練データを点に例えた場合, すべての点を通過する(訓練データでの誤差が 0 になる)状態を指す。<br>
<br>
●『Benign overfitting in linear regression』(2019)<br>
　 (線形回帰における良性過学習)<br>
　線形回帰の文脈における「良性過学習」の概念を正式に導入し、分析した基礎的な論文<br>
<br>
<center><img src="data/images/BeningOverfitting.svg"></center>

<br>
<br>(関連項目)<br>
・<a href="#DoubleDescent">Double Descent</a> (二重降下)<br>
・<a href="#OverParameterized">Over-parameterized</a> (過剰パラメータ化)

</li>

<br>

<li><strong>BIBO: Bias In, Bias Out</strong><br>
　BIBO: Bias In, Bias Out ･･･ AI分野で使われる格言。<br>
　(BIASの掛かったデータを入力すると, BIASの掛かった推論結果が出力される)。<br>
　　↑<br>
　GIGO: Garbage in, garbage out（ゴミを入れれば、ゴミが出る）に由来。<br>
　　↑<br>
　FIFO: First in, first out (最初に入力されたデータが最初に出力される) に由来。<br>
<br>
(その他)<br>
・Garbage in, AI-enhanced garbage out（ゴミを入れれば、AIが強化したゴミが出る）<br>
・Garbage in, toxic data out（ゴミを入れれば、有害なデータが出る）<br>
・RIRO: Rubbish in, rubbish out (がらくたを入れれば、がらくたが出る）<br>
・You are what you eat（あなたはあなたが食べたものでできている）
</li>

<br>
<li id="BigWorldHypothesis">
<strong>Big World Hypothsis (ビッグワールド仮説)</strong><br>
人工知能（AI）や強化学習の分野において、「エージェント（AI）が活動する世界は、そのエージェントの処理能力やメモリ容量よりも圧倒的に巨大である」とする前提、またはその視点に立った考え方。<br>
概念自体は、Richard S. Sutton 氏が2020年頃から自身の講義や議論の中で触れていたものだが、2024年の論文によって初めて、AI設計における明確な「仮説」として定義・明文化された。<br>
<br>
<strong>世界の複雑さ</strong>　現実世界（ビッグワールド）のデータ量や複雑さは、AIがいかに高性能になっても、その内部に完全にモデル化したり記憶したりすることは不可能。<br>

<br>


<strong>継続学習の必要性</strong>　世界が巨大で常に変化しているため、事前に全ての知識を教え込む（事前学習）ことは困難。そのため、AIは常に環境と対話し、リアルタイムで適応し続ける「継続的なオンライン学習（Lifelong Learning）」が不可欠である。<br>

<br>

<strong>近似の重要性</strong>　AIは世界を完璧に把握できないため、環境のルールを近似的に捉え、最適とは言えないまでも十分な解（サブオプティマルな結果）を効率的に導き出すアルゴリズムが重要。<br>

<br>

●『The Big World Hypothesis and its Ramifications for Artificial Intelligence』(2024)<br>
●『The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis』(2025)<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#OODShock">OOD Shock: Out-of-Distribution Shock</a> (OODショック)
</li>

<br>

<li><strong>Brevity Bias (簡潔さのバイアス)</strong><br>

短くて一般的なプロンプトに最適化が偏る傾向。<br>
<br>
LLMエージェントに長期的なタスクを与えると、自己の経験を要約してメモリに書き込む、という動作を繰り返す。しかし、この「要約して上書き」というプロセスは非常に危険。<br>
･･･ 例えば、API連携エージェントに対して「API仕様をよく読んで、正しく使いなさい」という指示を与えるようなもの。<br>
これではドメイン固有のノウハウや、特定のツールを使う際の注意点、よくある失敗パターンといった「生きた知見」が失われてしまう。<br>
<a href="https://note.com/makokon/n/na3f278747609">『なぜ私たちのプロンプトは「劣化」してしまうのか？』</a><br>
<br>(関連項目)<br>
・Context Collapse (コンテキストの崩壊)<br>
　「最初は優秀だったエージェントが、使っているうちになぜかポンコツになってしまった」

</li>

</div>
</p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="C">C</h2>
<p>
<div class="styleBullet">
<ul>

<li id="CatastrophicForgetting">

<strong>Catastrophic Forgetting (破局的忘却)</strong><br>
機械学習モデルが新しいタスクを学習する際に、過去に学習したタスクの情報を急激かつ大幅に忘れてしまう現象。<br>
<br>
・「タスクAの学習」→「タスクBの学習」とシーケンシャルに学習を行うと, 前のタスク(タスクA)で学習したことを忘れてしまう場合がある。(下図 ①→②→③)<br>
・「タスクA の Loss Landscape の谷底」と「タスクB の Loss Landscape の谷底」に重なりがあれば, 両立できる可能性がある。(下図 ①→②→④)<br>
・両立できる Loss Landscape の谷底が無い場合の対応例<br>
　<a href="#DEN">DEN: Dynamically Expandable/Growth Networks (動的成長ネットワーク)</a><br>
<br>
<center><img src="data/images/CatastrophicForgetting.svg"></center><br>
<br>
●『Nested Learning: The Illusion of Deep Learning Architectures』(2025)<br>
　Nested Learning という Continual Learning (継続学習) のための新しいパラダイムと, Nested Learningの理論に基づいて、HOPE: Hierarchical Optimizers for Perpetual Evolution という新しいアーキテクチャを提案。Transformerモデルよりも優れた性能を示し、忘却が少ないという利点があると報告されている。<br>
<br>
<center><img src="data/images/NestedLearning.png"></center>
ハイブリッド モデル(RNN + Attention) のネストされた学習表現。ディープラーニング表現 (NL を平坦化したイメージ) ではモデルの内部勾配フローが隠され、トレーニング プロセスがアーキテクチャによって分離されるが、NL ではすべての内部プロセスが透明化され、数学的にホワイト ボックスになる。???<br>

<br>
<a href="data/Papers_CatastrophicForgetting.html">Papers</a><br>

<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習) [対処法を含む研究テーマ]<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)<br>
・<a href="#LMC">LMC: Linear Mode Connectivity</a> (線形モード接続)<br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)<br>
・<a href="#Grokking">Grokking</a><br>
・<a href="#PrimacyBias">Primacy Bias</a> (プライマシーバイアス, 初頭バイアス)[心理学で使われていた用語が機械学習でも使われるようになった]
</li>

<br>

<li id="CDS">
<strong>Causal Discovery Methods（統計的因果探索）</strong><br>
観察データのみから変数間の因果構造（どの変数が原因で、どれが結果か）を推定する手法の総称。<br>
通常、因果関係を調べるには因果グラフ（構造）が事前に分かっている必要があるが、因果探索はデータからそのグラフ自体を構築することを目的としている。<br>
<br> 
<strong>制約ベース手法 (Constraint-based methods)</strong>　変数間の独立・非独立の関係を統計的検定によって調べ、因果の向きを特定する。<br>
・代表例：PCアルゴリズム、FCI（潜在的な共通原因がある場合に対応）<br>
<br>
<strong>スコアベース手法 (Score-based methods)</strong>　データへの適合度を示す「スコア関数」を定義し、最もスコアの高い因果グラフを探索する。<br>
・代表例：GES (Greedy Equivalence Search)<br>
<br>
<strong>関数型因果モデル (Functional Causal Models)</strong>　データの発生過程（誤差項の分布など）に特定の仮定を置き、因果の方向を一意に定めます。<br>
・代表例：LiNGAM（線形非ガウス非巡回モデル）。データが非ガウス分布（正規分布ではない）に従う場合に、因果の向きを特定できる強力な手法。<br> 
<br>
<strong>因果推論（Causal Inference）との違い</strong><br>
・因果探索： 「原因は何か？」という構造（矢印の向き）を見つける。<br>
・因果推論： 「原因を変えると結果がどれだけ変わるか？」という効果の大きさ（数値）を算出する。 
<li>

<br>

<li id="CFC">
<strong>CFC: Cross-frequency coupling (周波数間カップリング) </strong><br>
異なる周波数帯域の脳波（神経振動）の間における相互作用、または統計的な関係性の総称。<br>
脳は多様な周波数(例：シータ波、ガンマ波)で活動しており、これらの異なるリズムが相互に影響し合うことで、認知機能、記憶、学習などの複雑な情報処理を協調させていると考えられている。<br>
CFCにはいくつかの形態がある。<br>
・位相-振幅カップリング(PAC): 低周波の位相が高周波の振幅を調節する。<br>
・振幅-振幅カップリング(AAC): 2つの異なる周波数帯域の振幅が互いに影響し合う。<br>
・位相-位相カップリング(PPC): 2つの異なる周波数帯域の位相が同期する。 <br>
CFCは、脳内の異なる領域間や、局所的な神経回路内での情報伝達を調整する役割を担っている。例えば、記憶形成に関わる脳の領域（海馬など）でシータ波とガンマ波のPACが学習成績と相関することが示されており、異なる種類の情報処理を結びつけるメカニズムである可能性が示唆されている。<br>
<br>
●『Theta–gamma coupling increases during the learning of item–context associations』(2009)<br>
　ラットが特定の環境でどの刺激が報酬と関連しているかを学習する課題において、学習が進むにつれて海馬 CA3 領域のシータ波とガンマ波の PAC が強まることを示した。<br>
</li>

<br>

<li id="CLS">
<strong>CLS: Complementary Learning Systems (相補的学習システム)</strong><br>
脳における記憶と学習に関する認知神経科学の主要な理論モデルの一つ。<br>
<br>
エピソード記憶など、新しい情報や具体的な出来事を急速に学習・記憶する<strong>海馬 (Hippocampus)</strong> と, 長期的な記憶の統合、一般的な知識、スキルなど保持する <strong>新皮質 (Neocortex)</strong> の2つのシステムが相補的に機能する, とするモデル。海馬で一時的に保持された情報が、睡眠中などに海馬と新皮質の間で繰り返しやり取りされる（再活性化）ことで、最終的に新皮質へと移行し、長期的な安定した記憶として定着すると考えられている。<br>
<br>
●『Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory.』(1995)<br>
　(海馬と大脳新皮質に補完的な学習システムが存在する理由：学習と記憶のコネクショニストモデルの成功と失敗からの洞察)<br>
　海馬系が損傷すると、最近の記憶は破壊されるが、遠い記憶はそのまま残る。ここで提示された説明は、記憶がまず海馬系のシナプス変化を介して保存され、これらの変化が大脳新皮質における最近の記憶の復元をサポートし、大脳新皮質のシナプスは復元ごとに少しずつ変化し、遠い記憶は蓄積された大脳新皮質の変化に基づくことを示唆している。接続の変化を介して学習するモデルは、この構成を説明するのに役立つ。これらのモデルは、各項目の学習が段階的であり、他の項目の学習と交互に行われる場合、項目のアンサンブル内の構造を発見する。これは、大脳新皮質が経験のアンサンブル内の構造を発見することをゆっくりと学習することを示唆している。海馬系は、この構造を破壊せずに新しい項目を迅速に学習することを可能にし、新しい記憶の復元はそれらを他の記憶と交互に配置して、構造化された大脳新皮質記憶システムに統合する。<br>
<br>
●『The AI Hippocampus: How Far are We From Human Memory?』(2026) 解説は<a href="https://www.alphaxiv.org/ja/overview/2601.09113">こちら</a><br>
　大規模言語モデル（LLM）およびマルチモーダル大規模言語モデル（MLLM）における記憶メカニズムについて、人間の脳システム（新皮質、海馬、前頭前野）との類推を通じて構造化された包括的なレビューを発表した。
</li>

<br>

<li id="CodeAsTool">
<strong>Code-as-tool</strong><br>
AIモデルがタスクを完了するために内部的にコード（通常はPython）を生成、実行、デバッグする機能やアプローチ。複雑な計算、データ分析、論理的推論など、従来のテキストベースの応答だけでは難しい問題を解決するために使用される。<br>
<br>
●『PAL: Program-aided Language Models』(2022)<br>
・CoT の概念をさらに発展させ、思考連鎖を自然言語ではなく、実行可能なコード (Python) として表現するというアイデアを導入した。<br>
<br>
●『Toolformer: Language Models Can Teach Themselves to Use Tools』(2023)<br>
　(ToolFormer: ツールフォーマー：言語モデルはツールの使い方を自ら学習できる)<br>
・言語モデルがシンプルなAPIを介して外部ツールの利用を自ら学習し、両方の長所を活かすことができることを示す。<br>
・どのAPIをいつ呼び出すか、どのような引数を渡すか、そしてその結果を将来のトークン予測にどのように組み込むのが最適かを決定するように学習される。<br>
・これは自己教師あり学習で行われ、各APIについて数回のデモン​​ストレーションを行うだけで済む。<br>
・Toolformerは、コアとなる言語モデリング能力を犠牲にすることなく、ゼロショット性能を大幅に向上させ、多くの場合、はるかに大規模なモデルに匹敵する性能を実現する。
</li>

<br>


<li id="CognitiveAgent">
<strong>Cognitive Agent (認知エージェント)</strong><br>
人間の認知プロセス（知覚、学習、推論、意思決定など）を模倣するように設計された、AIエージェントのこと。<br>
<br>
●『ReAct: Synergizing Reasoning and Acting in Language Models』(2022)<br>
・<strong><span style="color:magenta;">大規模言語モデルが内部の思考と外部のアクションを交互に実行する</span></strong>ことで、推論と行動を相乗的に組み合わせることを可能にするReActというパラダイムを発表した。<br>
・<strong><span style="color:magenta;">エージェントのアクション空間をドメイン固有のアクション \(A\) から \(\hat{A}= A \cup L(言語ベースの推論)\) へと拡張</span></strong>することで、従来のエージェントと環境の相互作用を強化
した。<br>
・これにより、モデルは次に取るべきアクションについて推論し、目標に対する進捗を追跡し、例外を処理し、環境からの新しい情報を推論プロセスに組み込むことができる。<br>
●『Reflexion: Language Agents with Automatic Reflection』(2023)<br>
・エージェントが失敗した推論や行動の軌跡(trajectory)を分析し、それに基づいて将来の行動計画を改善するための<strong><span style="color:magenta;">「内省(reflection)」を行うことを可能にした</span></strong>。<br>
これにより、<strong><span style="color:magenta;">外部からの追加の人間による介入なしに、エージェントが自律的にパフォーマンスを向上させることができる</span></strong>。<br> 
●『Voyager: An Open-Ended Embodied Agent with Large Language Models』(2023)<br>
・Minecraft における初の LLM を活用した<strong><span style="color:magenta;">生涯学習エージェント</span></strong>。<br>
人間の介入なしに世界を継続的に探索し、多様なスキルを習得し、斬新な発見をする。<br>
●『Mastering Diverse Domains through World Models』(2023)<br>
・人間のデータやカリキュラムなしで Minecraft でダイヤモンドをゼロから収集する最初のアルゴリズム。<br>
<br>
<a href="data/Papers_CognitiveAgent.html">Papers</a><br>
<br>
<center><img src="data/images/CognitiveAgent.svg"></center>

<br>(関連項目)<br>
・<a href="#AIAgent">AI Agent</a> (AI エージェント)<br>
　定義されたルールやスクリプトに従って動作する。特定のタスクを効率的に実行できるが、予期せぬ状況への対応は苦手。
</li>

<br>

<li id="CompositionalGeneralization">
<strong>Compositional Generalization (組み合わせ的一般化, 構成的汎化)</strong><br>
人間が持つ「限られた手段で無限の新しい組み合わせを理解・生成できる能力」をAIに持たせることを目指すもの。源流は認知科学や言語学に深く根ざしている。 <br>
<br>
●『Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks』 (2017)<br>
・人間は構成能力(compositional skills)のおかげで、新しい発話を難なく理解し、生み出すことができる。<br>
　「dax」という新しい動詞の意味を一度覚えれば、「dax twice」や「sing and dax」の意味もすぐに理解できる。<br>
・汎化に体系的な構成能力が必要な場合（上記の「dax」の例のように）、RNNは見事に失敗する。<br>
・体系性の欠如がニューラル ネットワークの悪名高いトレーニング データの渇望の一因となっている可能性があることを示唆した。<br>
<br>
●『Compositional Generalization from First Principles』 (2023)<br>
　　(第一原理からの構成的汎化)<br>
・構成的汎化をより深く理解するために、ボトムアップアプローチを採用する。<br>
・識別可能表現学習に着想を得て、データそのものではなく、データ生成プロセスの特性として構成性を検証する。<br>
・この再定式化により、訓練分布のサポートとモデルアーキテクチャのみに基づいて、構成的汎化に十分な条件を導出できる。<br>
<br>
●『When does compositional structure yield compositional generalization? A kernel theory』(2024)<br>
　　(構成構造はいつ構成的汎化をもたらすのか？ カーネル理論)<br>
<br>
●『Learning by Analogy: A Causal Framework for Composition Generalization』(2025)<br>
　(アナロジーによる学習：構成的汎化のための因果的フレームワーク)<br>
　高レベルの概念(ニワトリ, 米, クジャク)が共有する低レベルの構成要素(くちばし、羽、足)に分解され、「米を食べるクジャク」のような新しい構成を生成するために再結合される様子を示している。<br>

<center><img src="data/images/LearningByAnalogy.svg"></center>


<br>(関連項目)<br>
・<a href="#CompositionalityGap">Compositionality Gap</a> (構成性ギャップ)<br>
・<a href="#LoTH">LoTH: Language of Thought hypothesis</a> (思考の言語仮説)<br>
・Systematic compositionality (体系的構成性, 系統的体構成性) ･･･ 哲学, 認知科学の用語<br>
・Infinite use of finite means (有限手段の無限利用)<br>
　ドイツの言語学者 Wilhelm von Humboldt (ヴィルヘルム・フォン・フンボルト)が提唱し, 後に Noam Chomsky (ノーム・チョムスキー)が「生成文法」理論の核心的な概念として引用して有名になった。
</li>

<br>

<li id="CompositionalityGap"><strong>Compositionality Gap (構成性ギャップ)</strong><br>
AIモデルが、個々の独立した事実は知っているにもかかわらず、それらを組み合わせて複雑な問題を解くことが苦手な現象。<br>
<br>
●『Measuring and Narrowing the Compositionality Gap in Language Models 』(2022)<br>
・「構成性ギャップ」という概念を導入した。<br>
・大規模言語モデルにおける事実想起と構成的推論の間のギャップを定量化し、それがモデルのスケールに関わらず持続的であることを発見した。<br>

<br>(関連項目)<br>
・<a href="#CurseOf2hopReasoning">Curse of two-hop reasoning</a>（2ホップ推論の呪い）<br>
・<a href="#LoTH">LoTH: Language of Thought hypothesis</a> (思考の言語仮説)<br>
・<a href="#CompositionalGeneralization">Compositional Generalization</a> (組み合わせ的一般化, 構成的汎化)
</li>

<br>

<li id="ConditionalComputationParadigm">
<strong>conditional computation paradigm (条件付き計算パラダイム)</strong><br>
入力データに基づいてニューラルネットワークやモデルの異なる部分（エキスパートやモジュールと呼ばれる）を選択的に活性化させ、実行するパラダイム。すべての計算リソースをすべての入力に対して常に使用するのではなく、特定のデータに適した部分だけを「条件付き」で使うため、その名前が付けられた。<br>
<br>
●『Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models』(2026)<br>
・スパース性は、生物学的神経回路から現代の大規模言語モデル（LLM）へと発展した。計算量の増加に比例することなくモデルサイズを大幅に拡大できるため、MoEはフロンティアモデルの事実上の標準となっている。<br>
・<strong><span style="color:magenta;">標準的なトランスフォーマーにはネイティブな知識検索プリミティブ(基本機能)がないため、現在のLLMは計算を通じて検索をシミュレートせざるを得ない</span></strong>。<br>
・条件付き計算は、動的ロジックを処理するためにパラメータをスパースにアクティブ化するのに対し、<strong><span style="color:magenta;">条件付き記憶は、固定された知識の静的埋め込みを取得するためにスパースなルックアップ操作に依存する</span></strong>。<br>
<br>(関連項目)<br>
・<a href="#MoE">MoE: Mixture-of-Experts (専門家混合)</a>
</li>

<br>

<li id="ConfirmationBias">
<strong>Confirmation Bias (確証バイアス)</strong><br>
自分の仮説や信念を裏付ける情報ばかりを集めて、反証する情報を無視したり軽視したりする傾向を指す心理学の用語。<br>
<br>
●『Confirmation Bias in Generative AI Chatbots』(2025)<br>
　ユーザー(人間)とのチャットを通じてAIが人間の確証バイアスに誘導され, ユーザーの確証バイアスが増幅される可能性がある。<br>
●『Generative artificial intelligence–mediated confirmation bias in health information seeking』(2025)<br>
　ChatGPTなどの生成型人工知能（GenAI）アプリケーションは、会話型で高度にパーソナライズされたインタラクションを提供する。この高度にカスタマイズされた応答を生成する能力は、既存の信念を強化し、医学的コンセンサスを曖昧にし、誤情報を永続させることで確証バイアスを増幅させるリスクがある。<br>
●『Does AI Make People More Open or Reinforce Bias?』(2025)<br>
　AIがユーザーの確証バイアスを強めるか、あるいは緩和するかの<strong><span style="color:magenta;">分析モデルを構築した</span></strong>。<br>
　情報の出所や意思決定の種類、そして情報がユーザーの先入観と一致するかによって、AIの影響は異なる。<br>
<br>(関連項目)<br>
・<a href="#Reasoning">Reasoning (推論)</a>
</li>

<br>

<li id="ContinualLearning">
<strong>Continual Learning (継続学習)</strong><br>
機械学習モデルが、新しいタスクやデータに順次対応しながらも、これまでに獲得した知識を忘れないように学習し続けることを目指す技術。<br>
別名, Lifelong Learning (生涯学習)。<br>
・Continual Learning(継続学習), Lifelong Learning(生涯学習)は、将来の分布シフトの予測までは行わない。<br>
・Prospective Learning(展望学習), Inductive Learning(帰納学習)は将来の分布シフトを(時間パラメータ付き)仮説として出力する<br>
<br>
<center><img src="data/images/OOD.svg"></center>
<br>
<a href="data/Papers_ContinualLearning.html">Papers</a><br>
<br>
●『PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning』(2017)<br>
・壊滅的な忘却を回避しながら、単一のディープニューラルネットワークに複数のタスクを追加する手法を提示する。<br>
・反復的な枝刈りとネットワークの再学習を行うことで、パフォーマンスの低下とストレージのオーバーヘッドを最小限に抑えながら、複数のタスクを単一のネットワークに順次「詰め込む」ことができる。<br>
<br>
<center><img src="data/images/PackNet.svg"></center>
<br>

<br>(関連項目)<br>
・<a href="#CatastrophicForgetting">Catastrophic Forgetting</a> (破局的忘却)[課題]<br>
・<a href="#LossOfPlasticity">Loss of Plasticity</a> (可塑性喪失)[課題]<br>
・<a href="#PrimacyBias">Primacy Bias</a> (プライマシーバイアス, 初頭バイアス)[課題]<br>
・<a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
・<a href="#DEN">DEN: Dynamically Expandable/Growth Networks</a> (動的成長ネットワーク)<br>
・Cumulative Learning (累積学習)<br>
　　新しい知識やスキルを既存の知識体系に統合し、積み上げていく学習プロセス。
</li>

<br>

<li id="ContrastiveLearning">
<strong>Contrastive Learning (対照学習)</strong><br>
機械学習における自己教師あり学習 (SSL: Self-Supervised Learning) の一種。<br>
データを「似ているペア（正例）」と「似ていないペア（負例）」に分け、モデルがこの違いを認識できるように学習する。最終的に、潜在空間において、正例のベクトル表現は近づけ、負例のベクトル表現は遠ざけることを目指す。<br>
(蛇足: 正常データを与えて異常検知する(One-Class Anomaly Detection)のと似ている気がする･･･)<br>
<br>
●『Representation Learning with Contrastive Predictive Coding』(2018)<br>
　(対照予測符号化を用いた表現学習)<br>
　様々なモダリティの高次元の生データから高レベルで有用な表現を抽出する汎用的な教師なし学習フレームワークであるContrastive Predictive Coding (CPC) を導入した。<br>
<br>
●『A simple framework for contrastive learning of visual representations』SimCLR(2020)<br>
　(視覚表現の対照学習のためのシンプルなフレームワーク)<br>
　画期的な対照学習手法である SimCLR を導入した。<br>
<center><img src="data/images/SimCLR.svg"></center>
<br>
SimCLR: 視覚表現の対照学習のためのシンプルなフレームワーク<br>
・拡張演算子がサンプリングされ、データに適用されて相関ビューが得られる。<br>
・ベースエンコーダネットワークf(･)と投影ヘッドg(･)は、対照損失を用いて一致を最大化するように学習される。<br>
・学習が完了したら、投影ヘッドg(･)を破棄し、エンコーダf(･)とエンコーダーの出力(表現 h)を下流のタスクに使用する。<br>
　(蛇足: 一緒に学習してきた相方を捨てるところが GAN に似ている気がする･･･)<br>
<br>(関連項目)<br>
・<a href="#SSL">SSL: Self-Supervised Learning (自己教師あり学習)</a>
</li>

<br>
<li id="CoP">
<strong>CoP: The Collapse of Patches (パッチ崩壊)</strong><br>
画像を小さな領域 (パッチ) に分割して処理するモデルにおいて、画像内のある特定のパッチを観察すると、他のパッチに関する不確実性が大幅に減少することがある。この効果は、量子力学における「波動関数の収縮(崩壊)」に類似していると直感的に表現され、「パッチ崩壊」と呼ばれている。<br>
<br>
●『The Collapse of Patches』(2025)<br>
<center><img src="data/images/CoP.svg"></center>
・パッチの崩壊概念の視覚化。オンドリの鶏冠、くちばし、羽毛のような高ランクのパッチを観察すると、画像全体の不確実性が段階的に減少することを示している。一方、背景の土や草のような相関の低い特徴は、画像理解への寄与が少ない。<br>
・画像内の特定のパッチを観察すると、他のパッチの不確実性が減少する。それらの実現は、量子力学における粒子の波動関数の崩壊に類似しており、残りの各パッチ特徴の分布エントロピーを低下させる。この現象は直感的にパッチ崩壊と呼ぶことができる。<br>
・ターゲット領域の崩壊中にどのパッチが最も信頼されているかを識別するために、パッチのサブセットをソフトに選択して各ターゲットパッチを再構築するオートエンコーダを学習する。各パッチの PageRank スコアについて学習したこれらの依存関係をグラフ化すると、画像を実現するための最適なパッチ順序が明らかになる。<br>
<center><img src="data/images/CoP2.svg"></center>
・画像が与えられると、CoMAEエンコーダーは各パッチを再構成するために必要な最も影響力のあるパッチを選択する。重要でないパッチは、より強いノイズ注入によってマスクされる。<br>
・選択重みはパッチ依存グラフを形成し、これに基づいてPageRankスコアを計算してパッチの崩壊順序を決定する。<br>
・ランキングを使用して、画像生成タスクと分類タスクが正しいパッチ処理順序に従うように教師学習される。
</li>

<br>

<li id="CoT">
<strong>CoT: Chain-of-Thought (思考連鎖)</strong><br>
大規模言語モデル（LLM）の性能を向上させるためのプロンプト技術の一種。<br>
複雑な問題を解く際に、最終的な答えだけでなく、その答えに至るまでの論理的な思考プロセスを段階的に示すようモデルに促すことで、推論能力を高める。<br>
<br>
<a href="data/Papers_CoT.html">Papers</a>
<br>
<center><img src="data/images/CoT.svg"></center>
<br>(関連項目)<br>
・<a href="#CurseOf2hopReasoning">Curse of two-hop reasoning</a>（2ホップ推論の呪い）<br>
・<a href="#SelfConsistency">Self-Consistency</a> (自己無撞着性, 自己整合性)<br>
・<a href="#ToT">ToT: Tree of Thoughts</a> (思考ツリー)
</li>

<br>

<li id="CoV">
<strong>CoV: Chain-of-View</strong><br>
VLM（視覚言語モデル）に空間推論を行わせるための新しいプロンプティング手法、または推論フレームワーク。<br>
<br>
●『CoV: Chain-of-View Prompting for Spatial Reasoning』(2026)<br>
　解説は<a href="https://www.alphaxiv.org/ja/overview/2601.05172">こちら</a><br>
　Embodied Question Answering (EQA) は、人工知能における極めて重要な進歩を表しており、システムが3D環境を理解し、推論しながら自然言語の質問に答えることを課題としています。この分野では、エージェントが視覚的知覚と空間的推論を結びつけ、人間が周囲を自然に探索し理解する方法を模倣することが求められます。現在のVision-Language Models (VLM) は、EQAタスクに適用される際に重大な制約に直面します。これらは通常、固定された有限の入力ビューセットで動作するため、質問に関連する十分なコンテキストを収集する能力が著しく制限されます。<br>
<br>(関連項目)<br>
・<a href="#EQA">EQA: Embodied Question Answering</a><br>
・<a href="#SpatialReasoning">Spatial Reasoning</a> (空間推論)<br>
・<a href="#ActiveInference">Active Inference</a> (能動推論)<br>
</li>

<br>

<li id="CoVT">
<strong>CoVT: Chain-of-Visual-Thought (視覚的思考連鎖)</strong><br>
AI、特にVision-Language Models（VLM: 画像言語モデル）における推論手法の一つ。<br>
大規模言語モデル（LLM）で広く用いられている「Chain-of-Thought (CoT: 思考連鎖)」プロンプティングの概念を視覚領域に応用・拡張したもの。<br>
<br>
●『Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens』(2025)<br>
　約20トークンという小さな予算内で、COVTは軽量な視覚専門家から知識を抽出し、2Dの外観、3Dの幾何学、空間配置、エッジ構造などの補完的な特性を捉える。<br>
<center><img src="data/images/CoVT.svg"></center>
トークンに知覚的意味を与えるために、トレーニング中にそれぞれのタスクにおいて軽量ビジョンエキスパート(SAM、DepthAnything、PIDINet、DINOなど)と連携させる。<br>
・SAM（Segmentation Anything Model) は視覚トークンをマスクプロンプトとして使用<br>
・DepthAnything は視覚トークンを使用して深度を再構築<br>
・PIDINet (Pixel Difference Network) は視覚トークンを使用してエッジを再構築<br>
・DINO (Self-<strong>di</strong>stillation with <strong>no</strong> labels) は視覚トークンを使用してパッチレベルの特徴をマッチングを実施<br>

</li>

<br>

<li id="CSB">
<strong>CSB: Choice Supportive Bias (選択支持バイアス)</strong><br>
自分が下した選択を後から正当化し、選ばなかった選択肢を過小評価する認知バイアス。<br>
<br>
<strong>選択の美化</strong>: 人は、一度何かを選ぶと、その選択肢の良い点を実際よりも過大に評価する傾向がある。<br>

<strong>非選択肢の軽視</strong>: 反対に、選ばなかった選択肢の欠点を強調したり、良い点を忘れてしまったりする。<br>

<strong>後悔の軽減</strong>: このバイアスは、自分の決定に対する満足感を高め、意思決定後の後悔（バイヤーズリモース）を減らすための防衛機制として働く。<br>

<strong>記憶の歪曲</strong>: 記憶が関与しており、選択を裏付けるように過去の記憶が歪められることがある。<br>
<br>
●『Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation』(2025)<br>
　(推論依存関係生成によるLLMにおける選択支持バイアスの軽減)<br>
　「最近の研究では、一部の大規模言語モデルが評価を行う際に選択支持バイアス（CSB）を示し、選択されたオプションを体系的に支持し、AI支援による意思決定の客観性を損なう可能性があることが実証されている･･･」<br>
<br>(関連項目)<br>
・post-purchase rationalization (購入後合理化) ･･･ Choice Supportive Bias (選択支持バイアス)の別名。<br>
　購入した楽曲, 映画館に観に行った映画･･･
</li>

<br>

<li id="CuriosityDriven">
<strong>Curiosity-driven（好奇心駆動型）</strong><br>
強化学習において、エージェントが未知の状態や予測が困難な環境を積極的に探索するように、内発的な動機づけを与える手法のこと。<br>
<br>
●『States of curiosity modulate hippocampus-dependent learning via the dopaminergic circuit』(2014)<br>
　(好奇心の状態はドーパミン回路を介して海馬依存性学習を調節する)<br>
　人は興味のあるトピックを学ぶ方が簡単だと感じるが、内発的動機づけ状態が学習にどのようなメカニズムで影響するかについてはほとんどわかっていない。我々は機能的磁気共鳴画像法を用いて、好奇心（学習への内発的動機づけ）が記憶にどのように影響するかを調べた。即時記憶テストと1日遅延記憶テストの両方で、参加者は<strong><span style="color:magenta;">好奇心の強い情報と、好奇心が強い状態で学習した付随的な内容に対する記憶力が向上した</span></strong>。<br>
　・・・<br>
　これらの知見は、外発的報酬動機づけと内発的好奇心を支えるメカニズムの間に関連があることを示唆しており、より効果的な学習体験を生み出すために好奇心を刺激することの重要性を強調する。<br>
<br>
●『Curiosity-driven Exploration by Self-supervised Prediction』(2017)<br>
　(自己教師予測による好奇心主導の探究)<br>
　論文は<a href="https://arxiv.org/abs/1705.05363">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/1705.05363v1">こちら</a><br>
　予測誤差を単なる「修正用信号」ではなく、エージェントを動かす「報酬そのもの」として定義し、探索効率を劇的に向上させた。<br>


<br>
・<a href="https://davidbau.com/archives/2025/12/09/in_defense_of_curiosity.html">In Defense of Curiosity</a> (好奇心を擁護する)</br>
　5000年もの間、人々は「考えるとはどういうことか」と問い続け、その答えは常に人間の心を中心に置いてきました。人間は唯一、合理的思考の好例であり、クジラやタコといった動物はその周辺に位置していました。<br>
<br>
<center><img src="data/images/CopernicanMoment.png"></center><br>
　しかし、AIの登場により、この見方は変化し、人間の心は中心という特権的な地位を失いつつあります。<br>
<!--
　：<br>
　<strong>好奇心に従ってください</strong>。それが私のメッセージです。私たちは好奇心を持たなければなりません。なぜなら、私たちはコペルニクス的転回を生きているからです。<br>
　5000年ぶりに、合理的思考に対する私たちの理解は変化しつつあります。アリストテレスは人間が唯一理性的な生き物であると提唱し、聖トマス・アクィナスは人間の理性こそが人間を唯一精神的な存在にしたと考えました。そしてデカルトは「我思う、故に我あり」という有名な言葉を残しており、理性と人格を同一視しています。<br>
　しかし今、私たちが生み出した思考装置は、これらの古き哲学者たちの考えを覆すものです。人間の心はもはや宇宙の中心ではなくなりました。AIが初めて、知性のもう一つの例を与えてくれたからです。それは遠くから観察できるだけでなく、細かく分解して、あらゆる計算、あらゆるニューロン、あらゆる学習の瞬間を分析できるものでもあります。<br>
　革命は私たちに多くの根本的な問いを突きつけます。思考とは何か？信念とは何か？意味とは何か？主体性とは？意識とは何か？<br>
　これらの疑問に答える実際的な理由がなくても、私たちは好奇心に従うべきです。コペルニクス的転回は、かつては科学的ではなかった多くの古代の疑問を解き明かし、今やそれらを科学的な疑問へと昇華させるのです。実用的なガラス作りに取り組む中で、少し時間を取ってレンズを星々に向けてみましょう。そして、考えるとはどういうことか、という問いを忘れずに問いかけるべきでしょう。<br>
-->

<br>(関連項目)<br>
・<a href="#IDTheory">ID: Interest-Deprivation theory of curiosity (興味・剥奪モデル, 興味・欠乏モデル)</a><br>
・<a href="#IntrinsicMotivation">Intrinsic Motivation</a> (内発的動機付け)<br>
・<a href="#NoisyTVProblem">Noisy TV problem</a> (ノイジーテレビ問題)<br>
・<a href="#NoveltySearch">Novelty Search</a> (新規性探索)</a><br>
・<a href="#TD">TD（Tempral Differences) Learning</a> (TD学習)<br>
</li>

<br>

<li id="CurriculumLearning">
<strong>Curriculum learning (カリキュラム学習)</strong><br>

人間や動物は、例がランダムに提示されるのではなく、意味のある順序で整理され、徐々に多くの概念、そして徐々に複雑な概念を示すように提示されると、はるかによく学習する。このような学習戦略を機械学習の文脈で定式化し、「カリキュラム学習」と呼ぶ。<br>
<br>
<center><img src="data/images/CurriculumLearning.svg"></center>
<br>
●『Curriculum learning』(2009)<br>
　カリキュラム学習の概念を導入した先駆的な論文<br>
<br>
●『From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks』(2025)<br>
　(模倣から識別へ：汎用カリキュラム優位メカニズムによるドメイン横断推論タスクの強化に向けて)<br>
・人間の認知発達にヒントを得た2段階のトレーニングフレームワークである CAPO: Curriculum Advantage Policy Optimization を提案。<br>
　2段階カリキュラム：模倣フェーズ(正のサンプルのみ)と識別フェーズ(正と負の混合サンプル)<br>
・アドバンテージ信号を単なる勾配の重みとしてではなく、学習プロセスを動的に導く内在的なカリキュラム指標として扱う。<br>
　※ アドバンテージ信号：特定のアクションが他のアクションと比較してどれだけ優れているかを示す評価信号(スコア)<br>
<br>
<center><img src="data/images/FromImitationToDiscrimination.svg"></center>
<center><img src="data/images/FromImitationToDiscrimination2.svg"></center>
<center><img src="data/images/FromImitationToDiscrimitation3.svg"></center>

模倣フェーズと識別フェーズの切り替え後、ネガティブサンプルはエントロピーと報酬の着実な増加をもたらし、汎化の向上を示している。<br>
・Training Entropy：エージェントの行動の多様性, ランダム性<br>
・Training Rewards：エージェントがトレーニング中に環境と相互作用することによって獲得する報酬の総和または平均値

<!--
<a href="data/Papers_CurriculumLearning.html">Papers</a>
-->
</li>

<br>

<li id="CurseOfDimensionality">
<strong>Curse of Dimensionality (次元の呪い)</strong><br>

データや問題の次元数（特徴量の数）が増えるにつれて、必要なデータ数や計算量が指数関数的に増加し、計算効率の低下やモデルの精度低下を招く現象。<br>
・計算コストの爆発：計算量が \(2^{次元},(次元)^2\), ･･･ だと手に負えなくなる。<br>
・疎らなデータ:　高次元ではデータがまばらになる<br>
・距離の均一化:　どのデータもほぼ同じ距離になる<br>
・球面集中現象(concentration on the sphere): ほとんどのデータが球の表面近くに分布するようになる<br>
　：<br>
「次元の呪い」だけでなく「次元の祝福」もある。<br>
●『The curses and blessings of dimensionality』(2000)<br>
・高次元空間には特有の構造（例えば、低次元の多様体など）があり, 新たな手法が生まれる可能性がある。<br>
<br>
<a href="data/Papers_Curse_of_Dimensionality.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#Hubness">Hubness (ハブ性)</a>
</li>

<br>

<li id="CurseOf2hopReasoning"><strong>Curse of two-hop reasoning（2ホップ推論の呪い）</strong><br>
大規模言語モデル（LLM）が、個別に学習した2つの事実（例: A→B と B→C）を結びつけて推論する（例: A→C）ことができない、または非常に困難であるという現象。<br>
(例)1ホップの質問：「『イマジン』の演奏者は誰?」「ジョン・レノンの配偶者は誰?」には答えられる。<br>
　　2ホップの質問：「『イマジン』の演奏者の配偶者は誰?」）には答えられない。<br>
<br>
●『The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C』 (2024)<br>
　論文は<a href="https://arxiv.org/abs/2411.16353v1">こちら</a><br>

推論のステップを明示的に示す「思考の連鎖（Chain-of-Thought）」プロンプティングがあれば、2ホップ推論を実行できる。しかし、そうした明示的な指示がないと、個々の事実を結合できない。<br>
これは、LLMが学習データから自動的に、あるいは「潜在的に」推論ステップを結びつける能力が欠けていることを示唆している。<br>
Compositionality Gapの一例。<br>
<br>(関連項目)<br>
・<a href="#CompositionalityGap">Compositionality Gap</a> (構成性ギャップ)<br>
・<a href="#CoT">CoT: Chain-of-Thought</a> (思考連鎖)
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="D">D</h2>
<p>
<div class="styleBullet">
<ul>
<li id="DataAugmentation">
<strong>Data Augmentation (データ拡張) </strong><br>
機械学習において、既存の学習データを人為的に加工・変換することで、データセットの量と多様性を増やすための技術。<br>

・目的：データ不足の解消 / 汎化性能の向上 / モデルのロバスト性向上<br>
・手法例(画像の場合)：回転, 反転, 切り出し, 拡大縮小, 平行移動, 明るさコントラスト調整, ぼかしノイズ付加<br><br>
●『A Flat Minima Perspective on Understanding Augmentations and Model Robustness』(2025)<br>
　　データ拡張により, Loss Landscape が平坦になり, 汎化性能, 堅牢性やドメインシフト耐性が向上する。<br>
<center><img src="data/images/DataAugmentation.svg"></center>
<center>経験的リスク(Empirical Risk): 学習データによる損失(平均誤差)</center>
<center>ターゲットリスク：目標とする真の損失</center>
<br>(関連項目)<br>
・<a href="#FlatMinima">Flat minima hypothesis</a> (平坦な最適解空間仮説)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)<br>
・<a href="#ERM">ERM: Empirical Risk Minimization</a> (経験的リスク最小化)
</li>

<br>

<li id="DDL">
<strong>DDL: Deep Delta Learning (ディープデルタ学習)</strong><br>
「残差接続（Residual Connection）」の仕組みを進化させた新しいアーキテクチャー。<br>
<br>
●『Deep Delta Learning』(2026)<br>
ディープ残差ネットワーク (ResNet) は、恒等ショートカット接続を通じて非常に深いネットワークのトレーニングを可能にすることで、ディープラーニングに革命をもたらしたが、残差接続は厳密に加算的であり、ネットワークが学習できる変換の種類を制約する硬直した帰納バイアスを生じた。Deep Delta Learning（DDL）と呼ばれる新しいアーキテクチャフレームワークは、標準的な残差接続を一般化するデータ依存の幾何学的変換を導入することで、この制限に対処する。<br>
<br>
入力データ \(X\) に基づいて計算される「ゲート・スカラー \(\beta (X)\)」により、層ごとの情報の扱いを3つのモードでスムーズに切り替える。<br>
<br>
<ul><li>
<strong>Skip:スキップ (\(\beta =0\)）</strong>：前の情報をそのまま維持する
</li><li>
<strong>Clean/Forget:クリーン（\(\beta =1\)）</strong>：特徴空間を書き換え、不要な干渉を取り除く
</li><li>
<strong>Reflection:反転（\(\beta =2\)）</strong>：情報を幾何学的に反転させ、複雑な対立関係や動的な変化を捉える
</li></ul>
<br>
<center><img src="data/images/DeltaResidualBlock.svg"></center>
<center>Delta Residual Block</center><br>
<br>(関連項目)<br>
・<a href="#SkipConnection">Skip Connection</a> (スキップ接続)<br>
</li>

<br>

<li id="DecisionBoundary">
<strong>Decision Boundary (決定境界)</strong><br>
機械学習の分類問題において、異なるクラス（カテゴリ）のデータを区別するためにモデルが学習によって作り出す境界線や面のこと。
\[
\begin{array}{c|c}
特徴量の数 & 境界 \\
\hline
2 & 境界線(直線または曲線) \\
3 & 境界面(平面または曲面) \\
\gt 3 & 境界面(超平面)
\end{array}
\]
<center><img src="data/images/DecisionBoundary.svg"></center>
</li>

<br>

<li id="DEN">
<strong>DEN: Dynamically Expandable/Growth Networks (動的成長ネットワーク)</strong><br>
継続学習（Continual Learning、または Lifelong Learning）の分野で用いられる手法の一つ。学習の過程でニューラルネットワークの構造やサイズ（容量）を動的に変化（拡大）させることを特徴とする。<br>
<br>
●『Lifelong Learning with Dynamically Expandable Networks』(2017)<br>
・生涯学習のための新たなディープネットワークアーキテクチャ「Dynamically Expandable Network (DEN)」を提案。<br>
・このアーキテクチャは、一連のタスクを学習する際にネットワーク容量を動的に決定し、タスク間でコンパクトに重複する知識共有構造を学習することができる。<br>

<center><img src="data/images/DEN.png"></center><br>

・動的に拡張可能なネットワークの増分学習：左：選択的再学習。DENはまず、新しいタスクに関連するニューロンを識別し、それらに関連するネットワークパラメータを選択的に再学習します。中央：動的ネットワーク拡張。選択的再学習で設定された閾値を下回る所望の損失が得られなかった場合、グループスパース性正則化を用いて不要なニューロンを削除しながら、トップダウン方式でネットワーク容量を拡張します。右：ネットワークの分割／複製。DENは各ユニットのドリフト \(ρ_i^t\) を計算し、学習中に元の値から大きくドリフトしたユニットを識別して複製します。<br>

<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習)
</li>

<br>

<li id="DGDA">
<strong>DG: Domain Generalization / DA: Domain Adaptation (ドメイン汎化/ドメイン適応)</strong><br>
<br>
<strong>DG: Domain Generalization (ドメイン汎化)</strong><br>
　未知のターゲットドメインで良好に機能するモデルを訓練すること。<br>
<br>
<strong>DA: Domain Adaptation (ドメイン適応)</strong><br>
　ラベル付けされたソースドメインで訓練されたモデルを、ラベルなしまたは疎にラベル付けされたターゲットドメインに適応させること。<br>
<br>
●『CLIP-Powered Domain Generalization and Domain Adaptation: A Comprehensive Survey』(2025)<br>
　(CLIPを活用したドメイン汎化およびドメイン適応：包括的レビュー)<br>
　論文は<a href="">こちら</a>, 解説は<a href="https://www.alphaxiv.org/overview/2504.14280v1">こちら</a><br>
</li>

<br>

<li id="DiffusionModel">
<strong>Diffusion Model (拡散モデル)</strong><br>
画像や音声、テキストなどのデータを生成するための深層学習モデルの一種。<br>
拡散モデルと連想記憶との間の関連性が確立され, 拡散モデルにおける暗記から汎化への移行について、統計物理学における相転移として特徴づけられている。<br>
<br>
<a href="data/Papers_DiffusionModel.html">Papers</a><br>
<br>
●『DiP: Taming Diffusion Models in Pixel Space』(2025)<br>
　　(DiP: ピクセル空間でディフュージョンモデルを制する(飼いならす))<br>
　・パッチサイズを大きくする(2x2, 4x4→16x16): 情報圧縮のためのVAEを削除<br>
　・Patch Detailer Head でパッチの高周波の詳細を予測<br>
<br>
<center><img src="data/images/DiP.svg"></center>
※ project in ･･･ パッチを1次元化 → DiT (Diffusion Transformer) が受け取れるトークンに変換する。<br>
　 project out ･･･ project in の逆(トークンをピクセルパッチに戻す)<br>
<br>
●『DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation』(2025)<br>
・<strong>LDM(潜在拡散モデル)</strong><br>
　　〇 圧縮された潜在空間で動作することで効率を達成<br>
　　× VAEの再構成品質とアーティファクトによって本質的に制限される。<br>
<br>
・<strong>PDM(ピクセル空間拡散モデル)</strong><br>
　　〇 ピクセル空間で直接動作することで LDM のVAEの制限を回避する<br>
　　× 単一のモデルが粗い意味情報ときめ細かい詳細の両方を同時に学習しなければならない場合に計算上の非効率性に苦しむ。<br>
<br>
・<strong>DeCo</strong><br>
　　2つの専門コンポーネントに分離する周波数分離アーキテクチャー<br>
　　- 低周波数セマンティクスに特化したDiffusion Transformer<br>
　　ｰ 高周波数詳細のための軽量ピクセルデコーダー<br>
<br>
<center><img src="data/images/DeCo.svg"></center>
<center><img src="data/images/DeCo2.svg"></center>
<br>
●『PixelDiT: Pixel Diffusion Transformers for Image Generation』(2025)<Br>
　VAEを必要とせずに、ピクセル空間で直接動作するTransformerベースの拡散モデル。<br>
　グローバルな意味論的モデリングとローカルなピクセル精緻化を戦略的に分離するデュアルレベルTransformerアーキテクチャを採用。<br>
<center><img src="data/images/PixelDiT.svg"></center>
<center>PixelDiT全体構成</center>
<br>
<center><img src="data/images/PixelDiT2.svg"></center>
<center>PiTブロックの詳細</center>
<br>(関連項目)<br>
・<a href="#GenerativeModel">Generative Model</a> (生成モデル)<br>
・<a href="#Memorization">Memorization to Generalization</a> (暗記から汎化へ) <br>
・<a href="#LDM">LDM: Latent Diffusion Model</a> (潜在拡散モデル)<br>
・<a href="#DiT">DiT: Diffusion Transformers</a><br>
</li>

<br>

<li id="DimensionalCollapse">
<strong>Dimensional Collapse (次元崩壊)</strong><br>
主に自己教師あり学習（特にコントラスティブ学習）において、モデルが学習した埋め込み（特徴）ベクトルが、利用可能な高次元空間を十分に活用せず、低次元の部分空間に集中してしまう現象。<br>
<br>
<a href="data/Papers_DimensionCollapse.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#ContrastiveLearning">Contrastive Learning</a> (対照学習)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)</br>
・<a href="#SSL">SSL: Self-Supervised Learning</a> (自己教師あり学習)<br>
・<a href="#RepresentationCollapse">Representation Collapse</a> (表現の崩壊)

</li>

<br>

<li id="DistributionalHypothesis">
<strong>Distributional Hypothesis (分布仮説)</strong><br>
・同じ文脈(Context: 前後関係)で使われる単語は、似た意味を持つ」という考え方。<br>
　「I drink beer.」（私はビールを飲む）<br>
　「I drink wine.」（私はワインを飲む）<br>
　「ビール」と「ワイン」が何らかの共通点（ここでは「飲み物」という属性）を持つと推測できる。<br>

●『Distributional Structure』 (1954)<br>
　単語の意味がその文脈（共起する他の単語）の分布によって決定されるという考え方を定式化。<br>
●『A synopsis of linguistic theory, 1930-1955』 (1957)<br>
　"You shall know a word by the company it keeps."<br>
　(あなたは言葉がいつも一緒にいる仲間によって、その言葉を知るだろう)<br>
　という有名な言葉で、この概念を簡潔かつ詩的に表現し、広く知らしめた。<br>
　英語の古い格言 "A man is known by the company he keeps" をもじったものだと考えられている。<br> 
●『Efficient Estimation of Word Representations in Vector Space』（Word2Vec）(2013)<br>
　<strong><span style="color:magenta;">分布仮説を、計算効率の高いニューラルネットワークモデルで実装した。</span></strong><br>

<br>(関連項目)<br>
・<a href="#WordEmbeddings">Word Embeddings</a> (単語埋め込み)
</li>

<br>

<li id="DiT">
<strong>DiT: Diffusion Transformers</strong><br>
画像生成などに使われる拡散モデル（Diffusion Model）において、従来のU-Netに代わり、Transformerのアーキテクチャを採用したモデル。<br>
<br>
●『Scalable Diffusion Models with Transformers』(2022)<br>
　　DiTアーキテクチャーを提案した。<br>
<br>(関連項目)<br>
・<a href="#LDM">LDM: Latent Diffusion Model</a> (潜在拡散モデル)
</li>

<!--
<br>
<li id="DivergentThinking">
<strong>Divergent Thinking (発散思考)</strong><br>
自由な発想で多様なアイデアや解決策を可能な限り多く生み出すための思考プロセス。<br>
⇔ Convergent Thinking (収束思考)<br>
\[
\begin{array}{l|l|l}
\text{思考法} & \text{特徴} & \text{目的}\\
\hline

\text{Divergent (発散的)}& \text{自由・多様・斬新}& \text{アイデアを広げる}\\
\hline

\text{Convergent (収束的)}&\text{論理的・体系的・効率的・実現可能}& \text{選択肢を絞り込む, アイデアを評価し計画立案へ}\\
\end{array}
\]
</li>
-->

<br>

<li id="DoubleDescent">
<strong>Double Descent (二重降下)</strong><br>

モデルの複雑さを増していき, モデルが過剰パラメータ化された領域ではテスト誤差が再び減少し始めるという現象。<br>

従来の機械学習の常識である「バイアス・バリアンスのトレードオフ」を覆すものとして、深層学習の研究で注目された。 <br>

「補間閾値」（モデルが訓練データを完全に記憶する点）でテスト誤差がピークに達し、それを超えてさらにパラメータを増やし、モデルを大きくする（過剰パラメータ化する）ことでテスト誤差が再び低下していく。<br>

従来の「汎化誤差が増加し始めたら学習を停止する」(Early Stopping: 早期停止) という手法の再考を促すことになった。<br>
<br>
<a href="data/Papers_DoubleDescent.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#BeningOverfitting">Bening Overfitting</a> (良性過学習)<br>
・<a href="#OverParameterized">Over-parameterized</a> (過剰パラメータ化)
</li>
<center><img src="data/images/DoubleDescent.svg"></center>

<br>

<li id="DPA">
<strong>DPA: Distributional Principal Autoencoders (分布主成分オートエンコーダ)</strong><br>
データの分布を正しく保ったまま再構成を行うことと、主成分分析（PCA）のような高い解釈性を持つエンコーディングを提供することを両立させた、新しいクラスのオートエンコーダー。<br>
<br><ul><li>
<strong>分布的に正しい再構成 (Distributionally Correct Reconstruction)</strong><br> 
従来のオートエンコーダーや PCA は、再構成時に平均二乗誤差（MSE）を最小化しようとするため、元のデータが持つ分散や裾の挙動といった分布特性が失われる傾向にあった。DPAは、潜在変数が与えられたときの条件付き分布を直接学習に組み込むことで、次元削減後も元のデータセットと同じ統計的分布を持つデータを再構成することを保証する。
</li><br><li>
<strong>主成分のような順序性 (Principal-Component-like Property)</strong><br>
PCA のように、潜在変数の各次元に「重要度の順序」を持たせることができる。<br> 
・次元の選択: 複数の潜在次元を同時に最適化することで、最初の数成分だけでデータの主要な変動を説明するような構造を学習する。<br>
・本質的次元の推定: データが特定の多様体上に存在する場合、その次元を超えた余分な潜在成分は「ノイズ」として扱われ、情報を持たなくなる。これにより、データの本質的な次元を自動的に特定できる可能性がある。
</li><br><li>
<strong>解釈性と物理的意味</strong><br>
・スコアとの関連性: DPAのエンコーダーのレベルセット（等値面）は、データ分布の「スコア」（対数密度の勾配）と密接に関係していることが理論的に証明されている。<br>
・物理応用: データがボルツマン分布に従う場合、この特性を利用して「最小自由エネルギー経路（MFEP）」などの科学的に重要な指標を単一のモデル学習から抽出できることが示されている。
</li></ul> 
<br>
●『Distributional Principal Autoencoders』(2024)<br> 
　分布主成分オートエンコーダ (DPA) を導入した。<br>
●『Distributional Autoencoders Know the Score』(2025)<br>
　Distributional Principal Autoencoder (DPA) がデータ分布のスタインスコアを学習し、データ多様体の内在次元を特定する能力を実証し、その理論的保証を提供する。
</li>

<br>

<li id="DRL">
<strong>DRL: Deep Reinforcement Learning (深層強化学習)</strong><br>
強化学習と深層学習（ディープラーニング）という2つの機械学習手法を組み合わせたもの<br>
<br>
<center><img src="data/images/DRL.svg"></center>
<br>
<a href="data/Papers_DRL.html">Papers</a><br>
<br>
●『1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities』(2025)<br>
　コンピュータビジョンや自然言語処理といった他のドメインが何千もの層にスケールアップすることで目覚ましい成功を収めているのに、<strong>なぜ RL モデルは浅いままなのか?</strong><br>
　著者らは、他の分野でスケーリングの成功の要となってきた<strong>自己教師あり学習が、RLで同様のブレイクスルーを達成するために欠けている要素である</strong>と提案している。<br>
　<strong>自己教師ありRLアルゴリズムと非常に深いネットワーク (最大1024層) を組み合わせることで</strong>、彼らは多様な移動、ナビゲーション、操作タスクにおいて<strong>2倍から50倍以上のパフォーマンス向上を実証</strong>している。<br>
<br>(関連項目)<br>
・<a href="#IL">IL: Imitation Learning (模倣学習)</a> ･･･ 概略図比較あり<br>
・<a href="#IRL">IRL: Inverse Reinforcement Learning</a> (逆強化学習) ポリシー ⇒ 報酬<br>
・<a href="#RL">RL: Reinforcement Learning</a> (強化学習) 報酬 ⇒ ポリシー
</li>

<br>

<li id="Dropout">
<strong>Dropout</strong><br>
ニューラルネットワークの学習時に、一部のニューロン（ノード）をランダムに無効化する正則化手法の一つ。<br>
<br>
<ul>
<li><strong>過学習の抑制</strong><br>
ディープニューラルネットワークは多くのパラメータを持つため、訓練データに過剰に適合し、未知のデータに対する汎化性能が低下しがちだった。Dropoutは、学習時にランダムに一部のニューロンとその接続を無効化することで、<strong><span style="color:magenta;">ニューロン間の過度な「共適応」を防ぎ</span></strong>、この問題を効果的に解決した。
</li><br><li>
<strong>アンサンブル学習の近似</strong><br>
Dropoutは、学習ごとに異なるサブネットワークを生成し、<strong><span style="color:magenta;">あたかも多数の異なるネットワークを学習しているかのような効果をもたらす</span></strong>。推論時には、すべてのニューロンを使いつつ、出力に重み付けを行うことで、これらのサブネットワークの予測を平均化するような効果を得られ、計算コストを抑えながらアンサンブル学習と同等の性能を発揮した。
<br>
<a href="data/Papers_Dropout.html">Papers</a>
</li>
</ul>
<br>(関連項目)<br>
・<a href="#EnsembleMethod">Ensemble Method (アンサンブル法)</a><br>
・<a href="#Regularization">Regularization (正則化)</a>
</li>
<br>

<li id="DunningKrugerEffect">
<strong>Dunning-Kruger Effect (ダニング・クルーガー効果)</strong><br>
能力の低い人が、自分の能力を過大評価してしまう認知バイアスの一種。<br>
<br>
AIモデルもこの効果を起こす。<br>
・コード モデルはダニング・クルーガー効果の影響を受けるか ?(2025)<br>
・大規模言語モデルは自信過剰になり、エラーを増幅させる(2025)<br>
人間もAIの影響を受けてこの効果が変化する。<br>
・AIはあなたを賢くするが、賢者にはしない(2025)<br>
<br>
<a href="data/Papers_Dunning-KrugerEffect.html">Papers</a>
</li>
<br>
<center><img src="data/images/Dunning-Kruger_Effect_Curve.svg"></center>
<br>
●『Science Abridged Beyond the Point -of- Usefulness』(2017)<br>
　　(科学：有用性を超えた要約)<br>
<br>
　　自分がダメだと思うなら、おそらくダメだろう。<br>
　　これは「自己成就予言（self-fulfilling prophecy）」と呼ばれるものだ。<br>
　　自分がすごいと思うなら、おそらくダメだろう。<br>
　　これは「ダニング＝クルーガー効果」と呼ばれるものだ。<br>
　　ここから導き出される明白な結論があるのだが、あなたはおそらくそれを見逃している。<br>

</ul></div></p>


<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="E">E</h2>
<p>
<div class="styleBullet">
<ul>

<li id="EMA">
<strong>EMA: Exponential Moving Average (指数平滑移動平均)</strong><br> 
直近のデータに重みを置いて算出する移動平均の手法。金融取引のテクニカル分析のほか、ディープラーニングなどのデータ分析でも活用される。<br>
<br>
●『Exponential Moving Average of Weights in Deep Learning: Dynamics and Benefits』(2024)<br>
<center><img src="data/images/EMA.svg"></center><br>
ResNet-18上のCIFAR-100。EMA vs SGDベースライン、および学習率(η)。EMAはモメンタムSGDを凌駕し、初期から良好なパフォーマンスを示していることがわかる。EMAはエポック150でピークに達した後、低下する。　
</li>

<br>

<li id="EmbodiedAI">
<strong>Embodied AI(身体化AI)</strong><br>
物理的な身体 (ロボットやデバイス) を持ち、実世界 (フィジカル空間) と相互作用しながら自律的に学習・行動する人工知能のこと。<br>
<br>
Physical AI (フィジカルAI) とほぼ同義だが, 「研究・学習のアプローチ(※)」を指すのが Embodied AI であり、「産業・ビジネスとしての実装形態」を指すのが Physical AI。<br>
<br>
※ <strong>身体性(Embodiment)</strong>　知能は身体と環境との相互作用から生まれるという哲学・理論がベース。AIが自分の「体」を通じて経験し、学習して賢くなるプロセスを指すことが多い。 
</li>

<br>

<li id="EmbodiedCognition">
<strong>Embodied cognition（身体化された認知）</strong><br>
心と認知能力が、脳だけでなく体全体の物理的な経験や感覚と深く結びついているとする認知科学の理論。「体があるからこそ、特定の方法で物事を考え、感じる」というアプローチ。<br>
<br>
<strong>身体の役割</strong>　思考や学習は、抽象的な脳内プロセスだけでなく、身体の構造（手足の動かしやすさ、姿勢、感覚器官など）に影響を受けたり、それによって形成されたりするという考え方。<br>
<strong>物理的経験の重要性</strong>　例えば、重いものを「持つ」経験が「重要性」や「深刻さ」といった抽象的な概念の理解に影響を与えたり、温かい飲み物を持つことが他者への信頼感に繋がったりする、といった研究結果がある。<br>
<strong>環境との相互作用</strong>　認知は、身体が周囲の環境とどのように相互作用するかというダイナミックなプロセスの中で生まれる。 <br>
<br>
●『ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction』(2025)<br>
・非身体的な方法で訓練された現代の視覚言語モデル(VLM)は、身体性認知の兆候を示すか?<br>
・視覚的質問応答(VQA)形式における自己中心的相互作用から、身体性認知を世界モデリングとして評価するベンチマークであるENACTを紹介する。<br>
・2つの補完的なシーケンス並べ替えタスク、<strong>順世界モデル</strong>（行動が与えられた場合にシャッフルされた観測結果を再構成する）と<strong>逆世界モデル</strong>（観測結果が与えられた場合にシャッフルされた行動を再構成する）から構成される。<br>
・これらのタスクを解決するには、暗黙的に、部分的に観察可能な自己中心的な入力からの具体化された認知アフォーダンス認識、行動効果推論、具体化された意識、および対話型の長期的記憶に中心的な機能が要求される。<br>
<br>(関連項目)<br>
・disembodied intelligence (身体のない知性), disembodied AI（身体のないAI）<br>
　物理的な身体を持たずに存在する、あるいは機能する知能, AI。<br>

</li>

<br>

<li id="Empowerment">
<strong>Empowerment (エンパワーメント)</strong><br>
エージェントが環境に対して及ぼしうる「潜在的な影響力」の大きさを示す。エージェントの「行動（Actuation）」と、その結果として得られる「感覚入力（Perception）」の間の相互情報量（Mutual Information）の最大値（チャネル容量）として定義される。<br>
外部からの報酬が与えられない環境でも、エージェントが自律的に学習・探索を行うための「内発的動機づけ（Intrinsic Motivation）」のメカニズムとして利用される。<br>
<br>
●『Empowerment: A Universal Agent-Centric Measure of Control"』(2005)<br>
　動物の行動やゲームなどの例に着想を得て、特定のタスクに依存しない普遍的な効用関数として「エンパワーメント」を提案した。<br>
●『Plasticity as the Mirror of Empowerment』(2025)<br>
　(可塑性：エンパワーメントの鏡)<br>
　人工知能においては、エンパワーメントはエージェントが観測可能な未来にどれだけ影響を与えられるかを定量化し、可塑性はエージェントがその経験によってどれだけ形成され得るかを測定する。可塑性が「エンパワーメントの鏡」として機能すると提唱し、エージェントが影響を与える能力と影響を受ける能力との間に深い対称性があることを示唆している。<br>
<center><img src="data/images/Empowerment.svg"></center>
</li>

<br>

<li id="EnsembleMethod">
<strong>Ensemble Method (アンサンブル法)</strong><br>
複数の機械学習モデルを組み合わせて、単一のモデルよりも高い予測精度や安定性を目指す手法。<br>「三人寄れば文殊の知恵」の機械学習版。<br>
複数の学習器を組み合わせた方が単一の学習器より精度が高くなることは昔(1960年代かもっと前)から知られていたが、定式化されたのが 1980 年代で、証明され, アルゴリズムができたのは 1990 年代になってから。<br>
⇒ <a href="#PAC">PAC Learning: Probably Approximately Correct Learning (確率的で近似的に正しい学習)</a><br>

<br>
<center><img src="data/images/EnsembleMethod.svg"></center>
<ul>
<li>■<strong>Boosting (ブースティング)</strong><br>
複数のモデルを逐次的に学習させてモデルのアンサンブルを構成する方法。<br>
乱択(ランダムな選択)と同程度の精度の低い識別器を出力する弱学習器を, 高精度な識別器を出力する強学習器へとブースト(昇格)させる。<br>
<br>
<center><img src="data/images/Boosting.svg"></center>
</li>
<br>
<li>■<strong>Bagging (バギング)</strong><br>
複数のモデルを並行して学習させる方法。<br>
データセットから重複を認めて学習データをランダムに選択する <strong><u>B</u></strong>ootstrap法 と, それぞれの学習データで学習させた識別器の推定を集約する <strong><u>agg</u></strong>regat<strong><u>ing</u></strong> をつないで bagging。<br>
<br>
<center><img src="data/images/Bagging.svg"></center>
</li>
<br>
<li>■<strong>Stacking</strong></br>
複数の弱学習器の予測結果を、別の学習器（メタモデル）の入力として使用し、最終的な予測を行う手法。<br>
・複数の異なるモデル (決定木、SVMなど) をベースモデル学習器として訓練する。<br>
・複数のモデルの出力をどのように組み合わせるかをメタモデルで学習する。<br>
<br>
<center><img src="data/images/Stacking.svg"></center>
</li>
<br>
<li>■<strong>DNN: Deep Neural Network</strong><br>
ブースティングは, <strong><span style="color:magenta;">ニューラルネットワークに隠れユニットを徐々に追加することで, 個々のニューラルネットワークをアンサンブルとして解釈して適用されてきた</span></strong>(Bengio et al.,2006a)<br>
　：<br>
ドロップアウトは, 非常に多くの大規模なニューラルネットワークに対してバギングを実用的にする方法であると考えられる。バギングには複数のモデルの訓練と各テスト事例に対する複数のモデルの評価が必要である。これは, 各モデルが大規模なニューラルネットワークである場合に, そのようなモデルの訓練や評価は実行時間とメモリの点でコストがかかるため, 実用的ではないと考えられる。5個から10個のニューラルネットワークから構成されるアンサンブルを使うことは一般的であり, Szegedy et al.(2014a)では6個を使ってILSVRCで優勝しているが, それ以上多くなると急激に扱いづらくなってしまう。<strong><span style="color:magenta;">ドロップアウトによって, 指数関数的に多くのニューラルネットワークを集めたアンサンブルの訓練と評価のための, 安価な近似が得られる。</span></strong><br>
[書籍]『Deep Learning』Ian Goodfellow 他<br>

</li>
</ul>
<br>(関連項目)<br>
・<a href="#PAC">PAC Learning: Probably Approximately Correct Learning (確率的で近似的に正しい学習)</a><br>
・<a href="#ModelMerge">Model Merge</a> (モデルマージ)<br>
・<a href="#ModelSoup">Model soups (モデルスープ)</a> ･･･ Ensemble Method は推論時に複数のモデルを動作させるが, モデルスープは複数のモデルの重みを加重平均した単一のモデルを動作させる。<br>
・<a href="#Dropout">Dropout</a>
</li>

<br>

<li id="EoE">
<strong>EoE: Era of Experience (経験の時代)</strong><br>
AI（人工知能）が人間から与えられたデータだけでなく、AI自身の「経験」を通して自律的に学習・進化していくという、AI研究における新たな方向性を示す概念。<br>
Google DeepMind の著名な研究者 David Silver と, 強化学習の創始者のひとり Richard S. Sutton が2025年4月に発表した論文『Welcome to the Era of Experience』で提唱された。<br>
<br>
<center><img src="data/images/EoE.svg"></center>
<br>
●『Welcome to the Era of Experience』(2025)<br>
　論文は<a href="https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf">こちら</a>, 機械翻訳は<a href="https://boyoyon.github.io/HTMLs_translated_to_Japanese/2025_Welcome%20to%20the%20Era%20of%20Experience/2025_Welcome%20to%20the%20Era%20of%20Experience.html">こちら</a><br>
<br>
　<strong><span style="color:magenta;">例えば、あるエージェントが5,000年前の人間の思考と専門家の回答を用いて推論するように訓練されていたとしたら、物理的な問題についてアニミズムの観点から推論していたかもしれません。</span></strong><br>
→ 人間を教師にしていることがネックになる･･･<br>
<br>
データは、エージェントが強くなるにつれて継続的に改善される方法で生成されなければなりません。静的なデータ合成手順は、すぐに追い越されてしまいます。これは、エージェントが自身の経験、つまり環境との相互作用によって生成されるデータから継続的に学習できるようにすることで実現できます。<br>

<br>

●『Agent Learning via Early Experience』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2510.08558">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.08558v1">こちら</a><br>
<br>
　「早期経験」パラダイムを導入する。これにより、言語エージェントは、<strong><span style="color:magenta;">明示的な報酬シグナルを必要とせずに</span></strong>、環境との自身の相互作用から学習することができる。<br>
・このパラダイムでは、2つの戦略を研究する。<br>
　(1) Implicit world modeling (暗黙的世界モデリング) <br>
　　収集された状態を使用して環境ダイナミクスにポリシーを根拠付ける。<br>
　(2) Self-reflection (自己反省)<br>
　　エージェントは最適ではない行動から学習し、推論と意思決定を改善する。<br>
<br>
●『The Missing Reward: Active Inference in the Era of Experience』(2025)<br>
　(失われた報酬: 経験の時代の能動推論)<br>
　論文は<a href="https://arxiv.org/abs/2508.05619">こちら</a></br>
<br>

　1900年、ケルビン卿は、地平線上の「二つの小さな雲」を除けば物理学はほぼ完成しているように見えると指摘しました。これらの雲（黒体放射とマイケルソン・モーリーの実験）は、最終的に量子力学と相対性理論を通じて私たちの理解に革命をもたらしました。今日のAIも、同様の雲に直面しており、それは私たちの現在のパラダイムにおける些細な調整ではなく、根本的な限界を示唆しています。<br>
<br>

<div class="styleBullet">
<ul><li>

<strong>第一の雲: リソースの飽和 - 規模の物理的限界</strong><br>
・質の高い英語のテキストは10年以内に枯渇すると予測されている。<br>
・スパムが増え、合成コンテンツが増え、真の人間の知識は減少する。<br>
・モデルの能力：倍増 ⇒ エネルギーは指数的に増加, 性能は対数的増加。
</li>
<br>
<li>
<strong>第二の雲：外部化された認知 - 人間の隠れた依存関係</strong><br>
・「自律型」AIシステムは、舞台裏で稼働する膨大な人間の認知ネットワークに依存している。<br>
　(<strong><span style="color: magenta;">判断、適応、そしてエラー修正が人間の作業員にアウトソーシングされる</span></strong>)<br>
・モデルがより洗練されるにつれて、アライメント(*)にはより繊細な人間の判断が必要となり、専門知識の必要性がますます高まる。<br>
　* AIの出力を人間の倫理観や価値観, 嗜好に合わせること。<br>
・人間の価値観は静的な目標ではなく、動的で文脈依存的なプロセスであり、どんなにラベル付けしても完全に捉えることはできない。<br>
　⇒エンジニアは報酬関数に絶えずパッチを当て、アノテーターは嗜好データセットを果てしなく改良し、安全チームは新たな故障モードを絶えず追いかける。<br>
　<strong><span style="color: magenta;">これは知能ではなく、アルゴリズムのカーテンの背後から人間が糸を操る精巧な人形劇なのだ。</span></strong><br>
　フェイフェイ・リーが「人工知能には人工的なものは何もない」と言った通りだ。<br>
</li>
</ul>
</div>
<br>
AIF: Active Inference (能動推論)は<strong><span style="color: magenta;">外部報酬信号を自由エネルギー最小化への内発的動機に置き換えることで、エージェントが統一されたベイズ的目的を通して探索と活用を自然にバランスさせることができる</span></strong>と提案する。
</li>

<br>

<li id="EPE">
<strong>EPE: Expected Prediction Error (期待予測誤差)</strong><br>
エージェントが予測した価値（将来得られる報酬の期待値）と、実際に得られた結果（報酬および次の状態の価値）との間のズレ（誤差）の期待値を指す。<br>
・TD誤差 (Temporal Difference Error) の期待値<br>
　TD学習において、予測の修正量を決定する中核的な指標<br>
・内在的報酬としての活用<br>
　未知の環境を探索するために、この予測誤差 (またはその期待値) を「好奇心(内在的報酬)」として利用する手法がある。<br>
<br>
●『The Elements of Statistical Learning』(2001)<br>
・統計的機械学習の「聖書」とも呼ばれる著書。<br>
・二乗誤差損失や分類誤差などの条件下で、未知のテストデータに対してモデルがどの程度の誤差を出すか（期待値）を「Expected Prediction Error」として定義した。<br>

<br>(関連項目)<br>
・<a href="#GAE">GAE: Generalized Advantage Estimation</a> (汎用アドバンテージ推定)</br> 
<br>

<li id="Epiplexity">
<strong>Epiplexity (エピプレキシティ)</strong><br>
計算能力に制限のある観測者がデータからどれだけの情報を学習できるかを定式化した概念。<br>
<br>
●『From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence』(2026)<br>
　(エントロピーからエピプレキシティへ：計算量制約のある知能のための情報の再考)<br>
　解説は<a href="https://www.alphaxiv.org/ja/overview/2601.03220">こちら</a>
</li>

<br>

<li id="EpisodicMemory">
<strong>Episodic Memory (エピソード記憶)</strong><br>
個人の過去の経験や出来事を、その時の状況（いつ、どこで、誰が、何を）や感情とともに記憶する能力。一般的な知識を記憶する「意味記憶」とは区別される。<br>
<br>
Prediction errors disrupt hippocampal representations and update episodic memories (2021)<br>
(予測エラーは海馬の表現を混乱させ、エピソード記憶を更新する)<br>
予測誤差に直面すると海馬の記憶表現が中断され、その後の記憶更新に関連することが、fMRIを用いた研究で示唆されている。この現象は前脳基底部の活動と関連し、神経調節物質が海馬の処理を調整している可能性が指摘されている。<br>
<br>
『入力トークンを「ベイジアン・サプライズ」（予測外の情報）に基づいてイベント単位に分割する。<strong><span style="color:magenta;">人間が予期せぬ出来事によって新しいエピソードを記憶するように、LLMも予測誤差が大きい箇所でイベント境界を認識し、記憶を形成する。</span></strong>』Human-like Episodic Memory for Infinite Context LLMs (EM-LLM)(2024)<br>
<br>
<a href="data/Papers_EpisodicMemory.html">Papers</a>
</li>

<br>

<li id="EQA"><strong>EQA: Embodied Question Answering</strong><br>
物理的な身体（またはシミュレーション上の身体）を持つAIエージェントが、自律的に環境を探索し、ユーザーの質問に回答するタスクや研究分野。<br>
<br>
<strong>能動的な探索</strong>　エージェントは「冷蔵庫の中に何がある？」といった質問に対し、まず冷蔵庫のある場所まで移動し、扉を開けて中を確認するという一連の行動（ナビゲーション）を行う。<br>
<br>
<strong>マルチモーダルな理解</strong>　視覚情報（カメラ画像）、言語情報（質問）、および自身の位置や動作（運動系）を統合して処理する。
</li>

<br>

<li id="ERM">
<strong>ERM: Empirical Risk Minimization (経験的リスク最小化)</strong><br>
モデルの学習時に「経験的リスク（手元の学習データセット上での平均誤差）」を最小化するようにパラメータを調整する、というアプローチ。<br>
今となっては当たり前すぎて何とも言えないが, たまに出てくるので覚えておこう･･･<br>
・経験的：理論や仮説から導かれた訳ではない･･･<br>
・リスク：限られたデータからの推定量である, ということらしい<br>
<br>
ERMではない学習アプローチはあるのか?<br>
・ベイズ学習：単一目標の最小化(勾配降下)ではない。<br>
・GAN: 単一の目的関数ではなく、生成器と識別器のミニマックスゲームとして定式化される<br>
・メタ学習: 単一のタスクに対する経験リスクを最小化ではない<br>
・PAC学習:　ERMを包含する、より広範な学習理論。汎化性能も改善したい。

</li>

<br>

<li id="ES">
<strong>ES: Evolution Strategies (進化戦略)</strong><br>
生物の進化プロセス（突然変異や自然淘汰など）を模倣することで最適化問題を解決する確率的アルゴリズムの一種。<br>
<br>
●『Optimierung technischer Systeme nach Prinzipien der biologischen Evolution』(1970)<br>
　 (生物進化の原理に基づく技術システムの最適化)･･･博士論文<br>
　『Evolutionsstrategie – Optimierung technischer Systeme nach Prinzipien der biologischen Evolution』(1973)<br>
　　博士論文を書籍化したもの。pdf は <a href="https://gwern.net/doc/reinforcement-learning/exploration/1973-rechenberg.pdf">こちら</a><br>
<br>
●『Evolution Strategies as a Scalable Alternative to Reinforcement Learning』(2017)<br>
・Q 学習や方策勾配法などの一般的な MDP ベースの RL 手法の代替としてブラックボックス最適化アルゴリズムの一種である進化戦略 (ES) を提案。<br>
　OpenAI のこの論文の実装を OpenES と呼ぶことがある。<br>
<br>
●『Evolution Strategies at the Hyperscale』(2025)<br>
・進化戦略(ES)は, バックプロパゲーションとは異なり<br>
　〇 微分不可能な目的関数を処理できる<br>
　〇 ノイズの多いフィードバックで動作する<br>
　〇 高価な勾配集約不要<br>
　× フルランクのパラメータ摂動を生成することに伴う法外なメモリと計算コスト<br>
⇒ EGGROLL:Evolution Guided General Optimization via Low-rank Learning (ランク学習を介した進化誘導型一般最適化) を導入<br>
　フルランク行列 \(E\in\mathbb{R}^{m×n}\) をサンプリングする代わりに小さな2つの行列 \(A\in\mathbb{R}^{m×r}\) と \(B\in\mathbb{R}^{n×r}\) をサンプリング。<br>
　\(r \ll \min(m,n), \frac{1}{\sqrt{r}}AB^T\) を摂動とすることで, 計算コスト, メモリ要件を削減する。<br>
<br>
<center><img src="data/images/ES.svg"></center>
<br>
<center>強化学習(PPO), OpenESとの比較</center>
<br>
<center><img src="data/images/ES2.png"></center>
<br>(関連項目)<br>
・<a href="#LoRA">LoRA: Low-rank adaptation of LLM</a> (低ランク適応)  ･･･ 低ランク行列活用が似ている
</li>

<br>

<li id="Exploration-ExploitationDilemma">
<strong>Exploration-Exploitation Dilemma/Tradeoff (探索と利用のジレンマ/トレードオフ)</strong><br>
不確実な状況下での意思決定において、新しい可能性を模索する「探索（Exploration）」と、すでに知っている最良の選択肢を活用して確実な利益を得る「利用（Exploitation）」という、相反する2つの行動間のバランスを取るのが難しい、という問題。<br>
(お気に入りのいつもの店にするか, 新しい店を開拓するか･･･)<br>
<br>
■Mult-Armed Bandit Problem (多腕バンディット問題)<br>
・複数台のスロットマシンがある状況で、限られた試行回数の中で、報酬(コイン)の総額を最大化するための最適な選択戦略を学習する問題。<br>
・スロットマシンを米俗語でOne-Armed Bandit(片腕の盗賊)というので、複数のスロットマシンを Multi-Armed(多腕)と表現している。<br>
・greedy, ε-greedy, UCB(Upper Confidence Bound), optimism in the face of uncertainty(不確かな時は楽観的に), などの戦略がある。
</li>

<br>

<li id="EvolutionaryProgramSynthesisSystems">
<strong>Evolutionary program synthesis systems (進化的プログラム合成システム)</strong><br>
生物の進化（自然淘汰、突然変異、組み換えなど）のプロセスから着想を得た進化的アルゴリズム（Evolutionary Algorithms）を応用し、指定された要件を満たすコンピュータープログラムを自動的に生成 (合成) しようとする人工知能（AI）およびソフトウェア工学の分野横断的なシステム。<br>
<br>
<strong>AlphaEvolve</strong><br>
　●『AlphaEvolve: A coding agent for scientific and algorithmic discovery』(2025)<br>
　・科学的・アルゴリズム的発見のためにLLMを使用してコードを反復的に進化させる手法を提示した。<br>
<br>
<strong>OpenEvolve</strong><br>
　・DeepMind の AlphaEvolve の主要なコンセプトを再現したオープンソース実装のフレームワーク<br>
　　<a href="https://github.com/algorithmicsuperintelligence/openevolve">Github</a><br>
　●『Even with AI, Bijection Discovery is Still Hard: The Opportunities and Challenges of OpenEvolve for Novel Bijection Construction』(2025)<br>
　　(AIを用いても、全単射発見は依然として難しい：新しい全単射構築のためのOpenEvolveの機会と課題)<br>

<br>
<strong>ShinkaEvolve</strong><br>
　・Sakana AIによって開発されたフレームワークで、LLMと進化的アルゴリズムを組み合わせ、特に効率性（サンプル効率）とオープンエンドな探索に焦点を当てている。<br>
　●『ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution』ShinkaEvolve(2025)<br>
<br>
<strong>ThetaEvolve</strong><br>
●『ThetaEvolve: Test-time Learning on Open Problems』(2025)<br>
・AlphaEvolveは新たな境界を達成するために最先端のLLMのアンサンブルに依存しており、モデルが進化戦略を内部化することができない純粋な推論システムである。<br>
・本稿では、AlphaEvolve を簡素化・拡張し、コンテキスト内学習と強化学習（RL）の両方をテスト時に効率的にスケーリングするオープンソースフレームワークである ThetaEvolveを紹介する。

</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="F">F</h2>
<p>
<div class="styleBullet">
<ul>
<li id="FAI">
<strong>FAI: Friendly AI (友好的な人工知能)</strong><br>
人間に対して悪影響を与えることなく、良い影響を与えるように設計された、倫理的な AGI(汎用人工知能) を指す仮説的な概念。<br>
<a href="https://intelligence.org/files/CFAI.pdf">Creating Friendly AI 1.0</a> (2001)で概念が提唱された。<br>
<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a> ･･･ Friendly AIを実現するための技術的課題を解決する研究分野
</li>

<br>

<li id="FBFF">
<strong>Feedback control (フィードバック制御) / Feedfoward control (フィードフォワード制御)</strong><br>
<br>
<strong>フィードバック制御</strong><br>
・リアルタイムの感覚入力 (視覚など) を使用して、動作中に調整を行い、エラーを修正する。<br>
・例: 歩行を習得する幼児は、視覚と固有受容覚のフィードバックを用いて各ステップを調整する。<br>
<br>
<strong>フィードフォワード制御（適応）</strong><br>
・<strong><span style="color:magenta;">内部モデルと過去の経験を使用して動きを予測および事前に計画</span></strong>し、継続的な修正なしでより速くスムーズな動作を可能にする。<br>
・例：成人は意識的に各足の位置を監視することなく、楽に（ほぼ「オープンループ」で）歩く。<br>
<br>
●『The control of movement gradually transitions from feedback control to feedforward adaptation throughout childhood』(2025)<br>
　(運動の制御は、小児期を通じてフィードバック制御からフィードフォワード順応へと徐々に移行する)<br>
<br>
　<strong>年少児（例：3〜8歳）</strong><br>
　　フィードバックに頼り、新しい状況にゆっくりと適応し、複雑で急速な調整に苦労する。<br>
<br>
　<strong>年長児 (例: 9 〜 14 歳)</strong><br>
　　運動適応が大幅に向上し、フィードフォワード戦略が改善されるが、完全な成熟は青年期まで続くことがある。<br>
<br>
この移行には、<strong><span style="color:magenta;">より優れた内部モデルと予測能力の開発</span></strong>が含まれ、瞬間的な視覚修正への依存が減少する。 <br>
<br>
●『Using reinforcement learning to probe the role of feedback in skill acquisition』(2025)<br>
　(強化学習を用いてスキル獲得におけるフィードバックの役割を探る)<br>
<br>
・次のゲームを考えてみましょう。まず、紙切れをくしゃくしゃにしてボール状にし、数メートル先に投げます。ボールがどこに落ちるかを注意深く観察し、次に目を閉じて、ボールがあると思われる場所に向かって歩き、覗き込まずに拾おうとします。
<center><img src="data/images/FeedbackControl.png"></center><br>
手を伸ばすと、ほんの少しだけずれていることに気づくことがよくあります。では、一度だけ覗き見が許されたとしましょう。おそらくいつも成功するでしょう。この遊び心のある実験から、2つの観察結果が浮かび上がります。第一に、視覚的なフィードバックがなくても、私たちは目標にかなり近づくことができます。第二に、最小限の視覚的なフィードバックがあれば、私たちは確実に課題を完了することができます。これらの観察結果は、この課題で活用される多くのスキルが、私たちが利用できるフィードバックよりも少ないフィードバックしか必要としないことを示唆しています。<br>
<br>
高性能なポリシーを学習するために必要な情報は、それを実行するために必要な情報よりも大幅に豊富である可能性があることを示唆しています。
最後に、これらの調査結果について説明し、学習中に豊富なフィードバックを活用しながら、パフォーマンスの最後の 1 マイルを回復する場合を除いて実行時にそれを選択的に無視するアーキテクチャを動機付けます。

</li>

<br>

<li id="FEP">
<strong>FEP: Free Energy Principle (自由エネルギー原理)</strong><br> 
知的なシステム（生物やAIなど）の行動や知覚、学習の根底にある基本的な原理を説明する神経科学および理論物理学の枠組み。<br>
英国の計算神経科学者である Karl Friston によって提唱された。FEPは、「すべての自己組織化システムは、その Variational Free Energy (変分自由エネルギー)の長期的平均値を最小化するように振る舞う」と主張。<br>
※ ヒントンの初期の研究（ヘルムホルツマシン, ボルツマンマシンにおけるエネルギー関数）から大きな影響を受けているとされる。<br>
●『The wake-sleep algorithm for unsupervised neural networks』Helmholtz machine (1995)<br>
　「奇妙な偶然ですが、知覚システムが生成モデルを使用するという考えはヘルムホルツによって提唱されたため、式5の自由エネルギーを最小化することによって生成モデルをデータに適合させる任意のニューラルネットワークを 「ヘルムホルツマシン」と呼びます。･･･」<br> 

<br>
・<strong>Surprisal (驚き) の最小化</strong><br>
　システムが予測できないような稀な事象(サプライズ)の発生確率を最小限に抑えることが目的<br>
<br>
・<strong>変分自由エネルギー</strong><br>
　「驚き」の上限値（代理指標）として機能する数学的な量。FEPは、驚きそのものを直接計算するのは難しいため、代わりにこの自由エネルギーを最小化することを目指す。<br>
<br>
・<strong>Generative Model (生成モデル)</strong><br>
　システムは、感覚入力がどのように生成されているかについての内部的な「世界モデル」を持っている。<br>
<br>(関連項目)<br>
・<a href="#ActiveInference">Active Inference</a> (能動推論)
</li>

<br>

<li id="FMP">
<strong>Flat Manifold Problem (平坦多様体問題)</strong><br>
継続学習において、古いタスクで構築されたデータ多様体が、新しいタスクを学習する過程で「平坦化」または破壊され、その結果として以前の知識が失われる（壊滅的忘却）現象。<br>
<br>
●『The Geometry of Abstraction: Continual Learning via Recursive Quotienting』(2025)<br>
　(抽象化の幾何学：再帰的商算による継続的学習)<br>
　ニューラルアーキテクチャ内のトークンが、時間多様体内の離れた点を橋渡しする極端に正の曲率を持つ領域であるワームホールとして物理的に実現可能であることを明らかにした。我々の枠組みは、システムが経験多様体を能動的に折り畳み、過去の出来事の線形探索を再帰的商位相による測地線的近道に置き換える場合にのみ、<strong><span style="color:magenta;">固定次元で無制限の推論が達成可能であることを実証する</span></strong>。<br>
<br>(関連項目)<br>
・<a href="#CatastrophicForgetting">Catastrophic Forgetting</a> (破局的忘却)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)
</li>

<br>

<li id="FlatMinima">
<strong>Flat minima hypothesis (平坦な最適解空間仮説)</strong><br>
機械学習モデル、特に深層学習モデルの訓練において、損失関数の「平坦な」最小値に収束したモデルは、未知のデータに対する汎化性能が「鋭い」最小値に収束したモデルよりも優れている、という仮説。<br>
・Dinh et al. (2017) らは、モデルのパラメータを再パラメータ化（重みのスケーリングなど）することで、汎化性能を変えずに最小値の鋭さを人為的に操作できることを示し、この仮説に疑問を投げかけた。<br>
・スケール不変な「平坦さ」の定義が提案されたり、平坦さの定義自体が再考されたりする研究が進められている。<br>
<center><img src="data/images/FlatMinima.png"></center>
<br>
<a href="data/Papers_FlatMinimaHypothesis.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)</br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)<br>
・<a href="#DataAugmentation">Data Augmentation</a> (データ拡張)
</li>

<br>

<li id="FluencyIllusion">
<strong>Fluency Illusion（流暢性の錯覚）</strong><br>
学習した内容が「スムーズに頭に入る」という感覚を、そのまま「その内容を完全に習得した」と誤解してしまう心理現象。<br>
<br>
<strong>なぜ起こるのか</strong>　脳は、処理が簡単な（流暢な）情報を「正しい」「価値がある」「覚えている」と判断しやすい性質を持っている。受動的な学習（読むだけ、聞くだけ）は脳への負荷が低いため、この「流暢性の錯覚」が非常に起きやすくなる。<br>
<br>
<strong>対策</strong>　この錯覚を打破するには、あえて脳に負荷をかける「アクティブ・ラーニング（能動的学習）」が有効と言われている。<br> 
※ このActive Lerning は 機械学習におけるActive Learningではなく, 教育学におけるもの <br>
・想起（テスト）: 本を閉じて、学んだ内容を何も見ずに書き出す。<br>
・自己説明: 学んだ内容を、他人に教えるように自分の言葉で説明してみる。<br>
・インターリービング: 同じ内容を繰り返すのではなく、異なるトピックを混ぜて学習し、脳が安易に「慣れる」のを防ぐ。<br>
<br>
<strong>AIが起こす「流暢性の錯覚」(ハルシネーション)</strong>　AI（特に大規模言語モデル）は、確率的に「もっともらしい続きの言葉」をつなげる仕組みであるため、「内容は間違っているが、文章としては完璧で流暢」な回答を生成することがある。<br> 
・AIには人間のような「真実かどうかの内省」や「実体験に基づいた理解」がない。<br>
・統計的に「賢そうな回答パターン」を再現することに長けているため、論理が破綻していても表面上は整った説明(ハルシネーション)を出力してしまう。<br>
<br>
<strong>人間がAIに対して抱く「流暢性の錯覚」</strong>　AIの回答があまりにもスムーズで自信に満ちているため、それを受け取る人間側が「このAIは深い知能を持っている」「この情報は正しい」と誤認してしまう現象。 <br>
<br>
●『The critical importance of retrieval for learning』(2008)<br>
　学習において情報を記憶から「思い出す」行為がいかに重要かを科学的に示し、その後の教育・心理学分野に大きな影響を与えた。この研究は、単純な再読（再学習）よりも、テスト形式で記憶から情報を引き出す「想起練習」の方が、長期的な学習定着に劇的な効果があることを実証した。
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="G">G</h2>
<p>
<div class="styleBullet">
<ul>

<li id="GAE">
<strong>GAE: Generalized Advantage Estimation (汎用アドバンテージ推定)</strong></br>
強化学習の方策勾配法において「アドバンテージ関数（Advantage function）」を効率的に推定するための手法。<br>
・TD法 (低分散・高バイアス) とモンテカルロ法 (不偏・高分散) の間のバランスを、ハイパーパラメータ \(\lambda \) (ラムダ) を用いて柔軟に調整できる。<br>
・\(\lambda=0\): 1ステップのTD誤差のみを使用し、バイアスは高くなりますが分散は最小限になりる。<br>
・\(\lambda=1\): 全ステップの報酬を考慮するモンテカルロ法に相当し、バイアスはなくなりますが分散が非常に大きくなる。<br>
・実用的な値: 一般的に \(\lambda =0.95\) 前後の値が用いられ、バランスの取れた推定が行われる。<br>
・PPO (Proximal Policy Optimization) や TRPO (Trust Region Policy Optimization) といった、現代の主要な Actor-Critic アルゴリズムの基盤技術として広く採用されている。<br> 
<br>
●『High-dimensional continuous control using generalized advantage estimation』(2015)<br>
・GAE: Generalized Advantage Estimation を導入した論文<br>
<br>(関連項目)<br>
・<a href="#EPE">EPE: Expected Prediction Error (期待予測誤差)</a>
</li>

<br>

<li id="GAIA">
<strong>GAIA（General AI Assistants）ベンチマーク</strong><br>
AIアシスタントやAIエージェントの「汎用的な知能と実用性」を測定するための評価指標。<br>
2024年に発表されて以来、LLM（大規模言語モデル）単体の性能ではなく、AIが自律的にツールを使い、複雑なタスクを完結できるかを測る基準として重要視されている。<br>
・学術的な知識（暗記など）ではなく、ブラウジング、画像・音声の処理、コーディング、外部ツールの活用など、現実世界の多段階的な推論を必要とする問題で構成されている。466の現実世界シナリオ問題。<br>
・3段階の難易度: タスクは難易度順にLevel 1（5ステップ未満）からLevel 3（高度な計画性とツール統合が必要）まで分かれている。<br>
<br>
●『GAIA: a benchmark for General AI Assistants』(2023)<br>
<br>
<a href="https://huggingface.co/spaces/gaia-benchmark/leaderboard">GAIA Leaderboard(ランキング)</a>
<li>

<br>

<li>
<strong>GAN:Generative Adversarial Network (敵対的生成ネットワーク)</strong><br>
生成ネットワークと識別ネットワークの2つのニューラルネットワークを競合させながら学習させることで、現実世界に存在するデータと区別がつかないほどの新しいデータを生成するAI技術。<br>
<br>
<a href="data/Papers_GAN.html">Papers</a>
</li>

<br>

<li id="GDPO">
<strong>GDPO: Group reward-Decoupled Normalization Policy Optimization (グループ報酬分離正規化ポリシー最適化)</strong><br>
複数の報酬信号を「分離（Decouple）」して正規化することで、特定の信号が他をかき消すのを防ぎ、精度と制約遵守の両立を図るポリシー最適化手法。<br>
<br>
●『GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization』(2026)<br>
　(GDPO: 複数報酬強化学習最適化におけるグループ報酬分離正規化ポリシー最適化)<br>
<br>
<center><img src="data/images/GDPO.svg"></center>
<br>(関連項目)<br>
・<a href="#RewardSignalCollapse">Reward Signal Collapse (報酬信号崩壊)</a>
</li>

<br>

<li id="GenerativeModel">
<strong>Generative Model (生成モデル)</strong><br>
学習したデータの特徴やパターンを理解し、その知識に基づいて、訓練データに類似した新しいデータを自律的に生成できるAI（人工知能）モデル。<br>
従来の AI モデル (Discriminative Model: 識別モデル) が、与えられたデータを「識別する（分類する）」ことに特化していたのに対し、生成モデルは「創造する（生成する）」ことに特化している点が大きな違い。<br>
<center><img src="data/images/GenerativeModel2.svg"></center>
<br>
・Boltzmann Machine (BM) → Restricted Boltzmann Machine (RBM)<br>
・<a href="#VAE">VAE: Variational Auto Encoder</a><br>
・GAN: Generative Adversarial Networks <br>
・Flow-based model<br>
　Normalizing Flow <br>
・<a href="#DiffusionModel">Diffusion Model (拡散モデル)</a><br>
　DDPM: Denoising Diffusion Probabilistic Model<br>
などがある。<br>
<br>
<a href="data/Papers_GenerativeModel.html">Papers</a><br>

<center><img src="data/images/BM.svg"></center>
<center><img src="data/images/GenerativeModel.svg"></center>
<br>(関連項目)<br>
・<a href="#SSL">SSL: Self-Supervised Learning (自己教師あり学習)</a>
</li>

<br>

<li id="GHA">
<strong>GHA: Generalized Hebbian Algorithm </strong><br>
ニューラルネットワークにおける教師なし学習アルゴリズムの一種。主に主成分分析(PCA)を実行するために使用される。<br>
・神経科学の基本的な仮説である「ヘッブの法則」を一般化したもの。<br>
　※ ヘッブの法則：「同時に発火するニューロン間の結合効率が強化される」というもの。<br>
・入力データのみから学習を行い、正解データ（教師信号）を必要としない。<br>
・データが持つ情報(バリアンス)を最大限に保持しつつ、データの次元を削減(圧縮)することを目指す。<br>
・フィンランドの計算機科学者 Erkki Oja (エルッキ・オヤ) によって開発された Oja の法則(単一ニューロンでの主成分抽出)を、複数のニューロンに対応できるように一般化したアルゴリズム。<br>
・Sanger's rule（サンガーの法則）とも呼ばれる。<br>
<br>(関連項目)<br>
・<a href="#SangersRule">Sanger's rule</a>（サンガーの法則）
</li>

<br>

<li>
<strong>GNN: Graph Neural Networks</strong><br>
グラフ構造のデータ（ノードとエッジで構成されるデータ）を直接扱えるように設計された、特別なタイプのニューラルネットワーク。<br>
<br>
<a href="data/Papers_GNN.html">Papers</a>
</li>

<br>

<li>
<strong>Goal Understanding (目標理解)</strong><br>
AI (人工知能) の分野において、人間や他のエージェントがどのような目標を持って行動しているのかを推測・理解する能力。<br>
表面的な指示をこなすだけでなく、その指示の背後にある意図や目的を読み解くことが, 目標理解の本質。<br>
<br>(関連項目)<br>
・<a href="#IntentExtraction">Intent Extraction</a> (意図抽出)
</li>

<br>

<li id="GoodhartsLaw">
<strong>Goodhart's Law (グッドハートの法則)</strong><br>
「ある指標が目標になると、それはもはや良い指標ではなくなる」という法則
もともとは、イギリスの経済学者チャールズ・グッドハートが提唱した概念で、組織運営、経済政策、データサイエンスなど、さまざまな分野でみられる。<br>
<br>(関連項目)<br>
・<a href="#RewardHacking">Reward Hacking (報酬ハッキング)</a><br>
　類似の現象を強化学習の文脈で説明したもの。
</li>

<br>

<li id="Grokking"><strong>Grokking</strong><br>
機械学習モデルの学習過程で発生する、「遅れて現れる汎化」を指す現象。<br>
モデルが学習データを完全に記憶（過学習）した状態になった後、長い時間が経ってから突然、未知のデータに対する高い汎化性能を獲得する。<br>
<br>
この用語は、SF作家ロバート・ハインラインの小説『異星の客』に出てくる「完全に、深く理解する」という意味の造語「grok」に由来する。<br>
<br>
<center><img src="data/images/Grokking.svg"></center>
<center><img src="data/images/TrendGrokking.svg"></center>
<br>
<a href="data/Papers_Grokking.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#Memorization">Memorization to Generalization</a> (暗記から汎化へ) ･･･ Grokking を含む上位の問題<br>
・<a href="#PrimacyBias">Primacy Bias</a> ･･･ Grokking の高速化で Primacy Bias を克服する<br>
・<a href="#NGD">NGD: Natural Gradient Descent (自然勾配降下法)</a> ･･･ Grokking を加速<br>
・<a href="#SC">Softmax Collapse</a> ･･･ Softmax関数の数値的不安定性が Grokking を起こす
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="H">H</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Hallucination (幻覚)</strong><br>
生成AIが、事実に基づかない情報や誤った内容を、もっともらしく、あたかも真実であるかのように出力する現象。<br>
<br>
<a href="data/Papers_Hallucination.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#RAG">RAG: Retrieval-Augmented Generation</a> (検索拡張生成)<br>
・<a href="#RLHF">RLHF: Reinforcement Learning from Human Feedback</a> (人間のフィードバックによる学習)
</li>

<br>

<li id="HP">
<strong>Halpern-Pearl Definition of Actual Causality (ハルパーン-パールの因果関係の定義)</strong><br>
・SCM: Structural Causal Models (構造的因果モデル)と呼ばれる枠組みを用いて「特定の出来事 A が出来事 B の原因である」ということを形式的に表現したもの。<br>
・事実(出来事 A と出来事 B が起こった)に対して, 反事実 (もし A が起こらなければ B は起こらなかっただろう) という概念を厳密な数学的モデルに落とし込んだもの。<br>
<br>
・<strong>Actual Occurrence (事実条件)</strong>:　実際に観察された世界 (現実世界)では、原因となる出来事 A と結果となる出来事 B の両方が発生している。<br>
・<strong>Necessity/But-For Causation (必然性条件)</strong>:　他のすべての要因が現実世界と同じ値に固定された場合、もし A が起こらなければ B は起こらなかったであろう、という反事実的な状況が存在する。<br>
・<strong>Non-redundancy/Contingency (非冗長性条件)</strong>:　必要に応じて特定の要因を操作(介入)して固定しても、A が B の原因であるという条件が成り立ち続ける必要がある。これは、因果関係を定義する上で発生する標準的な問題 (例：過剰決定) を解決するために導入された最も技術的で重要な条件である。<br>
<br>
●『Causality Without Causal Models』(2025)<br>
・因果性のハルパーンとパールの定義は因果モデル(構造方程式モデルとも呼ばれる)を用いて定義されている。<br>
・この定義を抽象化し、その主要な特徴を抽出することで、反事実が定義される他のモデルにも適用できるようにする。<br>
・定義を抽象化することで<br>
　- バックトラッキングを許すモデルを含むより広範なモデルに定義を適用できる。<br>
　- A と B が選言(formulas involving disjunctions: 論理和を含む論理式)、否定(negations)、信念(beliefs)、入れ子の反事実(nested counterfactuals)を含む式であっても、A が B の原因であるかどうかを判断するために定義を適用することができる。<br>
　- さらに、因果モデルを超えて適用できる説明の抽象的な定義を得るためにアイデアを拡張することができまる。<br>
　- 最後に, 因果モデルにおける定義の特徴についてより深い理解を得ることができる。<br> 
</li>

<br>

<li id="HedonicAdaptation">
<strong>Hedonic Adaptation (幸福順応, 快楽順応)</strong><br>
人々が報酬刺激に急速に慣れて鈍感になるという心理現象<br>
・宝くじに当たった人は、一般的に他の人よりも幸せではなく、実際には日常的な出来事にあまり喜びを感じない。<br>
・最初に好んだ食品を繰り返し摂取すると、その食品の美味しさとその後の摂取量が低下する。<br>
・特定の快楽活動（薬物摂取など）に対する脱感作（感度の低下）が、一種の代償作用として依存行動の形成を促す可能性がある。<br>
<br>
●『Hedonic adaptatio』(1999)<br>
●『A computational and neural model of momentary subjective well-being』(2014)<br>
・瞬間的な幸福度が最近の予測誤差の履歴によって強く予測されることを発見した。<br>
　(予測誤差自体が主観的に価値があり、目的関数として機能しうる)　
</li>

<br>

<li id="HHH">
<strong>HHH: Helpful, Honest, and Harmless (有益、誠実、無害)</strong><br>
AI（人工知能）システム、特に大規模言語モデル(LLM)の設計と運用における重要な行動指針(原則)。AIを人間の価値観に整合させる(アライメント)ためのフレームワークとして、Anthropic社などによって提唱された。<br>
<br>
<strong>Helpful (有益)</strong>　AIは、ユーザーの目標達成を支援するために、正確で関連性のある情報やサービスを提供する必要がある。単に情報を提示するだけでなく、実際に役立つ存在であることが求めらる。<br>
<br>
<strong>Honest (誠実)</strong>　AIは、透明性と真実性を確保し、事実に基づいた情報を提供する必要がある。不確実な情報や誤解を招く可能性がある場合(例：画像診断の不確実性)、それを率直に認め、明確に伝えることが求められる。<br>
<br>
<strong>Harmless (無害)</strong>　AIは、差別的、攻撃的、非倫理的、または危険なコンテンツを生成するなど、いかなる形でも害を及ぼすことを避ける必要がある。バイアスを軽減し、安全性を優先することが重要。<br>
<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a> (AIアライメント) 
</li>

<br>

<li id="HTM">
<strong>HTM: Hierarchical Temporal Memory (階層的時間的記憶)</strong><br>
人間の大脳新皮質の構造と機能に触発された、バイオインスパイアな（生物学的に制約された）機械学習理論および技術。<br>
Jeff Hawkins らによって提唱され、彼が共同設立した Numenta 社によって開発が進められている。<br>
・HTMは、従来の人工ニューラルネットワークとは異なり、大脳新皮質が持つ共通のアルゴリズム(すべての皮質領域で同様の学習プロセスが行われているという理論)を再現することを目指している。<br>
・感覚器官から常時流れ込む時間ベースのデータストリームから、教師なしでパターンを学習し、将来の状態を予測することに焦点を当てている。<br>
・情報が階層的に処理される構造を持ち、各ノード(皮質領域に相当)が時系列パターンを学習・記憶する。<br>
・データは、少数のビットのみがアクティブな高次元のバイナリベクトルとして表現される。これにより、ノイズに対する堅牢性と高い記憶容量を実現している。<br>
<br>
●『How do neurons operate on sparse distributed representations? A mathematical theory of sparsity, neurons and active dendrites』(2016)<br>
●『Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex』(2016)<br>
<center><img src="data/images/HTM.png"></center><br>
A) ほとんどの人工ニ​​ューラルネットワークで用いられるニューロンモデルは、シナプスが少なく、樹状突起は存在しない。<br>
B) 大脳新皮質錐体ニューロンは、樹状突起上に数千の興奮性シナプスを有する。<br>
・細胞体近位のシナプスを形成するフィードフォワード入力(緑色)は、直接活動電位につながる。<br>
・より遠位の基底樹状突起および頂端樹状突起で生成されるNMDAスパイクは細胞体を脱分極させるが、通常は細胞体活動電位を生成するには不十分である。<br>
C) HTMモデルニューロンは、樹状突起とNMDAスパイクを、それぞれ一連のシナプス(それぞれ数個のみ表示)を備えた同時検出器の配列でモデル化する。<br>
<br>
・近接シナプスからの入力(現実の刺激)が来る前に、遠位シナプスが context から「次に何が起こるか」を予測すると、その細胞は「準備状態（脱分極）」になる。<br>
・実際に刺激が来た際、<strong><span style="color:magenta;">予測されていた細胞だけが他よりも早く発火し、周囲を抑制（側方抑制）する</span></strong>。<br>
・結果として、予測が的中している時は、予測がない時よりも<strong><span style="color:magenta;">さらに少数のニューロンだけが活動する（よりスパースになる）</span></strong>という現象が起こる。<br>
・予測が外れた場合は, スパースにならず, 驚きとして異常(予測外れ)が検知される。<br>
<br>(関連項目)<br>
・<a href="#Sparsity">Sparsity</a> (スパース性)<br>
・<a href="https://en.wikipedia.org/wiki/Hierarchical_temporal_memory">wikipedia: Hierarchical temporal memory</a><br>
</li>

<br>

<li id="Hubness">
<strong>Hubness (ハブ性)</strong><br>

機械学習、特に高次元データ空間で発生する現象。<br>
データセット内のごく一部のデータポイント（「ハブ」と呼ばれる）が、他の多くのデータポイントの k-Nearest Neighbors (k-近傍)に異常なほど頻繁に出現するようになる現象を指す。 一方、ほとんどどのデータポイントの k-近傍に現れない「アンチハブ」と呼ばれるデータポイントも同時に発生する。<br>
ハブネスは、「Curse of Dimensionality (次元の呪い)」の一側面とされている。高次元空間では、データポイント間の距離のコントラストが低下し、ほとんどのデータポイント間の距離がほぼ等しくなってしまう。その結果、データ空間の特定の場所に位置するごく一部のデータポイントが、多くのデータポイントから「近い」と認識されやすくなる。<br>
ハブネスは、kNN (k-近傍法) などの距離ベースのアルゴリズムに悪影響を及ぼす。<br>
<br>
<a href="data/Papers_Hubness.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#CurseOfDimensionality">Curse of Dimensionality (次元の呪い)</a>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="I">I</h2>
<p>
<div class="styleBullet">
<ul>

<li id="ICL">
<strong>ICL: In-Context Learning (文脈内学習)</strong><br>
大規模言語モデル（LLM）において、モデルのパラメーター（重み）を更新することなく、プロンプト内で与えられた例（文脈）に基づいて新しいタスクを学習し、実行する能力やその手法。従来の機械学習とは一線を画す、LLM特有の非常に強力な機能。<br>
<br>
●『Language Models are Few-Shot Learners』(2020)<br>
　(言語モデルはフューショット学習器である)<br>
・GPT-3（Generative Pre-trained Transformer 3）という当時としては空前の1,750億パラメータを持つ巨大モデルを発表したもの。<br>
・巨大化によって、モデルがトレーニング時には明示的に教え込まれていないタスクを、推論時にプロンプトの例示だけで実行できるようになることを実証した。<br>
・ファインチューニング（再学習）を必要とせず、プロンプト内（コンテキスト内）で数個の例示を与えるだけでタスクをこなすこの能力を「In-context Learning」あるいは「Few-shot Learning」と名付け、言語モデル研究の方向性を決定づけた。
</li>

<br>

<li id="ICoT">
<strong>ICoT: Implicit Chain-of-Thoughts Training (暗黙の思考連鎖トレーニング)</strong><br>
　トレーニング中に明示的な思考連鎖トークンを最初に提示し、段階的にそれらを取り除いていく。このアプローチは、乗算のようなタスクに必要な推論手順をモデルが内面化するのに役立つ。<br>
<br>
●『Why Can’t Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls』(2025)<br>
　(<strong><span style="color:magenta;">トランスフォーマーはなせ掛け算を学べないのか ?</span></strong> 逆エンジニアリングが長距離依存性の落とし穴を明らかにする )<br>
</li>

<br>

<li id="IDEstimation">
<strong>ID (Intrinsic Dimension) Estimation (固有次元推定, 内在次元推定)</strong><br>
データセットの「真の」または「本質的な」次元数を決定するための機械学習およびデータ分析における手法。<br>
AIの生成した文章と人間の作成した文章の判別や, LLM出力品質改善の指標として使われる。<br>
<br>
<strong>近傍ベースの手法 (Nearest Neighbor Methods)</strong>:　データポイント間の距離や近傍点の数に基づいて推定するWorldWor<br>
<strong>主成分分析 (PCA) ベースの手法</strong>:　PCAを適用し、どれだけの分散（データのばらつき）が保持されるかを分析して次元数を決定する。<br>
<strong>多様体学習ベースの手法</strong>:　データが非線形の多様体上に存在することを前提とし、その幾何学的特性を利用して推定する。<br>

<br>
●『Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts』(2023)<br>
　(AI生成テキストの堅牢な検出のための内在次元推定)<br>
・人間が書いたテキストの不変量、すなわち、与えられたテキストサンプルに対する埋め込み集合の基礎となる多様体の固有次元を提案する。<br>
・自然言語による流暢なテキストのは、アルファベットベースの言語の平均固有次元：9前後<br>
・中国語の平均固有次元：7前後<br>
・各言語のAI生成テキストの平均固有次元はそれより約1.5低い<br>
<br>
●『Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story』(2025)<br>
　(テキストの内在的次元の解明：学術抄録から創作物語まで)<br>
・確立された4つのID推定器（持続的ホモロジー次元（PHDIM）、最尤推定（MLE）、最近傍2つ（TwoNN）、タイト局所推定（TLE））を利用し, 科学的な散文は低いIDを示し、創造的なコンテンツは高いIDを示すことを発見した。
</li>

<br>

<li id="IDTheory">
<strong>ID: Interest-Deprivation theory of curiosity (興味・剥奪モデル, 興味・欠乏モデル)</strong><br>
好奇心を知的葛藤や情報不足によって生じる「剥奪タイプ」と、単に知ることを楽しむ「興味タイプ」の2つの側面から捉える理論。好奇心が一つの単純な感情ではなく、ポジティブな報酬追求的な側面と、ネガティブな状態を回避・解消しようとする側面という、2つの異なる心理的プロセスから成り立っていると説明する。 <br>
<br>
・Interest-type curiosity (興味タイプ)<br>
　CFI: Curiosity as a Feeling of Interest (興味の感情としての好奇心)<br>
　ポジティブな感情の誘導によって引き起こされる探索行動。特定のトピックについて深く掘り下げたり、新しい情報を得たりすること自体に喜びを感じることが動機となる。<br>
<br>
・Deprivation-type curiosity (剥奪タイプ, 欠乏タイプ)<br>
　CFD: Curiosity as a Feeling of Deprivation (欠乏感としての好奇心)<br>
　認知的葛藤、不確実さ、あるいは混乱といった不快な状態を解消したいという欲求によって引き起こされる情報探索行動。<br>
　I/D理論の「剥奪タイプ」は、AIが現在の知識と新しい情報の間の「不確実性」や「violation of expectation (予期違反)」を知覚したときに、そのギャップを解消しようとする行動としてモデル化される。これは、AIが「何をまだ知らないか」を認識し、その不足を埋めるための探索を促すのに役立つ。<br>
<br>
●『The Measurement of Curiosity As a Feeling of Deprivation』(2004)<br>
　Loewenstein の情報ギャップ理論を拡張し、好奇心を「興味（Interest）」と「剥奪（Deprivation）」の2因子で測定する尺度を初めて開発した。<br>
●『Curiosity and the pleasures of learning: Wanting and liking new information』(2005)<br>
　I/Dモデルをさらに発展させ、神経科学的な「Wanting（欲求）」と「Liking（嗜好）」の概念と結びつけた。これにより、D型（剥奪型）は情報に対する強い「Wanting」を伴う一方、I型（興味型）は発見の「Liking」が中心であることを理論化した。<br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven</a>（好奇心駆動型)<br>
・<a href="#InformationGapTheory">Information Gap Theory</a> (情報ギャップ理論)
</li>

<br>

<li id="IL">
<strong>IL: Imitation Learning (模倣学習)</strong><br>
熟練者 (人間やAIなど) が示したお手本の行動を観察し、それを真似ることでタスクの遂行方法を学習させる機械学習の手法。<br>
<br>
・<strong>BC: Bihavioral Cloning (行動クローニング)</strong><br>
　状態と行動の正解データセットを使ってポリシー(状態→行動)を学習する<br>
<br>
・<strong>GAIL:Generative Adversarial Imitation Learning(敵対的生成模倣学習)</strong><br>
　状態と行動の正解データセットを使ってGANのようにポリシーと識別器を同時学習する。<br>
<br>
・<strong>Reinforcement Lerning(強化学習)</strong><br>
　正解の行動が判らない状態で, 人間が定義した報酬を使って試行錯誤によりポリシーを学習する。<br>
　(人間が模倣学習を行って報酬関数を定義し. 強化学習によりポリシーの形にする)<br>
<br>
・<strong>Inverse Reinforcement Learning(逆強化学習)</strong><br>
　熟練者の行動から報酬の予測を学習する。<br>
<center><img src="data/images/IL.svg"></center>
<br>
●『Imitation Learning: Progress, Taxonomies and Challenges』(2021)<br>
　論文は<a href="https://arxiv.org/abs/2106.12177">こちら</a><br>
<br>
<center><img src="data/images/IL2.png"></center>
<br>(関連項目)<br>
・<a href="#DRL">DRL: Deep Reinforcement Learning (深層強化学習)</a><br>
・<a href="#IRL">IRL: Inverse Reinforcement Learning (逆強化学習)</a><br>
</li>

<br>

<li id="ill-posed">
<strong>ill-posed problem (不良設定問題)</strong><br>
・well-posed problem(良設定問題)ではない問題。<br>
　= 以下の条件のいずれかを満たしていない問題。<br>
・well-posed problem(良設定問題)<br>
　1. 解が存在する<br>
　2. 解が一意である<br>
　3. 解が安定している<br>
<br>
(例)<br>
　2+6=?  　　　　　　　良設定問題<br>
　△+□=8, △=?, □=?  不良設定問題<br>
<br>
　損失関数 |△+□-8| だけでは解が定められれない。<br>
<br>
　△, □は自然数? 整数? 実数? 複素数?<br>
　差が少ない方が良い? 大きい方が良い? <br>
　などの解が備えるべき性質(拘束条件, 正則化条件)が必要。<br>
<br>(関連項目)<br>
・<a href="#Regularization">Regularization (正則化)</a>
</li>

<br>

<li>
<strong>Implicit Bias (暗黙のバイアス)</strong><br>
無意識のうちに抱いている偏見、思い込み、先入観のこと。日本語では「潜在的バイアス」や「アンコンシャス・バイアス」とも呼ばれる。<br>
<br>
●『Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings』(2016)<br>
　(男性とコンピュータープログラマーの関係は、女性と主婦の関係と同じ？単語埋め込みのバイアス除去する)<br>
言語モデルにおけるバイアスへの懸念を高めた主要な研究の一つ。 単語埋め込みにおける強い性別ステレオタイプを実証した。<br>
<br>
<a href="data/Papers_ImplicitBias.html">Papers</a>
</li>

<br>

<li id="InductiveBias">
<strong>Inductive Bias (帰納バイアス)</strong><br>
学習時に遭遇したことのない入力に対する出力の予測を可能にするために用いる一連の仮定から生じるバイアスのこと。<br>
<br>
●『The need for biases in learning generalizations』(1980)<br>
学習とは、過去の経験から一般化を行い、その経験に「関連する」新しい状況に対処する能力を伴う。<strong><span style="color:magenta;">新しい状況に対処するために必要な帰納的飛躍は、状況のある一般化を他の一般化よりも選択するための特定のバイアスがある場合にのみ可能となるように思われる</span></strong>･･･<br>
<br>
事前分布はベイズ推論における帰納バイアスの一種と見なすことができる。
ここで「帰納的」という言葉は、帰納法の厳密な数学的意味を持つのではなく、以前の知識に基づいて何らかの推論を行うという事実を意味する。<br>
<br>
<a href="data/Papers_InductiveBias.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#Regularization">Regularization (正則化)</a>
</li>

<br>
<li id="InductiveLeap">
<strong>Inductive Leap (帰納的飛躍)</strong><br>
限られた個別的な観察や経験から、より広い範囲に適用される一般的な結論を導き出す際の、論理的な飛躍。<br>
(例)<br>
・「すべての白鳥は白い」<br>
　　オーストラリアでは黒い白鳥（コクチョウ）が見つかり、この結論は覆された。<br>
・「飼い主はいつも自分に親切だ」(by 七面鳥)<br>
　　感謝祭の日、仮説が間違っていたことが明らかになる。<br>
<br>
一見すると論理的な欠陥のように見えるが、知識を拡張する上で不可欠な思考プロセス。<br>
<br>(関連項目)<br>
・<a href="#Reasoning">Reasoning (推論)</a>
</li>

<br>

<li id="InductiveLearning"><strong>Inductive Learning (帰納学習)</strong><br>
●『Learning Model Successors』(2025) における Inductive Learning (帰納的学習) は、ある抽象度のレベルで得られたモデルから、さらに高レベルのモデル（「モデルの後継者」）を学習する、という新しいパラダイムを指す。<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)･･･概略図比較あり,　 <a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習=継続学習の別名)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
</li>

<br>

<li id="InfluenceCampaignsDetection">
<strong>Influence Campaigns / Operation Detection (印象操作検出,影響工作活動検知)</strong><br>
SNSやネットメディアを通じて人々の意見や行動、意思決定を操作しようとする「インフルエンス・オペレーション（影響工作）」を、AIやデータ分析技術を用いて特定・防御する取り組み。<br>
<br>
●『The spread of true and false news online』(2018)<br>
・12万件以上のニュース拡散を分析し、<strong><span style="color:magenta;">「偽ニュースは真実よりも速く、深く、広く拡散する」ことを定量的に証明した</span></strong>。<br>
●『The ABC Framework: A-ctors, B-ehavior, C-ontent』(2019)<br>
・それまで「嘘の内容（Content）」ばかりに注目していた検知の視点を、「誰が（Actors）」、「どのような不自然な振る舞い（Behavior）」で行っているか、という3軸で整理した。これにより、Meta(Facebook)などのプラットフォームが「協調的不自然挙動(CIB:Coordinated Inauthentic Behavior)」を定義し、排除する法的・技術的根拠となった。
</li>

<br>

<li id="IntentExtraction">
<strong>Intent Extraction (意図抽出)</strong><br>
ユーザーが発した言葉や文章の背後にある「意図」や「目的」を特定する技術。<br>
<br>
<a href="data/Papers_IntentExtraction.html">Papers</a>
</li>

<br>

<li id="InertialThinking">
<strong>Inertial Thinking (慣性思考)</strong><br>
過去の経験や成功体験に基づいて形成されたお決まりの思考パターンやアプローチに固執し、新しい状況や情報に直面しても、そのパターンからなかなか抜け出せない傾向。<br>
<br>(特徴)<br>
<strong>現状維持バイアス</strong>:　変化を嫌い、慣れ親しんだ現状やデフォルトの選択肢を選びがちになる。<br>
<strong>思考の柔軟性の欠如</strong>:　問題解決のために、常に同じルートや方法を選ぼうとする（例：いつも同じ通勤ルートを使う）。<br>
<strong>新しい情報への抵抗</strong>:　既存の信念や考え方を覆すような新しい証拠や情報が現れても、それを受け入れ、解釈を修正することに抵抗を感じる。<br>
<strong>盲点の発生</strong>:　決まりきった思考回路に頼るため、新しい可能性や斬新な解決策を見落としやすくなる。<br>
<br>(関連項目)<br>
・<a href="#ReverseThinking">Reverse thinking</a>
</li>

<br>

<li id="InformationGapTheory">
<strong>Information Gap Theory (情報ギャップ理論)</strong><br>
1994年に心理学者のジョージ・ローウェンスタイン（George Loewenstein）が提唱した、「好奇心」の発生メカニズムを説明する理論。<br>
<br>
●『The Psychology of Curiosity: A Review and Reinterpretation』(1994)<br>
（好奇心の心理学：展望と再解釈）<br>
　好奇心とは、「自分が今知っていること」と「知る必要があること（あるいは知りたいこと）」との間のギャップ（乖離）に気づいたときに生じる心理的な反応であると定義した。<br>
<br>(関連項目)<br>
・<a href="#IDTheory">ID: Interest-Deprivation theory of curiosity</a> (興味・剥奪モデル, 興味・欠乏モデル) ･･･ 情報ギャップ理論を拡張したモデル<br>
</li>

<br>

<li id="Interestingness">
<strong>Interestingness (面白さ, 興味深さ)</strong><br>
AIが生成するアウトプットが爆発的に増える中で、「<strong>正しいけれど退屈な情報</strong>」を排除し、「<strong>未知で価値のある洞察</strong>」を優先的に人間に提示することが必要不可欠になる。そのための指標。<br>
<br>
●『A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models』(2025)<br>
　数学の進化は、面白さによって部分的に導かれてきた。<br>
　人々の選択は、問題がどれだけ面白くて難しいかという判断によって導かれることがよくある。<br> 
　LLMなどのAIシステムが、高度な研究であれ教育であれ、人々と共に数学に関与することが増えるにつれて、その判断が人間の判断とどの程度一致しているかを理解することが重要になる。
</li>

<br>

<li id="IntrinsicMotivation">
<strong>Intrinsic Motivation (内発的動機付け)</strong><br>
報酬や評価といった外部の刺激に関係なく、個人の内面から自然と湧き上がる興味・関心、意欲によって行動すること。<br>
<br>
●『Intrinsic motivation systems for autonomous mental development』(2007)<br>
　(自律的な精神発達のための内発的動機付けシステム)<br>
・「学習の進捗を最大化するために中程度の難易度のタスクを選択する」<br>
<br>
<a href="data/Papers_IntrinsicMotivation.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven（好奇心駆動型）</a><br>
・<a href="#NoveltySearch">Novelty Search (新規性探索)</a><br>
</li>

<br>

<li id="Inversion">
<strong>Inversion ((AI推論の)反転)</strong><br>
AIモデルの推論結果から. 入力データや学習データを推定すること。<br>
<br>
<center><img src="data/images/Inversion.svg"></center>
<br>
●『Language Models are Injective and Hence Invertible』(2025)<br>
　(言語モデルは単射的であり 、したがって可逆である)<br>
　「一見複雑に見えるにもかかわらず、標準的なデコーダーのみのTransformer言語モデル（プロンプトから隠れ状態へのマップとして捉えられる）は、実際にはほぼ確実に単射である。つまり、実質的にあらゆるパラメータ設定において、また訓練過程において、異なるプロンプトは異なる最終トークン表現を生成する」<br>
<br>
●『The non-linear representation dilemma: Is causal abstraction enough for mechanistic interpretability?』(2025)<br>
　(非線形表現のジレンマ：メカニズム的解釈可能性にとって、因果的抽象化は十分か?)<br>
　トランスフォーマーがランダムな初期化時にほぼ確実に単射であることを証明した。<br>
<br>
●『Language model inversion』(2023)<br>
　(言語モデル反転)
　言語モデルの次トークン確率分布のみを分析することで、言語モデルに与えられた入力プロンプトを再構築することが可能であることを実証した。<br>
言語モデルAPIを通じて機密性の高いユーザーデータが漏洩する可能性のあるプライバシーの脆弱性を示した。<br>
<br>
●『Extracting training data from large language models』(2020)<br>
　(大規模言語モデルからの学習データ抽出)<br>
　大規模言語モデルからの学習データ抽出における具体的なリスクを実証し、プライバシーの脆弱性に対する重要な証拠を提供した。<br>
<br>
●『Inverting visual representations with convolutional networks』(2015)<br>
　(畳み込みネットワークによる視覚表現の反転)<br>
　画像分類器からの確率予測が重要な詳細を保持し得ることを示した。
</li>

<br>

<li id="IPS">
<strong>IPS: Interacting Particle System (相互作用粒子系)</strong><br>
相互作用する粒子系をニューラルネットワークの訓練の理論解析に使用する。<br>
<br>
●『Trainability and Accuracy of Neural Networks: An Interacting Particle System Approach』(2018)<br>
　(ニューラルネットワークの訓練可能性と精度：相互作用粒子系アプローチ)<br>
　重要な洞察は、<strong><span style="color:magenta;">個々のパラメーターに対する損失関数は通常非凸であるのに対し、分布 \(\mu\) に対する損失汎関数は凸になる</span></strong>ということである。この「分布レベルでの凸化」は、ワイドニューラルネットワークが、一見手に負えない最適化ランドスケープを持っているにもかかわらず、訓練可能である理由を根本的に説明する。
</li>

<br>

<li id="IRL">
<strong>IRL: Inverse Reinforcement Learning (逆強化学習)</strong><br>
熟練者 (人間やAIなど) の行動データ（デモンストレーション）から、その行動の背後にある「報酬関数」を推定する模倣学習のための強力な手法群。<br>
<br>
<center><img src="data/images/IRL.svg"></center>
<br>
●『Inverse Reinforcement Learning without Reinforcement Learning (2023)』<br>
　(強化学習なしの逆強化学習)<br>
　論文は<a href="https://arxiv.org/abs/2303.14623v4">こちら</a><br>
　従来の IRL 手法は、難しい強化学習（RL）問題をサブルーチンとして繰り返し解く必要があった。 模倣学習というより容易な問題を、より困難なRL問題を繰り返し解く問題に縮約した。理論上は指数関数的な高速化を実現する。実際に、連続制御タスクにおいて従来技術を大幅に高速化できることが分かった。<br>
<br>
●『General agents contain world models』(2025)
　(汎用エージェントは世界モデルを含む)<br>
　論文は<a href="https://arxiv.org/abs/2506.01622">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2506.01622v4">こちら<a/><br>
　「<strong><span style="color:magenta;">世界モデルは</span></strong>、柔軟な目標指向行動に<strong><span style="color:magenta;">必要な要素なのでしょうか、それともモデルフリー学習で十分なのでしょうか？</span></strong>この問いに対する正式な回答として、多段階の目標指向タスクに一般化できる<strong><span style="color:magenta;">エージェントは、環境の予測モデルを学習している必要があることを示す</span></strong>。」
　逆強化学習はエージェントの方策と世界モデルを用いて目標(報酬モデル)を特定するのに対し、我々の結果はエージェントの方策と目標(報酬)を用いて世界モデルを特定する。
<br>
<center><img src="data/images/WorldModel2.svg"></center>
\[
\begin{array}{l|c| c}
& 入力 & 出力 \\
\hline
強化学習 & 報酬(,世界モデル) & ポリシー \\
\hline
逆強化学習 & ポリシー(,世界モデル) & 報酬 \\
\hline
本論文 & 報酬, ポリシー & 世界モデル
\end{array}
\]

<br>
<a href="data/Papers_IRL.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#DRL">DRL: Deep Reinforcement Learning (深層強化学習)</a><br>
・<a href="#IL">IL: Imitation Learning (模倣学習)</a> ･･･ 概略図比較あり<br>
・<a href="#WorldModel">World Model (世界モデル)</a>
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="J">J</h2>
<p>
<div class="styleBullet">
<ul>

<li><strong>Japanese Dancing Mouse (ハツカネズミ)</strong><br>
Jの項目が少ないのでスペースホルダー①<br>
<br>
・Japanese：　17世紀頃に中国から日本に持ち込まれ、日本ではペットとして人気を博した。その後、日本から欧米に紹介されたため、「Japanese」という形容詞が冠された。当時は「Nankin mouse（ナンキンマウス）」とも呼ばれていた。<br>
<br>
・dancing:　まっすぐ進むことができず、突然くるくると円を描くように回ったり、回転したりする癖があります。この様子が、まるで踊っているように見えたため、「dancing (踊る)」という名前が付けられた。<br>
<br>(関連項目)<br>
・<a href="#YerkesDodsonLaw">Yerkes-Dodson Law</a> (ヤーキーズ・ドッドソンの法則)
</li>

<br>

<li><strong>Japanese Missing Cat Method</strong><br>
<br>
AIとは(今のところ)関係ない。Jの項目が少ないのでスペースホルダー②<br>
行方不明になった猫を捜す際に、近所にいる野良猫や「ボス猫」に、探している猫の特徴を伝えて協力を求めるという、日本に古くから伝わるという都市伝説的な手法。2025年ごろに海外のSNS、特にTikTokで話題になり、一気に広まった。<br>
<br>
<ul>
<li><strong>1. 近所の猫を探す</strong><br>
家の近所にいる野良猫、特に縄張りを仕切っていると見られるボス猫を探す。
</li><li>
<strong>2. 猫の目線になる</strong><br>
探してもらう猫の近くでしゃがみこみ、同じ目線になる。
</li><li>
<strong>3. 情報を伝える</strong><br>
行方不明になった猫の名前や特徴を具体的に、ささやくように伝える。
</li><li>
<strong>4. 感謝と熱意を伝える</strong><br>
猫がいかに大切な存在かを訴え、見つけてくれたらお礼をすることを伝える。
</li><li>
<strong>5. お礼の品を渡す</strong><br>
報酬として、その場でキャットフードなどを与える。
</li></ul>
</li>

<br>

<li><strong>Jensen's inequality (イェンセンの不等式)</strong><br>
<br>
凸関数 \(f\) と確率変数 \(X\) について、\(E[f(X)]\ge f(E[X])\) という関係が成り立つことを示している。<br>
直感的には, 凸関数に平均値を代入した値は、関数に代入してから平均をとった値よりも小さくなる、というもの。<br>
<br>
・変分ベイズやEMアルゴリズムでは、イェンセンの不等式を使って尤度の下限 (ELBO: Evidence Lower Bound) を導出する。<br>
<br>
・2つの確率分布間の違いを測る指標である KL (カルバック・ライブラー)ダイバージェンスが非負 (0以上) であることの証明に使われる。
</li>

<br>

<li id="JEPA">
<strong>JEPA: Joint-Embedding Predictive Architecture</strong><br>
Meta社が提唱した「より人間に近い学習能力」を持つAIを目指すための新しい自己教師あり学習アーキテクチャー。<br>
・<a href="https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/">I-JEPA: ヤン・ルカン氏のより人間らしいAIのビジョンに基づいた初のAIモデル</a><br>
<br>
<center><img src="data/images/JEPA.svg"></center><br>
・ジョイント埋め込みアーキテクチャは、互換性のある入力 x、y に対して類似の埋め込みを、互換性のない入力に対しては異なる埋め込みを出力することを学習します。<br>
・生成アーキテクチャは、再構成を容易にするために追加の（潜在的である可能性のある）変数 z を条件とするデコーダーネットワークを使用して、互換性のある信号 x から信号 y を直接再構成することを学習します。<br>
・ジョイント埋め込み予測アーキテクチャは、予測を容易にするために追加の（潜在的である可能性のある）変数 z を条件とする予測子ネットワークを使用して、互換性のある信号 x から信号 y の埋め込みを予測することを学習します。<br>
<br>(関連項目)<br>
・<a href="#NEPA">NEPA: Next-Embedding Predictive Autoregression</a><br>
・<a href="#SSL">SSL: Self-Supervised Learning</a> (自己教師あり学習)<br>
</li>

</ul></div>
</p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="K">K</h2>
<p>
<div class="styleBullet">
<ul>
<li id="KAN">
<strong>KAN: Kolmogorov-Arnold Networks</strong><br>
・従来の多層パーセプトロン (MLP) がノード (ニューロン) に固定された活性化関数を持つのに対し、KAN はエッジ (結合部分) に学習可能な活性化関数 (通常はスプライン関数でパラメータ化される) を導入した。<br>
・MLP よりも高い精度と解釈可能性を提供し、より少ないパラメータで複雑な関数をモデル化できる可能性がある。<br>
<center><img src="data/images/KAN.png"></center>
<br>
●『KAN: Kolmogorov–Arnold Networks』(2024)<br>
●『KAN 2.0: Kolmogorov-Arnold Networks Meet Science』(2024)<br>
●『From PINNs to PIKANs: recent advances in physics-informed machine learning』(2024)<br>
●『KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning』(2024)<br>
●『Kolmogorov-Arnold Transformer』(2024)<br>
</li>

<br>

<li>
<strong>Kan Extension (Kan拡張)</strong><br>
圏論における「最も普遍的な方法」で関手を拡張するための構成。ある関数をより広い定義域に拡張する操作を、圏論の文脈で一般化したもの。<br>
1960年に極限を用いてこの拡張を構成した ダニエル・カン (Daniel Marinus Kan) の名に由来している。<br>
<br>
●『Learning Is a Kan Extension』(2025)<br>
すべてのエラー最小化アルゴリズムが Kan 拡張として表現できることを証明する。
</li>

<br>

<li id="KD">
<strong>Knowledge Distillation (知識蒸留)</strong><br>
機械学習の技術の一つで、大規模で高性能なAIモデル（教師モデル）が持つ知識を、より小型で軽量なAIモデル（生徒モデル）に移転・圧縮する手法。<br>
<br>
<center><img src="data/images/KnowledgeDistillation.svg"></center>
<a href="data/Papers_KD.html">Papers</a><br>
<br>
●『Transferring Inductive Biases through Knowledge Distillation』(2020)<br>
　帰納的バイアスが、完全に異なるアーキテクチャを持つ「教師」モデルから「生徒」モデルへ効果的に転移できるかどうかを調査し,転移できることを確認した。<br>
　・LSTM (シーケンシャル処理に自然な好みを持つ) →Transformer<br>
　・CNN (空間的局所性, 並進不変性) → MLP<br>
<center><img src="data/images/IBtransfer.svg"></center>
<center>学習中の内部表現の遷移を視覚化したもの</center>
<br>
強い帰納的バイアスがない場合、モデルは損失面上の複数の局所的最小値に等しく引き寄せられる可能性があり、収束解は初期状態や訓練例の順序などのランダムな変動によって任意に影響を受ける可能性がある。強い帰納的バイアスを持つモデルを教師モデルにすることでそれらの影響を避けることができる。
</li>

<br>

<li id="KolmogorovComplexity">
<strong>Kolmogorov Complexity (コルモゴロフ複雑性)</strong><br>
あるデータ（文字列など）を記述するための最短のプログラムの長さとして、そのデータの情報量や複雑性を定量化する。<br>
<br>
<strong>モデル選択と正則化</strong>　機械学習において、訓練データを簡潔に（低いコルモゴロフ複雑性で）表現できるモデルは、優れた汎化性能を持つ (過学習しにくい) と考えられる。これは「オッカムの剃刀」の原則と一致する。<br>
<br>
<strong>データ圧縮</strong>　データの圧縮は、そのデータのコルモゴロフ複雑性の推定と見なすことができ、これは機械学習モデルがデータの本質的な特徴を捉える方法と密接に関連している。<br>
<br>
<strong>KoLMogorov-Test</strong>　コード生成モデルの知能テストとして「KoLMogorov-Test」というものが提案されている。
</li>

<br>

<li id="KolmogorovSinaiEntropy">
<strong>Kolmogorov-Sinai Entropy (コルモゴロフ・シナイ・エントロピー)</strong><br>
動的システムの複雑性やカオスを定量化する尺度。
</li>

<br>

<li id="KolmogorovStructureFunction">
<strong>Kolmogorov Structure Function (コルモゴロフ構造関数)</strong><br>
データセットの情報内容、圧縮可能性、および構造を理解するための理論的枠組みを提供し、AIの効率とエネルギー消費の最適化（エントロピー経済）の研究に応用されている。
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="L">L</h2>
<p>
<div class="styleBullet">
<ul>

<li id="LatentAction">
<strong>Latent Action (潜在アクション)</strong><br>
明示的なラベルがない動画などから、AIが自ら見つけ出した『行動』の抽象的な表現のこと。<br>
・インターネット上の膨大な動画には、「右に動かす」「掴む」といった操作ログ（アクションラベル）が付いていない。潜在アクションモデルは、動画のフレーム間（例えば時刻 \(t\) と \(t+1\)）の視覚的な変化（Visual Delta）を解析し、その変化を引き起こした「何らかの働きかけ」を数値のベクトル（潜在変数）として抽出する。これが「潜在アクション」。<br>
・潜在アクションは、具体的な機械の制御値（電圧や座標など）ではなく、「世界をどう変えるか」という本質的な変化を表現する。<br>
<br>
●『Learning Latent Action World Models In The Wild』(2026) 解説は<a href="https://www.alphaxiv.org/ja/overview/2601.05230">こちら</a><br> 
・「ワールドモデル」を構築するための従来のアプローチは、明示的にラベル付けされた行動、つまり各ステップでどのような行動が取られたかを正確に知ることに大きく依存していた。しかし、この依存性は、そのような詳細な行動の注釈がめったに利用できない実世界のシナリオにスケールアップしようとする際に、重大なボトルネックを生み出す。<br>
・潜在行動ワールドモデルの開発における重要なギャップに対処し、ラベル付けされていない膨大な量の実世界の(in-the-wild)ビデオデータから学習する方法を示す。<br>
<center><img src="data/images/LatentActionWorldModel.svg"></center>
<br>(関連項目)<br>
・<a href="#V-JEPA-2">V-JEPA-2: Video Joint Embedding Predictive Architecture 2</a><br>
</li>

<br>

<li>
<strong>Latent learning (潜在学習)</strong><br>
学習した内容が行動にすぐには現れず、適切な動機づけやきっかけが与えられたときに初めて表面化する学習の形態。<br>
エドワード・トルーマンは、報酬のない状態で迷路を探検させたラットが、後で報酬が与えられるようになると、すぐに迷路を効率的に通り抜けられるようになることを示した。これは、報酬がなくても環境の認知地図（cognitive map）が形成されていたことを示している。<br>
機械学習では、この概念はデータの「latent space (潜在空間)」と結びつけられることがある。<br>
<br>
●『Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences 』(2025)<br>
　(潜在学習：経験の柔軟な再利用を可能にすることで、エピソード記憶がパラメトリック学習を補完する)<br>
　機械学習システムの弱点の一つは、潜在学習、つまり現在のタスクとは無関係だが将来のタスクで役立つ可能性のある情報を学習できないことであると主張する。この視点が、言語モデリングにおける反転の呪いからエージェントベースナビゲーションに関する新たな知見に至るまで、様々な失敗にどのように関連しているかを示す。

</li>

<br>

<li id="LatentSpace">
<strong>Latent Space (潜在空間) </strong><br>
モデルが学習した、データの隠された本質的な特徴を捉えた、低次元で抽象的なベクトル空間のこと。<br>
<center><img src="data/images/LatentSpace.svg"></center>
<br>
<a href="data/Papers_LatensSpace_LatentZone.html">Papers</a><br>

●『Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification』(2025)
　(潜在ゾーニングネットワーク：生成モデリング、表現学習、および分類の統一的原理)
統一された原理で, 生成モデリング、表現学習、分類の 3つのタスクすべてに対処できるかを問う。このような統一により、ML パイプラインが簡素化され、タスク間の相乗効果を高めることができる。 この目標に向けた一歩として、潜在ゾーニング ネットワーク (LZN) を紹介する。
<br>
<center><img src="data/images/LatentZone.svg"></center>
●『Latent Collaboration in Multi-Agent Systems』(2025)<br>
・<strong>マルチエージェントシステム</strong><br>
　○ 個々のモデルが達成できる能力を超える複雑な推論と問題解決能力を実現できる。<br>
　× エージェントが自然言語テキストのみを介して通信するため、<strong>情報ボトルネック、計算オーバーヘッド</strong>、および<strong>エラー伝播</strong>が生じる。<br>
　→ エージェントが離散的なテキストトークンではなく、連続的な潜在表現内で完全に協調できるようにするフレームワークを導入した。<br>
<center><img src="data/images/LatentCollaboration.svg"></center>
<br>
●『One Small Step in Latent, One Giant Leap for Pixels:Fast Latent Upscale Adapter for Your Diffusion Models』(2025)<br>
　　(潜在空間における小さな一歩はピクセルにとっての大きな飛躍:拡散モデルのための高速潜在空間アップスケールアダプター)<br>
　　(蛇足: このタイトルで思い出すのはやはり<br>
　　「"That's one small step for man, one giant leap for mankind."<br>
　　 (一人の人間にとっては小さな一歩だが、人類にとっては大きな飛躍だ)」by アームストロング船長)<br>
<center><img src="data/images/LUA.svg"></center>
<br>
・<a href="#VAE">VAE: Variational Auto Encoder</a>
</li>

<br>

<li id="LCM">
<strong>LCM: Large Concept Model (大規模概念モデル)</strong><br>
Meta社が2024年12月に発表した、「トークン（単語の断片）」単位ではなく、「概念（文レベルのまとまり）」単位で推論を行う新しいAIアーキテクチャー。
\[
\begin{array}{l|l|l}
& \text{LLM(Large Language Model)} & \text{LCM(Large Concept Model)} \\
\hline
\text{最小単位} & \text{トークン(単語の断片)} & \text{概念(文, 高次のアイディア)}\\
\hline
\text{予測対象} & \text{次に来るトークン} & \text{次に来る概念(埋め込みベクトル)} \\
\hline
\text{言語依存} & \text{学習した言語に依存しやすい} & \text{言語を超えた共通の意味空間で動作}
\end{array}
\]

この技術には、Metaが開発した200以上の言語や音声をサポートする埋め込み空間「SONAR」が活用されており、多言語間でのスムーズな情報転送や生成が可能になっている。<br>
<br>
●『Large Concept Models: Language Modeling in a Sentence Representation Space』(2024)<br>
　従来のトークン単位の予測ではなく、文単位の意味ベクトル（SONAR埋め込み空間）を用いて、高次の「概念」を自己回帰的に予測するアーキテクチャが提案されている。<br>
●『Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space』(2025)<br>
　Dynamic Large Concept Models (DLCM)は, 現在のLLM（大規模言語モデル）における根本的な非効率性、すなわち、<strong><span style="color:magenta;">意味的重要性にかかわらず、すべてのトークンに一律に計算を適用するという問題に対処する</span></strong>。<br>
<br>
<center><img src="data/images/DLCM.png"></center>
<center>境界検出とプーリング</center>
</li>

<br>

<li id="LDM">
<strong>LDM: Latent Diffusion Model (潜在拡散モデル)</strong><br>
画像生成AIの分野における深層学習モデルの一種。
高次元のピクセルまたはデータ空間で直接処理するのではなく,学習した圧縮潜在空間で拡散およびノイズ除去プロセスを実行することで, 計算コストを大幅に削減しつつ、高品質な画像を効率的に生成できるように設計されている。画像生成AI「Stable Diffusion」などで使用されているコア技術。<br>
<br>
●『High-Resolution Image Synthesis with Latent Diffusion Models』(2021)<br>
<br>
<center><img src="data/images/LDM.svg"></center>
<br>

<br>(関連項目)<br>
・<a href="#DiffusionModel">Diffusion Model</a> (拡散モデル)<br>
・<a href="#DiT">DiT: Diffusion Transformers</a>
</li>

<br>

<li id="LifelongLearning">
<strong>Lifelong Learning(生涯学習)</strong><br>
Continual Learning (継続学習) の別名。<br>

<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
・<a href="#DEN">DEN: Dynamically Expandable/Growth Networks</a> (動的成長ネットワーク)
</li>

<br>
<li id="LLMAsAJudge">
<strong>LLM-as-a-Judge</strong><br>
人間や従来の評価基準ではなく、大規模言語モデル（LLM）自体を評価者（ジャッジ）として使用し、他のモデルの出力やパフォーマンスを評価する手法。<br>
<br>
●『From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge』(2024)<br>
・LLM-as-ajudge (LLMを判断基準とする)パラダイムについて, 何を判断すべきか、どのように判断すべきか、どのようにベンチマークすべきか, 課題, 将来展望を考察。<br>
<br>
●『How to Correctly Report LLM-as-a-Judge Evaluations』(2025)<br>
・LLM-as-a-Judge 評価におけるバイアスを補正し、不確実性を定量化するための統計的フレームワークを開発した。
</li>

<br>

<li id="LMC">
<strong>LMC: Linear Mode Connectivity (線形モード接続)</strong><br>
同じモデル構造とデータセットを用いて独立に学習された2つの異なる最適解（重みパラメータのセット）の間を、パラメータ空間上で損失値（または精度）をほぼ一定に保ちながら線形補間によって繋ぐことができるという性質。(モード接続性＋線形性)<br>
<br>
●『Linear Mode Connectivity in Multitask and Continual Learning』(2020)<br>
・同じタスクの異なる最小値が、通常、非常に単純な低誤差曲線で結ばれていることを示す最近の研究に着目し、マルチタスク解と継続的解も同様に結ばれているかどうかを検証する。<br>
・私たちは経験的に、そのような連結は確かに確実に達成できること、そしてさらに興味深いことに、両方の初期値が同じであることを条件として、<strong><span style="color:magenta;">線形経路で実現できることを発見した</span></strong>。<br>
・この観察結果を徹底的に分析し、継続学習プロセスにおけるその意義について議論する。<br>
<br>(関連項目)<br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#CatastrophicForgetting">Catastrophic Forgetting</a> (破局的忘却)
</li>

<br>

<li id="LoRA">
<strong>LoRA: Low-rank adaptation of LLM (低ランク適応)</strong><br>
大規模言語モデル（LLM）を、効率的かつ少ない計算コストで特定のタスクやデータに適応（ファインチューニング）させるための技術。<br>
<br>
●『LoRA: Low-Rank Adaptation of Large Language Models』 (2021)<br>
大規模言語モデル（LLM）の事前学習済み重みを凍結し、その横に低ランク行列 (\(A\)と\(B\)) のペアを追加。ファインチューニング時には、この小さな低ランク行列だけを学習させ、元のモデルの重みは変更しない。<br>
<strong><span style="color:magenta;">ファインチューニングに必要な学習可能なパラメータが劇的に少なくなる</span></strong>ため、効率的な学習を可能にした。<br>
<br>
</li>
<center><img src="data/images/LoRA.svg"></center>
<br>

<li id="LossLandscape">

<strong>Loss Landscape (損失景観)</strong><br>
ニューラルネットワークのパラメータ（重み）を軸とし、対応する損失関数の値を高さとした多次元の景観。モデルの学習は、この景観の低い場所（最適解）を探すことに相当する。<br>
ネットワークアーキテクチャー, 学習データ, 損失関数により景観が変わる。<br>
<br>
<a href="data/Papers_LossLandscape.html">Papers</a><br>
<br>
■教師あり学習<br>
　●『Visualizing the Loss Landscape of Neural Nets』(2018)<br>
<br>
<ul>
<li><strong>可視化手法の提案</strong><br>
<strong><span style="color:magenta;">高次元の損失関数を、2次元平面上にプロットする革新的な可視化手法を提案した</span></strong>。これにより、学習パラメータ空間の「地形」を視覚的に捉えることが可能になった。
</li><br>
<li><strong>平坦な最小値と汎化性能の関係</strong><br>
可視化の結果、最適解（最小値）の形状が、モデルの汎化性能に大きく影響することを発見した。この論文は、<strong><span style="color:magenta;">「平坦な最小値（flat minima）」にたどり着いたモデルは、より優れた汎化性能を持つことを視覚的に示した</span></strong>。
</li><br>
<li><strong>スキップコネクションの効果</strong><br>
ResNetなどのネットワークで使われる<strong><span style="color:magenta;">「スキップコネクション」が、損失ランドスケープをよりスムーズにする効果があることも明らかにした</span></strong>。
</li></ul>
<br>
<center><img src="data/images/LossLandscape.svg"></center>
<br>
■教師無し(自己教師)学習<br>
　●『WHAT SHAPES THE LOSS LANDSCAPE OF SELF SUPERVISED LEARNING ?』(2022/ICLR 2023)<br>
<center><img src="data/images/SSLlandscape.svg"></center>
<br>
自己教師学習（SSL）におけるランドスケープ。SSL損失は一般に、ネットワーク出力ペア間の相対角度（例：\(f(x)^Tf(x^\prime)\)）のみに依存する。したがって、線形ネットワーク（\(f(x) =Wx\)）のランドスケープは、大域的に回転対称性を持ち、原点を中心に対称となる。我々の理論によれば、原点における局所的な安定性が崩壊を決定し、データの変動が大きい場合（緑）は崩壊を防ぐ一方、強いデータ拡張（赤）は崩壊を促進する可能性がある。対角重み行列diag(r1, r2)を持つトイ線形モデルの損失をプロットする。（a）パラメータの1つを固定した場合の1次元ランドスケープ。（b-d）2次元ランドスケープ。（b）崩壊なし：原点は不安定な局所的最大値であり、周囲の局所的最小値が崩壊を回避する。次元的に崩壊した解は鞍点である。 (c) 次元崩壊：すべての安定固定点におけるw1の値はゼロに崩壊する。(d) 完全崩壊：原点は孤立した局所最小値となる。<br>
<br>
・Flat Minima(良好な汎化性能) ⇔ 多様性：トレードオフ<br>
　●『Sharpness-Aware Minimization for Efficiently Improving Generalization』(2024)<br>
　　・Loss Landscapeの鋭さを最小化する。<br>
　　　→ 分布内（ID）データと分布外（OOD）データの両方への堅牢な汎化において、重要な役割を果たす。<br>
　　　→ アンサンブル内の個々のメンバーの多様性が低下する傾向がある。<br>
<br>
■強化学習<br>
　⇒<a href="#RewardLandscape">Reward Landscape</a> (報酬ランドスケープ)<br>
<br>(関連項目)<br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)<br>
・<a href="#SkipConnection">Skip Connection</a> (スキップ接続)<br>
・<a href="#FlatMinima">Flat minima hypothesis</a> (平坦な最適解空間仮説)<br>
・<a href="#DataAugmentation">Data Augmentation</a> (データ拡張)<br>
・<a href="#RewardLandscape">Reward Landscape</a> (報酬ランドスケープ)<br>
・<a href="#RepresentationCollapse">Representation Collapse</a> (表現の崩壊)
</li>

<br>

<li id="LossOfPlasticity">

<strong>Loss of Plasticity (可塑性喪失) </strong><br>
あるシステムが、新しい情報に適応したり、学習したりする能力を徐々に失っていく現象。<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>

</li>

<br>

<li>
<strong>Lost in the Middle (「真ん中が失われる」現象)</strong><br>
モデルが長いコンテキスト（入力テキスト）を与えられた際、そのコンテキストの中間に存在する重要な情報を無視したり、見つけられなくなったりする現象。
</li>

<br>

<li id="LoTH">
<strong>LoTH: Language of Thought hypothesis (思考の言語仮説)</strong><br>
人間の思考は言語のような構造を持っており、その思考は「メンタリーズ (mentalese)」と呼ばれる生得的な（生まれつき備わっている）内的な言語によって行われるという認知科学・哲学の仮説。<br>
・思考は、私たちが日常的に話す言語 (日本語や英語など) と同様に、単語のような要素 (概念) とそれらを組み合わせる文法のような規則を持っているとされる。<br>
・「心の言語 (メンタリーズ) 」は学習によって獲得されるものではなく、人間が生まれつき持っている普遍的な認知メカニズムの一部であると主張される。<br>
・私たちが実際に話したり書いたりする言語 (公的言語) とは異なり、思考はまずこの内的な言語で行われ、その後に公的言語に翻訳されて表現されると考えられる。<br>
<br>
●『The language of thought』(1975)<br>
・LoTH仮説を提唱。<br>
<br>
●『A Complexity-Based Theory of Compositionality』(2024)<br>
・既知の概念の新しい組み合わせに体系的に適応する構成的表現は分布外一般化の強力な形態を可能にする。<br>
・しかし、構成性とは何かについて、測定可能かつ数学的な、満足のいく正式な定義を欠いている。<br>
⇒直感的な概念と一致する、構成性の形式的かつ定量的な定義(表現的構成性と呼ぶ)を提案した。<br>
　RC(R) = K(L) + K(Sentences|L) / (K(S) + K(R|S(Sentences)))<br>
<br>
●『Dreamweaver: Learning Compositional World Models from Pixels』(2025)<br>
・人間は、世界に対する認識を、色、形、動きのパターンといったオブジェクトとその属性に分解する生来の能力を持っている。<br>
・生の動画から階層的かつ構成的な表現を発見し、構成的な未来のシミュレーションを生成するニューラルアーキテクチャ、Dreamweaverを提案する。<br>
<center><img src="data/images/Dreamweaver.svg"></center>
・我々の目標は、構造化されていない連続的な感覚ストリームを抽象化されたモジュール型概念に結び付け、再利用可能な概念の記憶（概念ライブラリ）を構築することである。テキストは不要で、教師なし学習で構築される。これらの概念には、色や形といった静的な要素だけでなく、動きの方向や速度といった動的な要素も含まれる。最終的には、これらの概念を、例えば斬新な構成で再結合し、未知の世界を想像することを目指す。<br>
<br>
<center><img src="data/images/Dreamweaver2.svg"></center>
(左) Recurrent Block Slot Unit (RBSU) は、形状、色、動きの方向などの構成的および意味的概念を表すブロックスロットを維持および更新する。<br>
(右) Dreamweaverモデルは、将来のフレームを予測し、予測目的を最小化するようにトレーニングする。<br>
<br>
●『Cognitive Foundations for Reasoning and Their Manifestation in LLMs』(2025)<br>
・LLMが認知的要素を展開する方法、特に構造化されていない問題において、人間の認知と体系的な違いがあることを発見。<br>
・人間のような推論構造に基づくテスト時ガイダンスがLLMの性能を最大60%向上させる可能性があることを示した。<br>
<br>
●『ORION: Teaching Language Models to Reason Efficiently in the Language of Thought』(2025)<br>
・冗長な「思考」トークンの長い連鎖に依存するため、レイテンシの増大、冗長性、そして矛盾した推論パスが生じる。人間の推論は Mentalese と呼ばれる記号的かつ構成的な精神言語に基づいているという思考言語仮説に着想を得て、我々はモデルが同様にコンパクトなスタイルで推論するように訓練するフレームワークを導入する。Mentalese は抽象的な推論を超圧縮された構造化トークンとしてエンコードすることで、モデルがはるかに少ないステップで複雑な問題を解くことを可能にする。<br>

<br>(関連項目)<br>
・<a href="#CompositionalGeneralization">Compositional Generalization</a> (組み合わせ的一般化, 構成的汎化)<br>
・<a href="#CompositionalityGap">Compositionality Gap</a> (構成性ギャップ)<br>
・サピア＝ウォーフの仮説: 話者が使用する特定の公的言語 (日本語、英語など) が、その人の思考や世界観を決定または強く影響する。

</li>

<br>

<li id="LTH">
<strong>LTH: Lottery Ticket Hyposis (宝くじ仮説)</strong><br>
大規模なニューラルネットワークの中に、元のネットワークと同じかそれ以上の性能を発揮する、より小さな「サブネットワーク」が存在するという仮説。<br>
<center><img src="data/images/LTH.svg"></center>
<br>
<br>(関連項目)<br>
・<a href="#Pruning">Pruning</a> (枝刈り)<br>
・SLTH:The Strong Lottery Ticket Hypothesis (強い宝くじ仮説)<br>
　高性能なサブネットワーク(当りくじ) が<strong>ランダムに初期化されたニューラルネットワークの中に</strong>隠れているという仮説。<br>
　<br>
　●『The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms』(2025)<br>
　トランスフォーマーのマルチヘッドアテンションメカニズム内における強い宝くじチケットの存在を示し、適切に枝刈りされ, ランダムに初期化されたネットワークが任意のアテンション関数を高精度で近似できることを証明した。
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="M">M</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Mamba</strong><br>
トランスフォーマーモデルに代わる、効率的な次世代ネットワークアーキテクチャとして2023年に発表された、新しい機械学習モデル。<br>
トランスフォーマーが抱える「長いシーケンス（入力テキスト）を扱う際の計算コストの増大」という課題を解決するために開発された。
</li>

<br>

<li id="MathVista">
<strong>MathVista ベンチマーク</strong><br>
AI（マルチモーダル・モデル）の「視覚情報を伴う数学的推論能力」を測定するためのベンチマーク。<br>
従来の数学ベンチマークが主にテキストベースであったのに対し、MathVistaは図表、グラフ、幾何図形といった「画像」に含まれる数学的情報の理解と、それに基づく論理的な思考力を厳密に評価する。<br>
 数学パズル、幾何学、関数のグラフ、学術論文の図解など、28の既存データセットと3つの新規データセット（IQテスト、関数QA、論文QA）を統合した約6,141の問題で構成されている。<br>
<br>
●『MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts』(2023)<br>
<br>
<a href="https://llm-stats.com/benchmarks/mathvista">MathVista ベンチマーク</a>
</li>

<br>

<li id="MCP">
<strong>MCP: Model Context Protocol</strong><br>
AI (LLM, 大規模言語モデル) と外部のデータソースやツールを連携させるためのオープンな標準規格。<br>
2024年11月にAnthropic社が発表した。<br>
<br>(関連項目)<br>
・<a href="#ToolAugmentation">Tool Augmentation</a> (ツール拡張) ･･･ MCPはツール拡張のための標準規格<br>
</li>

<br>

<li>
<strong>Measurement Semantics (計測意味論)</strong><br>
言葉や文章の「意味」を、ある尺度や指標で定量的に測定・評価するための考え方や手法
</li>

<br>

<li id="Memorization">
<strong>Memorization to Generalization (暗記から汎化へ)</strong><br>
機械学習モデル、特にニューラルネットワークが、訓練データを単に丸暗記する段階（Memorization）から、学習したパターンを組み合わせて未知のデータにも応用できる段階（Generalization）へと移行するプロセス。<br>
<br>
●『Diffusion Probabilistic Models Generalize when They Fail to Memorize』(2024)<br>
●『On the Edge of Memorization in Diffusion Models』(2025)<br>
●『Memorization to Generalization: Emergence of Diffusion Models from Associative Memory』 (2025)<br>
・訓練中に「偽の状態(Spurious Phase)」が出現することが、モデルの記憶から汎化への移行を示すことを実証。<br>
・スプリアス状態は通常、記憶容量を超えたときに現れる望ましくないアーティファクトと見なされていたが、<strong><span style="color:magenta;">出現するパターンは、モデルの創造的合成、つまり基本的な記憶を組み合わせて新しい組み合わせを生み出すことを表していると提案している。</span></strong><br>
<br>
<center><img src="data/images/Memorization_to_Generalization.svg">
</center>
<center>スプリアスフェーズを経由して記憶(暗記)から汎化に移行する</center>

<br>
(関連項目)<br>
・<a href="#Grokking">Grokking</a><br>
・<a href="#DiffusionModel">Diffusion Model</a> (拡散モデル)の相転移
</li>

<br>

<li id="MentalRotation">
<strong>Mental Rotation (心的回転)</strong><br>
心の中で二次元または三次元の物体を回転させる認知機能のこと。<br>
<br>
●『Mental Rotation of Three-Dimensional Objects』(1971)<br>
　3次元回転した画像ペアが同じか否か判定するテストの平均応答時間は3次元回転角度に比例する。<br>
<br>
<center><img src="data/images/MentalRotation.svg"></center>
<br>
●『Large Vision Models can solve mental rotation problems』(2025)<br>
　(大規模視覚モデルは心的回転の問題を解決できる)<br>
<br>
●『Spatial Mental Modeling from Limited Views』(2025)<br>
　(限定された視点からの空間メンタルモデリング)<br>
<br>(関連項目)<br>
・<a href="#SpatialReasoning">Spatial Reasoning</a> (空間推論)
</li>

<br>

<li><strong>Meta Learning (メタ学習)</strong><br>
「学習の仕方を学習する」ための機械学習技術。
</li>

<br>

<li id="mHC">
<strong>mHC: Manifold-Constrained Hyper Connection </strong><br>
従来の「残差接続（Residual Connections / Skip Connections）」に代わる、あるいはそれを補完する新しい接続手法。<br>
・ネットワークの異なる深さの層から得られる情報を直接、あるいは密に結合（ハイパー接続）させる。<br>
・深いネットワークで発生しやすい「勾配消失」や「表現の崩壊（コラプス）」といった問題を抑え、より複雑なパターンの学習を可能にする。<br>
<br>
●『mHC: Manifold-Constrained Hyper-Connections』(2025)<br>
　ハイパーコネクションに代表される研究は、残差接続パラダイムを、残差ストリーム幅の拡張と接続パターンの多様化によって拡張してきた。この多様化は大幅な性能向上をもたらす一方で、残差接続に固有の恒等写像性を根本的に損なうため、深刻な訓練不安定性とスケーラビリティの制限を引き起こし、さらに顕著なメモリアクセスオーバーヘッドも生じる。これらの課題に対処するため、我々は多様体制約ハイパーコネクションを提案する。<br>
<br>(関連項目)<br>
・<a href="#SkipConnection">Skip Connection</a> (スキップ接続)<br>
</li>

<br>

<li id="MMLM">
<strong>MMLM: Multimodal Language Model (マルチモーダル言語モデル)</strong><br>
テキスト情報だけでなく、画像、音声、動画、3Dデータなど、複数の種類の情報（マルチモーダル）を扱えるモデルの総称。<br>
モード間の関連付けの手法<br>
<br>
<ul>
<li><a href="#SharedEmbeddingSpace">Shared Embedding Space (共有埋め込み空間)</a><br>
異なるモードのデータを同じベクトル空間にマッピングすることで、モード間の比較と関連付けを可能にする。OpenAI の CLIP (Contrastive Language–Image Pre-training) モデルが代表例。<br>
</li>
<br>
<li><a href="#MMFusion">Multi-modal Fusion (マルチモーダル融合)</a><br>
モデルの途中の層で複数のモードの情報を直接統合する。<br>
各モードの情報を個別のエンコーダーで処理した後、Transformerモデルのクロスアテンション層などを利用して、モード間の特徴を相互に参照させる。<br>
Google DeepMind の Flamingo モデルなどがこのアプローチを利用している。
</li>
<br>
<li><a href="#TokenLevelIntegration">Token-level Integration (トークンレベル統合)</a><br>
画像を言語モデルが理解できる「トークン」として扱い、テキストトークンと並べて処理する。<br>
VisualBERT や SimVLM といったモデルがこの手法を採用している。
</li>
</ul>

<br>(関連項目)<br>
・<a href="#VLM">VLM: Vision-Language Model (視覚・言語モデル)</a> ･･･ MMLMは、VLMを内包する、より広範な概念<br>
・<a href="#UnifiedTokenizer">Unified Tokenizer (統合トークナイザー)</a>
</li>
<br>

<li>
<strong>Modality Gap </strong><br>
画像とテキストのように異なる種類のデータ（モダリティ）を扱うマルチモーダルモデルにおいて、それぞれのモダリティの表現が、モデルの共通の埋め込み空間上で離れてしまう現象。
</li>

<br>

<li id="ModeConnectivity">

<strong>Mode Connectivity (モード連結性)</strong><br>
ニューラルネットワークのパラメータ空間において、学習によって得られた複数の局所的最適解（ミニマム）が、低い損失関数の値を保ったまま経路で接続されている現象。<br>
<br>
<center><img src="data/images/ModeConnectivity.png"></center>
<br>(関連項目)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)<br>
・<a href="#FlatMinima">Flat minima hypothesis</a> (平坦な最適解空間仮説)<br>
・<a href="#OverParameterized">Over-parameterized<a/> (過剰パラメータ化)<br>
・<a href="#LMC">LMC: Linear Mode Connectivity</a> (線形モード接続)
</li>

<br>

<li id="ModelMerge">
<strong>Model Merge (モデルマージ)</strong><br>
複数の学習済みモデルのパラメータ（重み）を統合し、単一の新しいモデルを構築する手法。<br>
・モデルスープは, モデルマージの一種。Model Soup ⊂ Model Merge<br>
・アンサンブル法は推論時にアンサンブルを実施, モデルマージは推論前(モデル作成時)にマージを実施。<br>
・RegMean、Task Arithmetic、TIES、DARE-TIES、KnOTS-TIES、KnOTS-DARE-TIES などの手法がある。<br>
　普遍的サブスペースアプローチは、これらの手法を上回る性能を示すとのこと。<br>
　→ <a href="#UniversalWeightSubspaceHypothesis">The Universal Weight Subspace Hypothesis</a> (普遍重み部分空間仮説)<br>
<br>(関連項目)<br>
・<a href="#ModelSoup">Model Merge</a> (モデルマージ)<br>
・<a href="#EnsembleMethod">Ensemble Method</a> (アンサンブル法)
</li>

<br>

<li id="ModelSoup">

<strong>Model Soup (モデルスープ)</strong><br>
異なるハイパーパラメータ（学習率、エポック数など）でファインチューニングされた複数のモデルの重みパラメータを平均化し、単一の高性能モデルを作成する手法。<br>
<br>
●『Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs (2018)』<br>
<br>
<ul><li>
・<strong><span style="color:magenta;">異なる初期値から学習をスタートさせた複数のモデルがたどり着く局所最小値（「モード」）が、低損失の経路で繋がっている現象を発見した</span></strong>。
</li><br><li>
・この発見に基づき、<strong><span style="color:magenta;">学習済みの複数のモデルパラメータを線形補間するだけで、低損失を維持しながら、より優れた汎化性能を持つアンサンブルモデルを作成できることを示した</span></strong>。これは、モデルアンサンブルを効率的に行う新しい方法を提示した。
</li></ul>
<br>
●『Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time』(2022)<br>
　(モデルスープ：複数のファインチューニング済みモデルの重み平均による、推論時間増加なしの精度向上)<br>
<br>(関連項目)<br>
・<a href="#ModelMerge">Model Merge</a> (モデルマージ)<br>
・<a href="#EnsembleMethod">Ensemble Method (アンサンブル法)</a><br>
・<a href="#LossLandscape">Loss Landscape (損失景観)</a><br>
・<a href="#TaskArithmetic">Task Arithmetic</a> (タスク算術)
</li>

<br>

<li id="MoE">


<strong>MoE: Mixture-of-Experts (専門家混合)</strong><br>
複数の小さな専門家モデル（エキスパート）と、どの専門家を使うかを選択するルーティングシステム（ルーター/ゲーティングネットワーク）を組み合わせたAIアーキテクチャ。<br>
<br>
●『Outrageously large neural networks: The sparsely-gated mixture-of-experts layer』(2017)<br>
　(途方もなく巨大なニューラルネットワーク：まばらにゲートされたエキスパート混合層)<br>
<br>
●『Mixture of Neuron Experts』(2025)<br>
　(ニューロンエキスパートの混合)
</li>
<center><img src="data/images/MoE.svg"></center>

<br>

<li id="MonocularGeometricDensePrediction">
<strong>Monocular geometric dense prediction（単眼幾何学的密予測）</strong><br>
単眼カメラからの入力画像のみを使用して、シーンの精密な3次元の幾何学的情報を推定する手法やタスク。<br>
・<strong>Monocular (単眼)</strong>　1つのカメラからの画像データのみを使用する。<br>
・<strong>Geometric (幾何学的)</strong>　推定される情報が、奥行き、表面の法線、3D空間内の位置といった、シーンの形状や構造に関連する物理的な量であることを指す。<br>
・<strong>Dense Prediction (密予測)</strong>　入力画像内の全てのピクセルに対して、対応する幾何学的情報を推定することを意味する。例えば、画像内の各ピクセルがどれだけ離れているかを予測する場合、画像全体を覆う奥行きマップ（デプス画像の形で表現されることが多い）が結果となる。<br>
<br>
●『Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model』(2025)<br> 
・大規模生成モデル、特に数十億の画像とテキストのペアで訓練された拡散モデルの出現は、「世界事前知識」— 幾何学、意味、物理的整合性の暗黙的な表現 — を導入した。しかし、これらの生成モデルを密予測タスクに直接適応させる既存のアプローチは、確率的な生成目的と、幾何学的推論に必要とされる決定的で正確な予測との間に根本的なミスマッチを抱えている。<br>
・Lotus-2は、拡散モデルを確率的ジェネレーターとして扱うのではなく、その事前学習済み重みを決定論的な幾何学的予測のための構造化された世界事前知識として活用するというパラダイムシフトを通じて、これらの制限に対処する。このアプローチは、既存の大規模手法が必要とする訓練データのわずか0.09% (59K) しか使用せずに、単眼深度推定で最先端の性能を達成する。<br>
<center><img src="data/images/Lotus2.svg"></center>
</li>

<br>

<li id="MMFusion">
<strong>Multi-modal Fusion (マルチモーダル融合)</strong><br>
複数の異なる種類のデータ（モダリティ）を組み合わせて統合し、より包括的な理解や高い精度を達成するための技術。<br>
<br>
●『Everything at Once – Multi-Modal Fusion Transformer for Video Retrieval』(2022)<br>
●『Flamingo: a Visual Language Model for Few-Shot Learning』(2022)<br>
　論文は<a href="https://arxiv.org/abs/2204.14198">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2204.14198v2">こちら</a>
<center><img src="data/images/Flamingo.svg"></center>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="N">N</h2>
<p>
<div class="styleBullet">
<ul>
<li id="NAS">
<strong>NAS: Neural Architecture Search</strong><br>
特定のタスクにおいて、最も性能が良いニューラルネットワークの構造（アーキテクチャ）を自動的に見つけ出す技術。<br>
<br>
●『Random search for hyper-parameter optimization』(2012)<br>
　(ハイパーパラメータ最適化におけるランダム探索)<br>
　ハイパーパラメータ最適化における強力なベースラインとしてランダムサーチを確立した。<br>
<br>
●『Neural architecture search with reinforcement learning.』(2016)<br>
　(強化学習を用いたニューラルアーキテクチャ探索)<br>
　強化学習を用いてニューラルアーキテクチャ探索（NAS）の概念を導入した記念碑的な論文。<br>
<br>
●『Efficient Global Neural Architecture Search』(2025)<br>
　(効率的なグローバルニューラルアーキテクチャ探索)<br>
　EMNISTやKMNISTなどのデータセットで最先端の結果を達成し、CIFARで競合する性能を発揮するとともに、探索時間を大幅に短縮し、実世界の顔認識タスクへの高い転用可能性を示している。
</li>

<br>

<li id="NEPA">
<strong>NEPA: Next-Embedding Predictive Autoregression </strong></br>
生のデータ（ピクセルや単語）を直接予測するのではなく、データの抽象的な表現である「潜在的な埋め込み（Embedding）」を自己回帰的に予測するフレームワーク。<br>
・Masked Autoencoderは埋め込みベクトルを使って, マスクされたピクセルを予測する。<br>
・NEPA は埋め込みベクトル自体を予測する。<br>

\[
\begin{array}{l|l|l}
\text{手法} & \text{予測対象} & \text{特徴} \\
\hline
\text{Next-Token Prediction} & \text{離散トークン(単語など)} & \text{LLMの主流} \\
\hline
\text{Masked Reconstruction} & \text{マスクされたピクセル} & \text{画像の一部を復元。計算コストが高い} \\
\hline
\text{NEPA} & \text{埋め込みベクトル} & \text{情報が圧縮された状態で予測するので効率的} 
\end{array}
\]


<br>
●『Next-Embedding Prediction Makes Strong Vision Learners』(2025)<br>
　NEPA: Next-Embedding Predictive Autoregression を提唱した。<br>

<center><img src="data/images/NEPA.svg"></center>

　この手法は、画像をパッチに分割し、それらを連続ベクトル空間に埋め込み、先行する埋め込みに基づいて後続の埋め込みを予測するようにトランスフォーマーを訓練することで機能します。このアプローチは、大規模言語モデルの成功を牽引した次トークン予測を模倣していますが、離散トークンではなく埋め込み空間で直接動作します。その結果、著しくシンプルでありながら効果的な自己教師あり学習フレームワークが実現し、大幅なアーキテクチャの複雑さを必要とせずに、最先端の手法と競争力のある性能を達成します。

<center><img src="data/images/NEPA2.svg"></center>
JEPAのような手法が異なるモダリティに対して別々のエンコーダと予測器を使用するのに対し、NEPAは自己回帰型言語モデルと同様の単一のバックボーンアーキテクチャを使用します。<br>
<br>(関連項目)<br>
・<a href="#JEPA">JEPA: Joint-Embedding Predictive Architecture</a>
</li>

<br>


<li id="NeuralCollapse">
<strong>Neural Collapse </strong><br>
十分に訓練されたニューラルネットワークの最終層の表現が高度に構造化された形状に収束する現象。<br>

<br>
各クラスの特徴ベクトルがクラスごとの平均ベクトルに収束し、それらのクラス平均が「等角な単純体」（Simplex Equiangular Tight Frame: ETF）と呼ばれる非常に均整の取れた構造を形成する。<br>
</li>

<br>

<li>

<strong>Neural ODE</strong><br>
ニューラルネットワークの層の連なりを、連続的な常微分方程式として表現する革新的なモデル。<br>
従来のニューラルネットワークが、層ごとに離散的な変換を適用するのに対し、Neural ODEは隠れ状態の連続的な時間発展を学習する。<br>
</li>

<br>

<li id="NFL">
<strong>NFL: No Free Lunch Theorem (ノーフリーランチ定理)</strong><br>
あらゆる問題に普遍的に通用する万能なアルゴリズムは存在しない,という定理。<br>
<br>
●『The lack of a priori distinctions between learning algorithms』(1996)<br>
　(学習アルゴリズム間の先験的な区別の欠如)<br>
　教師あり学習における「ノーフリーランチ」 (NFL) 定理の基礎論文。<br>
<br>
●『The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning』(2023)<br>
　(ノーフリーランチ定理、コルモゴロフ複雑性、そして機械学習における帰納バイアスの役割)<br>
　「No Free Lunch」定理が実世界の低複雑度データには適用されないことを示し、現代のニューラルネットワークが固有の「単純性バイアス」を持っており、それによって多様なタスクやデータスケールにわたる広範な汎化が可能になることを示した。
</li>

<br>

<li id="NGD">
<strong>NGD: Natural Gradient Descent (自然勾配降下法)</strong><br>
通常の勾配降下法が持つ課題を解決するために、モデルのパラメーター空間の幾何学的構造を考慮して勾配の向きを補正する最適化アルゴリズム。<br>
<br>
●『脳・心・人工知能』ブルーバックス(甘利俊一)<br>
　学習を進めていくと、損失関数(誤差)は順調に減っていくが、そのうちにほとんど減らなくなる。これが Plateau (プラトー)だ。<br>
<center><img src="data/images/Plateau.svg"></center>

　ここで学習が終わりかというと、そんなことはない。さらに辛抱強く学習を進めていくと、再び急峻に減り始める。しかしまたプラトーにつかまって学習が停滞する。この原因は何なのか、それを避けるうまい方法はないものだろうか。<br>
　：<br>
パーセプトロンの学習は、シナプスの重みのなすパラメータの空間で進行する。ところがここに問題があった。<br>
　：<br>
<strong><span style="color:magenta;">損失関数の勾配をリーマン空間の中で考えればよい。式は少し面倒になるが、これを用いるとプラトーは消失し、素早い学習ができる。この方式を「自然勾配学習法」という</span></strong>が、これはいまブームの深層学習でも有効である。ただ、計算がややこしいので、いろいろな簡便法が世界で研究されている。<br>
<br>
●『Egalitarian Gradient Descent: A Simple Approach to Accelerated Grokking』(2025)<br>
　(平等勾配降下法：加速グロッキングへのシンプルなアプローチ)<br>
　論文は<a href="https://arxiv.org/abs/2510.04930v1">こちら</a><br>
　・（確率的）勾配降下法の速度が、勾配の異なる主方向（すなわち、特異方向）に沿って非対称になることで、グロッキングが誘発されることを、経験的かつ理論的に示す。<br>
　・次に、勾配を正規化し、すべての主方向に沿ったダイナミクスが全く同じ速度で進化するようにする、単純な修正法を提案する。<br>
　・この修正法 (我々は平等主義勾配降下法（EGD）と呼び、<strong><span style="color:magenta;">自然勾配降下法を慎重に修正した形式と見なすことができる</span></strong>) が、<strong><span style="color:magenta;">はるかに高速にグロッキングする</span></strong>ことを確立する。<br>
<br>
<br>(関連項目)<br>
・<a href="#Plateau">Plateau (プラトー)</a><br>
・<a href="#Grokking">Grokking</a>
</li>

<br>

<li id="NGU">
<strong>NGU: Never Give Up</strong><br>
・報酬が得られにくい（疎な報酬）環境でエージェントがうまく機能することを目指して開発された強化学習の分野における重要な手法の一つ。<br>
・エピソード的新規性と内発的動機付けを組み合わせる。<br>
<br>
●『Never Give Up: Learning Directed Exploration Strategies』(2020)<br>
・Atariの57のゲームのうち、Montezuma’s Revenge や Pitfall などの一部のゲームがでは、複雑な行動を取らないと報酬を得ることができず, 人間を超えるAIは長らく現れなかった。<br>
・NGU戦略は, 疎な報酬環境における強化学習の探索問題を解決するための重要なブレークスルーとなった。<br>
　(デモや手作業で作成した特徴量を使用せずに、Pitfall!ゲームにおいてゼロ以外の報酬（平均スコア8,400）を達成した最初のアルゴリズムになった)<br>
<br>
～その後～<br>
<br>
●『Agent57: Outperforming the Atari Human Benchmark』(2020)<br>
・Atari 2600の全57種類のゲーム全てにおいて、人間のパフォーマンスを上回った最初のAIシステム。<br>
・探索（新しい行動を試す）と活用（学習済みの最適な行動をとる）のバランスを動的に調整する「メタコントローラー」を導入。<br>
・NGUやR2D2など, 既存の強化学習アルゴリズムの進化版・組み合わせとして開発された。<br>
<br>
●『Human-level Atari 200x faster』(2023)<br>
・Agent57と比較して200倍の速さでアタリの全ゲームにおいて人間レベルのパフォーマンスを達成した。<br>
　-  Agent57：約800億フレームという膨大な量の環境との相互作用（プレイ経験）が必要<br>
　- 200x(MEMEエージェント):3億9000万フレームの経験で人間レベルのパフォーマンスを達成した。 

</li>

<br>

<li id="NLoS">
<strong>NLoS: Non-Line-of-Sight imaging (見通し外画像処理, 視線外画像処理)</strong><br>
カメラやセンサーの直接的な視野の外にある隠れた物体やシーンを画像化したり認識する技術。<br>
・<strong>信号の照射と反射</strong>:　レーザー光や音波などを壁などの「中継面」に照射する。<br>
・<strong>散乱と隠れた物体への到達</strong>:　中継面で散乱した信号は、直接は見えない場所にある隠れた物体に到達し、そこから再び反射する。<br>
・<strong>再度の反射と検出</strong>:　反射した信号は再び中継面に戻り、検出器（カメラやセンサー）によって捉えられる。<br>
・<strong>データ解析</strong>:　検出された信号 (特に光子の飛行時間(Time-of-Flight, ToF) 情報など）の時間的・空間的なデータを高度なアルゴリズム (計算イメージング、深層学習など)で解析し、隠れた物体の位置、形状、動きなどを推定・再構成する。<br>
※ ミリ波や Wi-Fi や超音波を使う手法もある。<br>
<br>
●『Accidental pinhole and pinspeck cameras: revealing the scene outside the picture
』(2012)<br>
　(偶然のピンホールカメラとピンスペックカメラ：写真の外側の光景を明らかにする)<br>
<center><img src="data/images/NLoS.png"></center>
・開いた窓から光が部屋に入る。<br>
・窓の反対側の壁には、光と影の投影された模様が見える。暗い部分は影なのだろうか ?<br>
<center><img src="data/images/NLoS2.png"></center>
・外光に照らされた室内に陰影の模様が生まれる。<br>
・影は実際にはぼやけた像であり、影ではない。この部屋は、偶然にカメラ・オブスキュラを作り出したのである。<br>
<br>
●『Neural network identification of people hidden from view with a single-pixel, single-photon detector』(2017)<br>
　(単一ピクセル・単一光子検出器を用いた視界から隠れた人物のニューラルネットワーク識別)<br>
●『Turning Corners into Cameras: Principles and Methods』(2017)<br>
　(角をカメラに変える：原理と手法)<br>
●『Computational periscopy with an ordinary digital camera』(2019)<br>
　(一般的なデジタルカメラを用いた計算潜望鏡)<br>
●『Non-line-of-sight imaging』(2019)<br>
　(視線外イメージング)<br>
●『Wave-based non-line-of-sight imaging using fast f-k migration』(2019)<br>
　(高速f-kマイグレーションを用いた波動ベース視線外イメージング)
</li>

<br>

<li id="NLU">
<strong>NLU: Natural Language Understnading (自然言語理解)</strong><br>
NLP: Natural Language Processing (自然言語処理) というAI分野のサブフィールド。人間が日常的に使用する自然言語の意図、意味、文脈をコンピュータが正確に解釈することを目指す。<br>
<br>
●『People thinking about thinking people: The role of the temporo-parietal junction in theory of mind』(2003)<br>
　(考える人について考える人：心の理論における側頭頭頂接合部の役割)<br>
・心的状態に関する言語を理解することが、機能的に特異的な非言語的脳領域（rTPJ）を動員することを示した。<br>
<br>
●『Dissociating language and thought in large language models』(2024)<br>
　(大規模言語モデルにおける言語と思考の分離)<br>
・形式言語能力（言語の規則とパターンに関する知識）と機能言語能力（世界における言語の理解と使用）を区別して LLM を評価する。<br>
・LLM は形式能力に関しては驚くほど優れているが, 機能的能力タスクでのパフォーマンスは依然としてムラがあり、多くの場合、専門的な微調整や外部モジュールとの連携が必要である。<br>
・この区別は、形式能力と機能的能力が異なる神経メカニズムに依存することを示した人間の神経科学に基づいている。<br>

<br>
●『What does it mean to understand language?』(2025)<br>
　(言語を理解するとはどういうことか？)<br>
・Exportation Hypothsis (輸出仮説) を通じて、脳が言語の「深い理解」の偉業をどのように達成するのか、体系的な説明を提供する。<br>
・このフレームワークは、言語処理の根本的に異なる2つのレベルを区別する。<br>
・主に左半球に位置する中核言語システムは、著者らが「浅い理解」と呼ぶもの、すなわち構文の抽出、単語の認識、抽象的な意味表現の形成を扱う。<br>
・これを超えて、「深い理解」は、心の理論、空間ナビゲーション、物理学、知覚、記憶に特化した非言語選択的な脳領域に情報を輸出することを必要とする。<br>
・真に根拠のあるAI理解のためには類似のモジュール型アーキテクチャが必要であることを示唆した。<br>
<center><img src="data/images/NLU.svg"></center>
<center>言語システムは、言語内容の深い理解を支える言語外システムに情報をエクスポートする</center>

</li>

<br>

<li id="NoisyTVProblem">
<strong>Noisy TV problem (ノイジーテレビ問題)</strong><br>
強化学習における好奇心ベースの探索手法が抱える問題の一つ。<br>
テレビの砂嵐(画面にランダムな画像やノイズが表示され続けるテレビ)のような予測不能でランダムな変化を起こす要素にエージェントが固執し、本来の目的を達成するための有益な探索が進まなくなる現象を指す。<br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven（好奇心駆動型）</a>
</li>

<br>

<li id="NoveltySearch">
<strong>Novelty Search (新規性探索)</strong><br>
進化計算や強化学習などの分野で用いられる探索アルゴリズムの一種。あらかじめ定義された目標や適応度関数を直接的に最適化するのではなく、過去に生成された解とは異なる「新奇性」を持つ行動や解を探索・評価することに焦点を当てる。<br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven（好奇心駆動型）</a><br>
・<a href="#IntrinsicMotivation">Intrinsic Motivation (内発的動機付け)</a>
</li>

<br>

<li>
<strong>NTK: Neural Tanget Kernel</strong><br>
幅が無限大のニューラルネットワークを、ある特殊な「カーネル法」で訓練されたモデルとして捉え、その学習過程と挙動を理論的に解析するための概念。
</li>

<br>

<li>

<strong>NTM: Neural Turing Machines</strong><br>
ニューラルネットワークのパターンマッチング能力と、チューリングマシンのようなコンピューターのアルゴリズム処理能力を組み合わせた、リカレントニューラルネットワークの一種。<br>
DeepMind社によって2014年に発表された。<br>
その後、この研究を発展させた微分可能ニューラル・コンピューター（DNC）が登場し、より洗練されたアテンション機構によってパフォーマンスが向上した。<br>
しかし、2020年代に入ると、NTM や DNC の役割は、Transformer のような大規模言語モデル（LLM）の発展によって部分的に代替されている。

</li>

<br>

<li id="NVS">
<strong>NVS: Novel view synthesis (新規視点合成)</strong><br>
撮影された複数の画像データから、撮影されていない新しい視点からの画像を合成する技術。<br>
<br>
(関連項目)<br>
・<a href="#3DGS">3D Gaussian Splating</a><br>
・<a href="#NeRF">NeRF</a><br>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="O">O</h2>
<p>
<div class="styleBullet">
<ul>

<li id="OccamsRazor">
<strong>Occam's Razor (オッカムの剃刀(かみそり))</strong><br>
ある事柄を説明するのに、必要以上に多くを仮定すべきでない, とする指針(思考節約の原理)。<br>
<br>
●『Deep Learning as a Convex Paradigm of Computation: Minimizing Circuit Size with ResNets』(2025)<br>
　(計算の凸パラダイムとしてのディープラーニング：ResNetによる回路サイズの最小化)<br>
・Computational Occam's Razor(計算論的オッカムの剃刀)という概念を中心に展開しており、効果的な学習アルゴリズムはデータに適合する最も単純な計算表現を見つけるべきであるとしている。<br>
・理論的な理想はコルモゴロフ複雑性(データを生成する最短のプログラムを見つけること)を最小化することだが、このアプローチは本質的に計算不能。<br>
・本論文では、代わりに、与えられた関数をある許容誤差内で近似できる最小のバイナリ回路を見つけようとする最小回路サイズ問題 (MCSP: Minimum Circuit Size Problem) に焦点を当てている。
</li>

<br>

<li id="OneStepGenerator">
<strong>One-Step Generator</strong><br>
拡散モデルのような多段階の生成プロセスを、わずか1回のステップで完了させることのできる生成モデル。<br>
<br>
●『Who Said Neural Networks Aren't Linear?』(2025)<br>
　(ニューラルネットワークは線形ではないと誰が言った？)<br>
　論文は<a href="https://arxiv.org/abs/2510.08570">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.08570v1">こちら</a><br>
　最も説得力のある応用の一つは、リニアライザーが数百の拡散サンプリングステップを単一の順伝播パスに統合する方法を示すもの。<br>
<br>
●『Terminal Velocity Matching』(2025)<br>
・フローマッチングの一般化であり、高精度な1ステップおよび数ステップ生成モデリングを可能にする終端速度マッチング（TVM）を提案する。<br>
<br>
●『Adversarial Flow Models』(2025)<br>
・敵対的モデルとフローモデルを統合した生成モデルの一種である敵対的フローモデルを提案。<br>
・従来のGANは、生成器がノイズとデータ分布間の任意の輸送計画を学習するが、本手法では、ノイズからデータへの決定論的なマッピングを学習する。これは、フローマッチングモデルと同じ最適な輸送である。これにより、敵対的トレーニングが大幅に安定化する。<br>
<center><img src="data/images/AFM.svg"></center>
</li>

<br>

<li id="OOD">
<strong>OOD: Out-of-Distribution Generalization (分布外汎化)</strong><br>
機械学習モデルが、訓練データとは統計的な性質（分布）が異なる未知のデータに対しても、高い性能を発揮する能力を指す。<br>
<br>
●『Creativity and artificial intelligence』(1998) 論文は<a href="https://www.sciencedirect.com/science/article/pii/S0004370298000551">こちら</a>, 機械翻訳は<a href="https://boyoyon.github.io/HTMLs_translated_to_Japanese/papers/1998_Creativity_and_AI/Creativity_and_artificial_intelligence.html">こちら</a><br>
　(創造性と人工知能)<br>
「AI技術は、3つの方法で新しいアイデアを生み出すために使用できる。それは、馴染みのあるアイデアの新しい組み合わせを生み出すこと、概念空間の可能性を探求すること、および以前は不可能だったアイデアの生成を可能にする変革を行うことである。」<br>
　→ OMEGA(2025)の構成的汎化,　探索的汎化, 変革的汎化につながる<br>

<!--
<br>
　本題(OOD)とは関係ないが, ユーモアの生成例として Jape が紹介されている。<br>
　(Q) どんな殺人犯が食物繊維を持っている？<br>
　(A) シリアルキラー<br>
　　　cereal killer：穀物殺人犯  ⇔  serial killer：連続殺人犯<br> 
<br>
　(Q) 奇妙な市場を何と呼ぶ？<br>
　(A) Bizarre Bazzar (奇妙なバザール)<br>
　　　Bizarre（奇妙な）と Bazaar（バザール、市場）の発音が非常に似ている<br>
<br>
　(Q) 落ち込んでいる列車を何と呼ぶ？<br>
　(A) ローコモーティブ（低い機関車）<br>
　　「locomotive」(機関車) を「Low-comotive」と区切る。<br>
　　「low」は「低い」だけでなく「落ち込んだ」の意味もある<br>
<br>
　(Q) 葉っぱと車の違いは？<br>
　(A) 落ち葉はブラシで掃き集め、車は急ブレーキをかける。<br>
　　　brush and rake（掃き集める、熊手）と rush and brake（急ブレーキ）<br>
-->
<br>
●『Towards a theory of out-of-distribution learning』 (2021)<br>
・現在の文献では、分布内学習パラダイムと分布外学習パラダイムの多くについて正式な定義が欠如していることは注目に値する。これらの学習設定について適切かつ普遍的に合意された定義を確立することは、異なる学習シナリオにおけるアイデアの進化を徹底的に探求し、これらの学習者に対する一般化された数学的境界を導き出すために不可欠である。<br>
<br.
本論文では、PAC 学習フレームワークを用いて、様々な学習タスクを時系列的に定義するアプローチを提案することで、この問題に対処することを目指す。<br>
<br>
まず、分布内学習から始め、最近提唱された生涯学習あるいは継続学習へと進む。<br>
<br>
●『OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization』(2025)<br>
　(OMEGA: LLMは数学において枠にとらわれない推論ができるか？—探索的、構成的、変革的汎化の評価)<br>
<br>
・<strong>Exploratory Generalization (探索的汎化)</strong>
　モデルが学習した戦略を同じ問題タイプのより複雑なインスタンスに適用できるかどうかを評価する。<br>
　例えば、モデルが八角形内の長方形を数えることを学習した場合、十二角形内の同じタスクを処理できるか? これは、既知のアプローチをより難しい変種にスケールアップするモデルの能力をテストする。<br>
<br>
・<strong>Compositional Generalization (構成的汎化)</strong>
　個別に学習したスキルの統合を評価する。モデルは、個別の数学的テクニックを単独で訓練され、それらの組み合わせを必要とする問題でテストされる。<br>
　典型的な例としては、最大公約数（GCD）の計算と多項式の根の発見を別々に訓練し、その後、両方のスキルを同時に必要とする問題でテストすることが挙げられる。<br>
<br>
・<strong>Transformative Generalization (変革的汎化)</strong>
　最も困難な評価であり、モデルが馴染みのあるが非効率的な戦略を捨て、より斬新で効果的なアプローチを採用できるかどうかをテストする。<br>
　これは、ブレークスルーとなる解決策がしばしば従来のメソッドを放棄することを必要とする、真の数学的創造性を反映している。<br>
<br>
　結果は、モデルのサイズや推論時の計算能力を単にスケールアップするだけでは、人間のような数学的推論を達成するには不十分である可能性を示している。むしろ、この研究は、スキルの構成と創造的な問題解決における根本的な限界に対処する「より賢いスケーリングソリューション」の必要性を示唆している。<br>


<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)･･･概略図比較あり,　 <a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習=継続学習の別名)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
</li>

<br>

<li id="OODShock">
<strong>OOD Shock: Out-of-Distribution Shock (OODショック)</strong><br>
AIモデルが学習時 (In-Distribution) には遭遇しなかった、未知の統計的性質を持つデータ (Out-Of-Distribution: OOD) に直面した際に、パフォーマンスが劇的に低下したり予期せぬ挙動を示したりする現象。<br>
<br>
AIの学習環境を「小さな世界（Small World）」と見なすと、現実の「大きな世界（Big World）」には学習データに含まれない未知の状況（OOD）が無数に存在することになる。この「世界の広大さ」ゆえに、AIが現実世界にデプロイされた際に必ずOOD Shockが発生するというビッグワールド仮説に基づく重要な視点。<br>
<br>(関連項目)<br>
<a href="#BigWorldHypothesis">Big World Hypothsis</a> (ビッグワールド仮説)
</li>

<br>

<li>
<strong>Open-Ended Generation </strong><br>
明確な答えや単一の目標を設定することなく、AIが創造的かつ多様なコンテンツを生成する能力のこと。
</li>

<br>

<li id="Oracle">
<strong>Oracle (神託)</strong><br>
<br>
・<strong>Oracle Machine (オラクルマシン)</strong><br>
　理論計算機科学において、特定の決定問題や関数問題を瞬時に解決できる「神託（オラクル）」へのアクセス権を持つ抽象的な計算モデル。<br>
<br>
・<strong>Reasoning Oracle (推論オラクル)</strong><br>
　機械学習では、特定のデータポイントに対する正解ラベルを提供できる「理想的な情報源」を比喩的に「オラクル」と呼ぶことがある。これは通常、人間によるアノテーション（ラベル付け）を指す。<br>
<br>
　大規模言語モデル(LLM)の分野では、「推論オラクル」や「推論メカニズム」といった言葉が、モデルの推論能力を評価したり、向上させたりするための技術を指して使われている。例えば、質問応答システムにおいて、モデルが最終的な答えを出す前に中間的な推論ステップ (思考連鎖、Chain-of-Thought) を生成する手法は、推論能力を高めるために「オラクル」として機能する中間テキストを生成していると見なせる。<br>
<br> 
・<strong>Test Oracle (テストオラクル)</strong><br>
　AIシステムのテストにおいて、そのシステムの出力が正しいかどうかを判断するための基準やメカニズムを指す場合がある。
</li>

<br>

<li id="OverParameterized">
<strong>Over-parameterized (過剰パラメータ化)</strong><br>
機械学習モデルのパラメータ（学習可能な変数）の数が、学習データ数よりもはるかに多い状態。<br>
<br>
●『Loss landscapes and optimization in over-parameterized non-linear systems and neural networks』(2020)<br>
　論文は<a href="https://arxiv.org/abs/2003.00307">こちら</a>,　解説は<a href="https://www.alphaxiv.org/ja/overview/2003.00307v2">こちら</a><br>
<br>
従来の凸性仮定を超えた新しい数学的フレームワークを提案し、過剰パラメータ化された領域で最適化がなぜこれほど効果的に機能するのかを説明した。<br>
重要な洞察は、パラメータ数が訓練例の数を上回る過剰パラメータ化システムが、パラメータが不足するシステムとは根本的に異なる最適化特性を示すこと。<br>
<br>
<center><img src="data/images/Over-parameterized.svg"></center>


<br>(関連項目)<br>
・<a href="#DoubleDescent">Double Descent</a> (二重降下)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)<br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)
</li>

<br>

<li>
<strong>Over-Squashing</strong><br>
グラフニューラルネットワーク（GNN）でメッセージ伝播を行う際に、遠く離れたノードからの情報がボトルネックによって圧縮され、情報が歪んだり失われたりする現象のこと。<br>
これにより、GNNがグラフ上の長距離にあるノード間の関係性を効率的に学習できなくなるという問題が生じる。<br>
※ 直訳は「スカッシュ(押しつぶし)し過ぎ」
</li>

<br>

<li>
<strong>Overthinking (考えすぎ, 過剰思考)</strong><br>
意思決定や問題解決に必要とされる範囲を超えて、物事を延々と、かつ非建設的に考え続けてしまう状態。<br>
<br>
●『Overthinking the Truth: Understanding how Language Models Process False Information』(2023)<br>
　(真実の過剰な深掘り：言語モデルにおける偽のデモンストレーションの処理メカニズムの解明)<br>
　論文は<a href="https://arxiv.org/abs/2307.09476">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2307.09476v3">こちら</a><br>
<br>
●『Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs』(2024)<br>
　(「2+3=?」に考えすぎないで：o1型LLMの過剰思考について)<br>
　論文は<a href="https://arxiv.org/abs/2412.21187">こちら</a>,　解説は<a href="https://www.alphaxiv.org/ja/overview/2412.21187v2">こちら</a><br>
<br>
●『Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models』(2025)<br>
　(考えすぎをやめよう：大規模言語モデルの効率的な推論に関する調査)<br>
　論文は<a href="https://arxiv.org/abs/2503.16419">こちら</a>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="P">P</h2>
<p>
<div class="styleBullet">
<ul>
<li id="PAC">
<strong>PAC Learning: Probably Approximately Correct Learning (確率的で近似的に正しい学習) </strong><br>
機械学習の計算論的学習理論における数学的な枠組みの一つ。<br>
「確率的で、近似的に正しい学習ができること」を数学的に保証するための理論。<br>
　訓練データとテストデータが同じ確率分布からサンプリングされる (i.i.d.独立同分布), 確率分布は変化しない, などを前提としており, OOD(分布外)学習などの比較対象(古典的枠組み)とされることがある。<br>

<br>
<strong>●『A Theory of the Learnable』</strong>(1984)<br>
　(学習可能なものの理論)　論文は<a href="https://web.mit.edu/6.435/www/Valiant84.pdf">こちら</a><br>
　「PAC 学習フレームワーク」を導入した基礎論文<br>
<br>
<strong>●『Thoughts on Hypothesis Boosting』</strong>(1988)<br>
　(仮説ブースティングについての考察)　論文は<a href="https://www.cis.upenn.edu/~mkearns/papers/boostnote.pdf">こちら</a><br>
　PAC学習モデルを基盤に、弱い学習器(ランダムな推測よりもわずかに優れた性能の識別器を生成する学習器)を組み合わせて強い学習器 (高い確率で、ほぼ正確に識別できる識別器を生成する学習器)へブースト(昇格)させることができるのか？という問いかけを行った。<br>
<br>
<strong>●『The Strength of Weak Learnability』</strong>(1990）<br>
　(弱い学習可能性の強み)　論文は<a href="https://link.springer.com/content/pdf/10.1007/BF00116037.pdf">こちら</a><br>
　弱い学習器の存在と強い学習器の存在が数学的に等価であることを証明した。つまり、<strong><span style="color:magenta;">弱い学習器があれば、そこから強い学習器を作り出すことができる</span></strong>ことを証明し，後のブースティングアルゴリズムの基礎となる構成法を示した。<br>
　　↓<br>
●『Stacked Generalization』(1992)<br>
●『A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting』AdaBoost (1995)<br>
●『Greedy Function Approximation: A Gradient Boosting Machine』GBDT(Gradient Boosting Decision Tree) (1999)<br>
●『Random Forests』(2001)<br>
　　：
<br>
　DNN の中間層, 訓練中の Drop Out はネットワークのアンサンブルによるブースティングと見なすことができる。<br>
<br>(関連項目)<br>
・<a href="#EnsembleMethod">Ensemble Method (アンサンブル法)</a><br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization (分布外汎化)</a><br>
</li>

<br>

<li id="PathVQA">
<strong>PathVQA ベンチマーク</strong><br>
AIによる「病理画像の視覚的質問応答（Visual Question Answering）」を評価するための世界初の大規模データセットおよびベンチマーク。<br>
病理学（Pathology）の専門的な画像に対し、AIがどれだけ正確に質問に答えられるかを測る。<br>
約5,000枚の病理画像（スライド画像や疾患の自然画像）に対し、32,000件以上の質問応答ペア（QA）が含まれている。<br>
2020年の発表当初、AIの自由記述形式の正答率はわずか数％（3%未満）と極めて低いものだったが、Qwen3 VLベースの医療モデルなどは、人間の専門家に迫る高い精度（90%超）を記録し始めている。 <br>
<br>
●『PathVQA: 30000+ Questions for Medical Visual Question Answering』(2020)
</li>

<br>

<li>
<strong>Perceptual Metric (知覚メトリック, 知覚的距離)</strong><br>
画像や音声などの信号を、人間が感じる品質や類似性にどれだけ近い形で評価できるかを測る指標のこと。<br>
LPIPS (Learned Perceptual Image Patch Similarity), FID (Fréchet Inception Distance)などがある。
</li>
<center><img src="data/images/LPIPS1.svg"></center>
<!--
<center><img src="data/images/LPIPS2.svg"></center>
<center><img src="data/images/LPIPS3.svg"></center>
-->
<br>

<li><strong>PINNs: Physics-Informed Neural Networks</strong><br>
ニューラルネットワークの出力が、物理法則の方程式を満たすように学習を制約する。通常の Loss の他に Physics Loss (物理損失) を使う。<br>
<br>
●『Artificial Neural Networks for Solving Ordinary and Partial Differential Equations』(1997)<br>
　論文は<a href="https://arxiv.org/abs/physics/9705023">こちら</a><br>
ニューラルネットワークの出力の導関数を計算することによって、微分方程式を解くためにニューラルネットワークを制約することを初めて提案した、
PINNsは後に解析的微分ではなくバックプロパゲーションを用いることで発展した。
<br><br>
●『Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations』(2019)<br>
論文は Google Scholar で検索すると pdf に辿り着ける
<br>
現代の物理情報ニューラルネットワーク (PINN) フレームワークを導入した。
<br><br>
<center><img src="data/images/PINNs.svg"></center>
<center>(蛇足：自動微分～物理損失を教師モデルと見なすと「Knowledge Distillation (知識蒸留)」に似ている･･･)</center>
</li>

<br>

<li id="Plateau">
<strong>Plateau (プラトー: 高原)</strong><br>
学習の過程で損失関数の値が一時的にほとんど変化しなくなり、学習の進捗が停滞しているように見える現象。<br>

<center><img src="data/images/Plateau.svg"></center>

<br>(関連項目)<br>
・<a href="#NGD">NGD: Natural Gradient Descent (自然勾配降下法)</a>
</li>

<br>

<li id="PlatonicRepresentationHypothesis">
<strong>Platonic Representation Hypothesis（プラトン的表現仮説）</strong><br>
異なるアーキテクチャや学習データで訓練されたAIモデル（特に深層学習モデル）が、現実世界の共通の統計的モデル、つまり「理想的な表現（プラトン的表現）」に収束していくという仮説。<br>
・この仮説は、視覚モデルや言語モデルなどが規模と能力を増すにつれて、データポイント間の距離や類似性を測定する方法がますます類似してくる、という観察に基づいている。<br>
・名称は哲学者プラトンの「イデア論」に由来しており、物理的な実体は不完全なコピーであり、完全で抽象的な「形（イデア）」が理想的な世界に存在するという考え方に例えられている。AIの文脈では、この「イデア」が現実世界の根本的な構造を表す理想的な数学的表現に相当する。<br>
<br>
●『The Platonic Representation Hypothesis』(2024)<br>
<center><img src="data/images/PlatonicRepresentationHypothesis.svg"></center><br>
画像(X)とテキスト(Y)は、共通の根底にある現実(Z)の投影である。
表現学習アルゴリズムは Z の共通表現に収束すると我々は推測しており、モデルサイズのスケーリング、そしてデータとタスクの多様性がこの収束を促進する。<br>
<br>(関連項目)<br>
・<a href="#UniversalWeightSubspaceHypothesis">The Universal Weight Subspace Hypothesis</a> (普遍重み部分空間仮説)<br>
<br>
どちらも一見異なるように見える多様なAIシステムが、基礎となる数学的構造や物理法則によって、効率的な「解」の空間に引き寄せられている可能性を示唆している。

\[
\begin{array}{c|c|c}
& \text{プラトン的表現仮説} & \text{普遍重み部分空間仮説}\\
\hline
\text{注目する点} & \text{表現} & \text{重み}
\end{array}
\]
</li>

<br>

<li>

<strong>Policy Collapse (ポリシー崩壊)</strong><br>
学習中のエージェントの行動方針（方策）が、望ましくない、または極めて限定的な状態に陥り、パフォーマンスが大幅に低下する現象のこと。<br>
<br>
●『An Entropy Regularization Free Mechanism for Policy-based Reinforcement Learning』(2021)<br>
　(エントロピー正則化を必要としないポリシーベース強化学習メカニズム)<br>
　論文は<a href="https://arxiv.org/abs/2106.00707">こちら</a><br>
ポリシーベースの強化学習法は、ポリシー崩壊問題に悩まされる。 ポリシーベースの方法向けに設計されたエントロピー正規化を必要としないメカニズムを提案。<br>
<br>
●『The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models』(2025)<br>
　(推論言語モデルのための強化学習のエントロピーメカニズム)<br>
　論文は<a href="https://arxiv.org/abs/2505.22617">こちら</a><br>
　共分散の高いトークンをクリップして KL ペナルティを適用することで、ポリシーがエントロピー崩壊するのを回避
</li>

<br>

<li>
<strong>Policy Optimization(方策最適化)</strong><br>
エージェントが環境でより良い行動を取れるように、その行動方針（方策）を直接的に改善していく手法の総称。<br>
・Policy Gradient (方策勾配法)<br>
・Actor-Critic (アクター・クリティック法)<br>
・PPO: Proximal Policy Optimization (近傍方策最適化)<br>
・TRPO: Trust Region Policy Optimization (トラスト・リージョン方策最適化)<br> などがある。
</li>

<br>

<li id="PolicyStaleness">
<strong>policy staleness (ポリシーの陳腐化)</strong><br>
<strong>非同期システム</strong>　大規模なシステムでは、複数の「アクター」（データを収集するための実行役）と「学習者」（ポリシーを更新する計算役）が非同期に動作することがある。アクターが古いバージョンのポリシー（方策）を使って環境からデータを収集し続けている間に、学習者側ではポリシーが最新のものに更新されてしまう、という時間的ギャップが生じる。<br>
<strong>データの「古さ」</strong>　時間的ギャップにより、学習者が受け取るデータは、現在の最新のポリシーではなく、古い（陳腐化した）ポリシーによって生成されたものになる。 
</li>

<br>

<li>
<strong>POMDPs: Partially Observable Markov Decision Process (部分観測マルコフ決定過程)</strong><br>
環境の「真の状態」をエージェントが完全には観測できない状況下での意思決定をモデル化するための数学的枠組み。<br>
強化学習の基本的なモデルであるマルコフ決定過程 (MDP: Markov Decision Process) では、エージェントは常に現在の状態を完全に把握できることを前提とする。しかし、現実世界の問題の多くでは、センサーのノイズや情報の制限などにより、完全な状態を知ることはできない。POMDPは、このような不確実性を考慮して意思決定を行うための拡張版。
</li>

<br>

<li id="PotemkinUnderstanding"><strong>Potemkin Understanding (ポチョムキン(的)理解)</strong><br>
大規模言語モデルがベンチマークの成功に基づいて概念を理解しているように見えるが、真に一貫性のある理解を欠いているという失敗モード。<br>
●『Potemkin Understanding in Large Language Models 』(2025)<br>
　　(大規模言語モデルにおけるポチョムキン理解)<br>
・「ポチョムキン理解」   ･･･ 誤った概念的一貫性を捏造する。<br>
・「Hallucination(幻覚)」･･･ 誤った事実を捏造する。<br>
<br>
※「ポチョムキン(的)理解」という用語は、見かけは立派だが実体がない外観、という歴史的な概念であるポチョムキン村に由来している。<br>
<br>(関連項目<br>
・<a href="#StochasticParrot">Stochastic Parrot</a> (確率的オウム)
</li>

<br>

<li id="PrimacyBias">
<strong>Primacy Bias (プライマシーバイアス, 初頭バイアス)</strong><br>
最初に受け取った情報や、経験の初期段階で得られた情報が、その後の判断や評価に過度な影響を与える認知バイアスのこと。<br>
機械学習では, あるタスクで最初に学習されたモデルが、異なるデータ分布や目的（あるいはその両方）で学習されると、新しいタスクにおいてランダムに初期化されたモデルよりもパフォーマンスが低下する現象を指す。<br>
日本語では「初頭効果」や「優先バイアス」とも呼ばれる。<br>
<br>
●『What Can Grokking Teach Us About Learning Under Nonstationarity?』(2025)<br>
　Grokking 出来れば, Primacy Biasに打ち合って継続学習できる<br>
<br>
<center><img src="data/images/PrimacyBias.svg"></center>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#CatastrophicForgetting">Catastrophic Forgetting</a> (破局的忘却)<br>
・<a href="#Grokking">Grokking</a><br>
</li>

<br>

<li>
<strong>Priming</strong><br>
先行する刺激（プライマー）が、その後の行動や判断に無意識的な影響を与える心理現象。<br>

</li>

<br>

<li id="Prisoner'sDilemma">
<strong>Prisoner's Dilemma (囚人のジレンマ)</strong><br>
個人が自分の利益だけを考えて合理的な選択をした結果、全員にとって望ましくない（非効率な）結果に陥ってしまうという、ゲーム理論における代表的なモデルケース。<br>
<br>

(例)

<center><img src="data/images/Prisoner'sDilemma.svg"></center>

・2人の囚人は連絡をとることができない(非協力ゲーム)<br>
・相手の行動がどちらの場合でも、自白した方が刑期が短い<br>
⇒ 2人とも「自白」を選択する。<br>
<br>
IPD: Iterated Prisoner’s Dilemma (反復囚人のジレンマ)<br>
基本的な「囚人のジレンマ」ゲームを同じ参加者間で何度も繰り返し行うというゲーム理論のモデル。<br>
<br>

●『The Evolution of cooperation』(1984)<br>
　(協力の進化 ･･･ 書籍の邦題：つきあい方の科学)<br>
・ゲーム理論家から戦略を募り、トーナメントで競わせた。<br>
・各戦略は、囚人のジレンマゲームを200回繰り返し、獲得ポイントの合計で競われた。<br>
・<strong><span style="color:magenta;">優勝したのは、</span></strong>アナトール・ラポポートが提出した<strong><span style="color:magenta;">「しっぺ返し」（TFT:TIT FOR TAT）と呼ばれる非常に単純な戦略だった。これは、最初の動きで協力し、その後、相手が前の動きで行ったことを繰り返す（お返しする）というものだ。</span></strong>(相手が協力するなら協力し, 裏切ったら,こちらも裏切る)<br>

<br>

●『The evolution of stochastic strategies in the prisoner’s dilemma』(1990)<br>
・現実世界のやりとりにおける「ノイズ」や不確実性を加味。<br>
・誤りが生じやすい環境では、たった一つのミスが一連の相互非難を引き起こす可能性があること、ある程度の「寛大さ」を備えた確率論的な戦略は、この悪循環を打破することができることを示した。<br>

<br>

●『Learning with Opponent-Learning Awareness 』LOLA (2017)<br>
　(敵対学習意識による学習)<br>
・各エージェントが相手の学習プロセスを考慮して戦略を立てる「LOLA」という手法を提案。2つのLOLAエージェントが対戦すると、反復囚人のジレンマゲームで TFT のような協力行動が自然に起こることが示された。<br>

<br>

●『Foolproof Cooperative Learning』 (FCL)V(2019)<br>
・強化学習で「Foolproof Cooperative Learning (FCL)」アルゴリズムを導入。このアルゴリズムは、協力的な戦略を取りつつ、利己的なプレイヤーに利用されないように設計されており、TIT FOR TAT的な行動に落ち着くことを証明した。<br>
<br>
●『Strategic Intelligence in Large Language Models Evidence from evolutionary Game Theory』 (2025)<br>
　(大規模言語モデルにおける戦略的知能：進化ゲーム理論からの証拠)<br>
・現代のLLM（例: GPT-4o mini, Gemini 1.5 Flash）を使用して反復囚人のジレンマゲームを分析している。
</li>

<br>

<li id="ProspectiveLearning">


<strong>Prospective Learning (展望学習)</strong><br>
未来の動的な変化に対応するための学習。<br>
特徴<br>
・データ分布や目的が時間と共に変化する動的な世界を想定する<br>
・未来のデータ分布の変化を予測し、将来にわたって高い性能を維持することを目的とする。<br>
・時間の経過に伴うデータの「分布シフト」に対処する。<br>
<br>
●『Prospective Learning: Principled Extrapolation to the Future』(2022)<br>
　(展望学習：未来への原理に基づいた外挿)<br>
　論文は<a href="https://arxiv.org/abs/2201.07372">こちら</a><br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)･･･概略図比較あり,　 <a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習=継続学習の別名)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
</li>

<br>

<li id="Pruning">

<strong>Pruning (枝刈り)</strong><br>
学習済みのモデルから重要度の低いパラメータや接続を削除することで、モデルを圧縮する手法。<br>
<br>(関連項目)<br>
・<a href="#LTH">LTH: Lottery Ticket Hyposis</a> (宝くじ仮説)<br>
</li>

<br>

<li>

<strong>"Pushcut" Phenomenon  </strong><br>
訓練中のモデルが、事前に与えられた教師データには含まれていなかった、より効率的で洗練された新しい行動パターンを自律的に発見することを指す。<br>
モデルが単に与えられたデータを模倣するのではなく、データにない独自の解決策を「押し出し（push）」、問題を「切り開いていく（cut）」ような振る舞いをすることから名付けられた。 
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="Q">Q</h2>
<p>
<div class="styleBullet">
<ul>
<li>

<strong>Qualia (クオリア)</strong><br>
哲学や脳科学において、意識に現れる主観的で個人的な「感覚的な質感」や「感じ」のこと。<br>
<br>
●『The Qualia Structure Paradigm: towards a construction of a Qualia Periodic Table for the dissolution of the Hard Problem of Consciousness』 (2024)<br>
(クオリア構造パラダイム：意識の難問解決のためのクオリア周期表の構築に向けて)<br>
<br>
<strong><span style="color:magenta;">クオリア間の類似性が距離の公理（最小性、対称性、三角不等式）を満たすかどうかといった根本的な疑問さえも未だ解決されていない</span></strong>。 クオリアの「空間」については様々な種類が提案されているが、すべてのクオリアを何らかの高次元空間内の点とみなせるかどうかは不明である。現段階では、クオリアのための何らかの空間の存在を仮定するのではなく、<strong><span style="color:magenta;">一歩下がってクオリアの数学的「構造」の可能性を探る方がよいかもしれない。これが、「クオリア構造」パラダイムである･･･</span></strong><br>

<br>
<a href="data/Papers_Qualia.html">Papers</a><br>
<a href="https://en.wikipedia.org/wiki/Qualia">wikipedia</a>
</li>

<br>

<li>

<strong>Quality-Diversity Optimization (品質多様性最適化)</strong><br>
単一の最適な解を見つけるのではなく、高品質で多様な解の集合を生成することを目指す最適化手法の一種。<br>
進化計算(生物の進化（突然変異、淘汰、交叉など）を模倣し、複雑な問題の最適解を探索する一連のアルゴリズムを指す枠組み)の新しいサブカテゴリー。

</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="R">R</h2>
<p>
<div class="styleBullet">
<ul>
<li id="RAG">
<strong>RAG: Retrieval-Augmented Generation (検索拡張生成, 取得拡張生成)</strong><br>
質問に関連する文書を検索(Retrieval)し, 取得した文書をもとに(Augmented) LLM で回答を生成(Generation)することで、より正確で信頼性の高い回答を生成する技術。<br>
<br>
RAG は "open-book"QAパラダイムの実装手法の一つ。<br>
例)『Reading Wikipedia to answer open-domain questions』(2017)<br>
<br>
⇔ "closed-book" QAパラダイム：知識をモデルのパラメータ内に完全に格納する<br>
例)『How much knowledge can you pack into the parameters of a language model?』(2020)
</li>

<br>

<li id="RashomonSet">
<strong>Rashomon Set (羅生門集合)</strong><br>
最適な予測精度とほとんど同じ精度を持ちながら、異なる判断基準や構造を持つ多様なモデルの集合。<br>
由来はやはり･･･黒澤明監督の映画『羅生門』や芥川龍之介の小説『羅生門』。<br>
一つの出来事に対して関係者がそれぞれ異なる(しばしば矛盾する)証言や解釈を提示する「羅生門効果（現象）」が描かれている。<br>
<br>
●『Resolving Predictive Multiplicity for the Rashomon Set』(2026)<br>
　(羅生門集合の予測的多重性の解決)<br>
　特定の予測タスクに対して、同等の精度を持つ複数のモデルが存在する場合、予測の多重性が生じる。つまり、「羅生門セット」と呼ばれるモデル群は、同様の精度を達成しますが、個々の予測値はばらつく。この不一致は、一貫性のある予測が求められるハイステークスなアプリケーションにおける信頼性を損なう。羅生門セットのメンバー間の予測値の不一致を低減するための3つのアプローチを提案する。<br>
<br>
1つ目のアプローチは「外れ値補正」である。外れ値とは、どの優れたモデルも正しく予測できないラベルである。外れ値があると、羅生門セットの予測値が局所的に高い分散を示す可能性があるため、外れ値を修正することで分散を低減できる。<br>
<br>
2つ目のアプローチは、局所パッチングである。テストポイント周辺の局所領域では、モデルの一部に偏りがあるため、モデル間の予測値が一致しない場合がある。検証セットを用いることで、このような偏りを検出し修正することができ、多重性も低減される。<br>
<br>
3つ目のアプローチは、ペアワイズ調整である。これは、テストポイント周辺の領域で一致しないモデルのペアを見つけるものである。不一致な予測を修正することで、バイアスを低減する。<br>
<br>
これら3つのアプローチは併用することも個別に使用することもできる。
</li>

<br>

<li id="Reasoning">
<strong>Reasoning (推論)</strong><br>
既存の知識や情報に基づいて、結論を導き出したり、予測を立てたり、説明を組み立てたりする思考プロセス。<br>
<br>
<center><img src="data/images/InferencePredictionReasoning.svg"></center>
<br>
<ul>
<li><strong>Deduction (演繹法)</strong><br>
一般法則から個別の結論を導き出す推論。結論は必ず真となる。<br>
「A (十分条件を満たす) ⇒ B (必要条件を満たす)」と言っているだけなので新しいことは生み出さない。<br>
<br>
<center><img src="data/images/Deduction.svg"></center>
</li>
<li><strong>Induction (帰納法)</strong><br>
複数の個別事例から共通する一般法則を導き出す推論。<br>
結論の蓋然性(確からしさ)は高いが, 真とは限らない。<br>
確証バイアスや帰納飛躍の影響を受ける可能性がある。<br>
</li>
<br>
<li><strong>Abduction (アブダクション, 仮説形成, 探究的推論)</strong><br>
驚くべき観察結果や事実に直面した際に、それを最もよく説明できる仮説を形成する推論。<br>
真とは限らないので検証が必要。<br>
<br>
●『Abduction in Logic Programming』(2002)<br>
　この分野の初期の研究(80年代～90年代)を概観した論文。<br>
●『Automated Abduction in Scientific Discovery』(2007)<br>
　科学における仮説生成の自動化に焦点を当てた論文。<br>
●『Abductive Artificial Intelligence Learning Models』(2019)<br>
　　(アブダクティブ人工知能学習モデル)<br>
　機械学習モデルに基づくアブダクティブ学習について論じた論文。<br>
●『Generative AI for Scientific Discovery: Automated Hypothesis Generation and Testing』(2025)<br>
　(科学的発見のための生成AI：自動化された仮説生成と検証)<br>
　Transformerモデルなどを利用して、創薬や材料科学などの分野で仮説生成を自動化する研究について述べている。<br>

</li>
</ul>
<br>(関連項目)<br>
・<a href="#ConfirmationBias">Confirmation Bias (確証バイアス)</a><br>
・<a href="#InductiveLeap">Inductive Leap (帰納的飛躍)</a>
</li>

<br>

<li id="Regularization">

<strong>Regularization (正則化)</strong><br>
・不良設定問題に対して、解の滑らかさなどの定性的な拘束条件を加えて解が存在する様に問題を変換して解く手法。<br>
・事前情報が不足しているため、通常の手法では唯一、安定な解を得ることができない時に、定性的なルールを適用して解を求めるもの。<br>
・機械学習の文脈では, モデルの「過学習」を防ぎ、未知のデータに対する「汎化能力」を向上させるための手法。<br>
・ベイズ推定の文脈では, 事前確率分布の対数尤度を損失関数に加えること<br>
・帰納バイアスを表現する手段<br>
<br>(関連項目)<br>
・<a href="#ill-posed">ill-posed problem (不良設定問題)</a><br>
・<a href="#InductiveBias">Inductive Bias (帰納バイアス)</a><br>
・<a href="#Dropout">Dropout</a>
</li>

<br>

<li id="RelationalSimilarity">
<strong>Relational Similarity (関係類似性) </strong><br>
2つの異なる物事のペア(単語ペアや画像ペアなど)の間に存在する「関係」そのものの類似度を指す。個々の要素の属性(見た目や特徴)が似ていること(属性類似性)とは対照的な概念。<br>
<br>
<strong>Attributional similarity (属性類似性)</strong>: 物事自体の特徴がどれだけ似ているか。例えば、「犬」と「狼」は多くの特徴を共有しているため、属性類似性が高いと言える。<br>
<strong>Relational similarity (関係類似性)</strong>:　物事間の関係がどれだけ似ているか。異なる要素間であっても、それらを結びつける論理や機能が共通している場合に類似性が高いと判断される。<br>
<br>
●『Relational Visual Similarity』(2025)<br>
　人間は属性の類似性だけでなく、関係性の類似性も認識します。リンゴは桃と似ています。どちらも赤みがかった果物だからです。しかし、地球も桃に似ています。地球の殻、マントル、そして核は、桃の皮、果肉、そして種に対応しています。この関係性の類似性を知覚し認識する能力こそが、人間を他の種と区別するものだ、と認知科学者は主張しています。しかしながら、今日広く使用されている視覚的類似性指標（LPIPS、CLIP、DINOなど）はすべて、知覚的属性の類似性のみに焦点を当てており、人間が知覚する豊かで、しばしば驚くべき関係性の類似性を捉えることができていません。<br>
<center><img src="data/images/RelationalSimilarity0.svg"></center>
<center><img src="data/images/RelationalSimilarity1.svg"></center><br>
(a) LAION-2B から高品質な関係画像を選択する画像フィルタリングモデルを学習する。<br>
　※ LAION-2B ･･･ AI研究を目的とする非営利団体「LAION」によって作成された大規模な画像とテキストのペアのデータセット<br>
(b) 匿名キャプションモデルは、同じ基本ロジックを共有する画像グループで学習され、各グループ内のすべての画像に同じ匿名キャプションが付けられる。<br>
　※ 匿名キャプション ･･･ キャプションが生成された文脈や、特定の参照情報が意図的に伏せられているキャプション<br>
<br>
<center><img src="data/images/RelationalSimilarity2.svg"></center><br>
(c) 関係視覚類似性 (relsim) モデルの学習では、画像特徴とそれに対応する匿名キャプション間のコントラスト損失が生じる。<br>
<br>
●『Structure Mapping in Analogy and Similarity』(1997)<br>
<center><img src="data/images/RelationalSimilarity4.svg"></center><br>
●『Matching Local Self-Similarities across Images and Videos』(2007)<br>
<br>
<center><img src="data/images/SelfSimilarity.png"></center><br>
これらの画像は、共通の画像特性（色、テクスチャ、エッジ）を共有していませんが、局所的な内部自己相似性の類似した幾何学的レイアウト(ハート形)を共有しています。
</li>

<br>

<li id="ReLU">

<strong>ReLU: Rectified Linear Unit </strong><br>
深層学習（ディープラーニング）で最も広く使われる活性化関数のひとつ。<br>
<br>
●『Visual feature extraction by a multilayered network of analog threshold elements』(1969)<br>
　　ReLUと命名されていないが, 最初の ReLU とされている。<br>
　　<a href="https://people.idsia.ch/~juergen/who-invented-convolutional-neural-networks.html">Who invented convolutional neural networks ?</a><br>
<br>
●『Rectified linear units improve restricted boltzmann machines』(2010)<br>
　　ReLU と命名した基礎的な論文。<br>
<br>
●『Imagenet classification with deep convolutional neural networks (AlexNet論文)』(2012)<br>
　　深層畳み込みネットワークにおける ReLU の有効性を示すことにより ReLU を普及させた。<br>
　　機械翻訳は<a href="https://boyoyon.github.io/HTMLs_translated_to_Japanese/2012_AlexNet/2012_Imagenet-classification-with-deep-convolutional-neural-networks.html">こちら</a>。(図1.「tanhの6倍･･･」)<br>
<br>
●『Dying relu and initialization: Theory and numerical examples』(2019)<br>
　「ReLUの死滅問題」に関する詳細な分析と特定の実験設定を提供。<br>
　　死滅問題：入力が常に負 → 出力が 0 → 勾配 0 → 重みが更新されない <br>
　　原因：学習率が高すぎる / バイアスが負の大きな値になっている / データの偏り, 等々

</li>

<br>

<li id="RepresentationCollapse">
<strong>Representation Collapse (表現の崩壊)</strong><br>
モデルが入力データの多様な特徴を捉える能力を失い、限られた、または単一の表現に集約されてしまう現象。<br>
<br>
<div class="styleBullet">
<ul>
<li><strong>Total Collapse / Trivial Collapse (完全な崩壊)</strong><br>
モデルがすべての入力データに対して常に同じ単一の表現（特徴ベクトル）を出力するようになる現象。稀な病気を検出するように訓練したら, 常に「陰性」を出力するようになってしまった･･･ような現象。</li><br>
<li><strong>特徴量の多様性の喪失</strong><br>
モデルの内部表現が、互いに似通ってしまう状態。異なるクラスのデータであっても、最終層に近い特徴表現が同じような値に収束してしまい、区別がつかなくなることがある。<br>
</li><br>
<li><strong>Dimensional Collapse (次元の崩壊)</strong><br>
コントラスト学習や自己教師あり学習などの文脈で、特徴表現の次元が実質的に低下し、多様な情報を保持できなくなる現象。<br>
</li><br>
<li><strong>Modality Collapse (モード崩壊)</strong><br>
マルチモーダル (画像とテキストなど複数の種類のデータ) を扱うモデルにおいて、特定のモダリティ(データ形式) が他のモダリティよりも支配的になり、他の情報が無視されてしまう現象。<br>
GAN が新たな画像を生成せず, 一部の学習データのみを再現する現象もモード崩壊という。<br>
</li><br>
<li><strong>Expert Collapse (エキスパートの崩壊)</strong><br>
Sparse Mixture of Experts (SMoE) という大規模言語モデルなどで使われるアーキテクチャにおいて、一部のエキスパート（専門的な処理を行う部分）しか選択されなくなり、他のエキスパートが使われなくなる現象。<br>
</li><br>
<li><strong>Neural Collapse (ニューラルコラプス)</strong><br>
学習の終盤に自然に発生する幾何学的な現象で、クラス内の特徴がそのクラスの平均に収束し、クラス平均同士が対称的な構造 (正単体など) を形成する現象。これは必ずしも悪い現象ではなく、むしろ効率的な学習の帰結として理解されることもある。
</li>
</ul></div>
<br>
●『VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning』(2021)<br>
　　各次元に沿った埋め込みの分散に個別の単純な正則化項を適用することで、崩壊問題を明示的に回避する手法であるVICReg（分散・不変・共分散正則化）を導入。<br>
●『LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics』(2025)<br>
　　等方性ガウス分布 (すべての次元が等しい分散を持ち、無相関である分布) に従う埋め込みを使って表現の崩壊を防ぐ 自己教師あり学習アーキテクチャー (Joint-Embedding Predictive) を提案している(らしい)<br>
<br>(関連項目)<br>
・<a href="#DimensionalCollapse">Dimensional Collapse</a> (次元崩壊)<br>
・<a href="#NeuralCollapse">Neural Collapse</a><br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)
</li>
<br>

<li>

<strong>Representation Learning (表現学習)</strong><br>
画像、音声、テキストなどの生データから、機械学習モデルがタスクを解決するために必要な「特徴」や「本質的な情報」を自動的に抽出・学習する一連の技術。
</li>

<br>

<li>

<strong>Reversal Curse (反転の呪い)</strong><br>
大規模言語モデル（LLM）が学習データで「AはBである」という形式の知識を学んでも、「BはAである」という逆の関係を自動的に推論できない、という現象。<br>
<br>
(例)「プラトンはアリストテレスを教えた」と学習した言語モデル<br>
　　「アリストテレスの先生は誰でしたか？」という質問に答えられない。<br>
　　「BはAの親である」から「AはBの息子である」を推論できない。<br>
<br>
●『The reversal curse: Llms trained on "a is b" fail to learn "b is a"』(2023)<br>
　モデルが「逆探索」タスク（値からキーを検索する）において低い性能を示すことを指摘し、この失敗を言語モデルで観察される「反転の呪い（reversal curse）」現象に明示的に結びつけており、より広範なLLM研究との強い関連性を示した。
</li>

<br>

<li id="ReverseThinking">
<strong>Reverse Thinking</strong><br>
問題解決やアイデア創出のために、従来の思考プロセスを意図的に「逆転」させるクリエイティブな思考法。<br>
・「どうすれば失敗するか」「最悪の結果は何か」「目標達成を妨げる要因は何か」「顧客が絶対に買わない商品は何か」<br>
・「思考の盲点」を洗いだす。<br>
<br>
●『InvThink: Towards AI Safety via Inverse Reasoning』(2025)<br>
　InvThinkでは、あえて「どのようにすれば失敗するか」「どのような応答が有害か」といった失敗モード（failure modes）を推論させる。これにより、潜在的なリスクを事前に特定し、回避する能力をモデルに学習させる。<br>
<br>
●『Reverse Thinking Makes LLMs Stronger Reasoners』(2024)<br>
　人間が問題解決の際に順方向だけでなく、解答から問題へと思考を遡る「逆思考」を用いることに着目。モデルに順方向推論と逆方向推論の両方を行わせ、結果の整合性を確認することで、推論の精度を高める。<br>
<br>
●『Modeling reverse thinking for machine learning』(2018)<br>
モデルが生成した「間違った」結果に対してリバースシンキングを適用し、その間違いの原因を特定・修正する新しい学習方法を提案。<br>
<br>(関連項目)<br>
・<a href="#InertialThinking">Inertial Thinking</a> (慣性思考)
</li>

<br>

<li id="RewardEngineering">
<strong>Reward Engineering (報酬エンジニアリング, 報酬工学)</strong><br>
適切な「報酬（Reward）関数」を設計・調整するプロセス。<br>
<br>
●『The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination』(2026)<br>
　(報酬エンジニアリングの終焉：LLMはいかにマルチエージェント協調を再定義するか)<br>
　マルチエージェント強化学習（MARL）は、長らく報酬関数の手動設計という根本的なボトルネックに制約されてきた。報酬設計として知られるこのプロセスは、複雑な人間の意図を、エージェントの行動を導く数学的関数に変換することを必要とするが、エージェントの数が増えるにつれて、このタスクは指数関数的に困難になる。大規模言語モデル（LLM）の最近の進歩は、このパラダイムを根本的に変革する位置にあり、従来の報酬設計の必要性を完全に排除する可能性のある自然言語目標への道筋を提供する。<br>
<center><img src="data/images/EndOfRewardEngineering.svg"></center>
</li>

<br>
<li id="RewardHacking">

<strong>Reward Hacking (報酬ハッキング)</strong><br>
強化学習エージェントが、設計者が意図した本来の目的を達成するのではなく、報酬関数の欠陥や抜け穴を悪用して不当に高い報酬を得ようとする現象。「仕様の悪用（Specification Gaming）」とも呼ばる。 <br>
<br>
●『Specification gaming: the flip side of ai ingenuity』(2020)<br>
　(仕様ゲーミング：AIの創意工夫の裏側)<br>
<br>(関連項目)<br>
・<a href="#GoodhartsLaw">Goodhart's Law (グッドハートの法則)</a><br>
　類似の現象を経済学や社会科学の文脈で説明したもの。
</li>

<br>

<li id="RewardLandscape">
<strong>Reward Landscape (報酬ランドスケープ)</strong><br>
強化学習において、方策（ポリシー）や価値関数といったモデルのパラメータ空間における、期待報酬（目的関数）の地形（曲面）を表す概念図、あるいはその抽象的なモデル。<br>
・定義域：方策（ポリシー）や価値関数といったモデルのパラメータ空間<br>
・値域：報酬<br>
<br>
　●『Fractal Landscapes in Policy Optimization』(2023)<br>
　　　いくつかの方策最適化の失敗事例が、フラクタルな風景によって説明できることを実験で示す。<br>
<br>
　●『Flat Reward in Policy Parameter Space Implies Robust Reinforcement Learning』(2025)<br>
　　　フラットな報酬風景と強化学習モデルのロバスト性との関連を正式に結びつけることを目指す。<br>
<br>
<center><img src="data/images/RewardLandscape.svg"></center>
<br>
エージェントの報酬面の可視化。x軸とy軸はパラメータ空間におけるランダムな方向に沿った摂動を表し、z軸は平均収益を表す。<br>
<br>(関連項目)<br>
・<a href="#LossLandscape">Loss Landscape (損失景観)</a>
</li>

<br>

<li id="RewardSignalCollapse">
<strong>Reward Signal Collapse (報酬信号崩壊)</strong><br>
主に大規模言語モデル (LLM) の強化学習 (RLHF等) において、複数の報酬指標を組み合わせて最適化を行う際に、特定の報酬信号が他の信号にかき消されたり、学習が特定のパターンに固執して多様性が失われたりする現象。<br>
AIが報酬を追いすぎるあまり、バランスを欠いたり、単調な回答しかできなくなったりする学習の失敗状態。<br>
<br>(関連項目)<br>
・<a href="#GDPO">GDPO: Group reward-Decoupled Normalization Policy Optimization</a> (グループ報酬分離正規化ポリシー最適化)
</li>

<br>

<li id="RL">
<strong>RL: Reinforcement Learning (強化学習)</strong><br>
心理学および動物行動学において「オペラント条件づけ（道具的条件づけ）」という概念に基づいて研究されていた, 
動物や人間が、自発的な行動の結果として得られる報酬や罰を通じて、特定の行動を学習するプロセス。<br>
制御工学では, 動的計画法 (Dynamic Programming) や最適制御理論といった手法が中心に研究された。<br>
機械学習の文脈では、コンピューターエージェントが試行錯誤を通じて最適な行動ルールを学習するアプローチ。<br>
<br>
<a href="data/Papers_RL.html">Papers</a><br>
<br>
●『Reinforcement Learning: An Overview』(2024/2025)　<a href="https://arxiv.org/abs/2412.05265">こちら</a>　<a href="https://boyoyon.github.io/Introductions/data/RLoverview_01.html">1章の機械翻訳</a><br>
　(強化学習の概要, 237ページ)<br>
<br>
<center><img src="data/images/RL.svg"></center>
DRL(深層強化学習)では DNN が End-to-End で処理するため, 明確な機能モジュールに分かれている訳ではない。(例：DQNの構成)<br>
<br>
<center><img src="data/images/DQN.svg"></center>
<br>(関連項目)<br>
・<a href="#DRL">DRL: Deep Reinforcement Learning</a> (深層強化学習)<br>
・<a href="#WorldModel">World Model</a> (世界モデル)
</li>

<br>

<li id="RLVR">
<strong>RLVR: Reinforcement Learning with Verifiable Rewards（検証可能な報酬を用いた強化学習）</strong><br>
大規模言語モデル（LLM）などのAIシステムをトレーニングする手法の一つで、人間の主観的な評価ではなく、客観的で自動的に検証可能な基準に基づいて報酬を与える。<br>
・モデルの出力が事前に定義された正解基準（例：数学の問題の答えが正しいか、コードがテストケースを通過するか）に一致するかどうかに基づいて、明確な報酬（例：正解なら1、不正解なら0）が与えられる。<br>
　報酬は2値に限定される訳ではなく, 回答の「部分的な正しさ」や、複数のテストケースに合格した数に応じて報酬値を変えるソフト報酬を使うこともできる。<br>
・RLHF (人間のフィードバックからの強化学習) のように人間の好みや主観に依存しないため、報酬の設計が明確で「報酬ハッキング」（報酬システムの欠陥を悪用して高得点を獲得すること）のリスクが低減される。<br>
・最終結果だけでなく、そこにたどり着くまでの推論過程 (Chain-of-Thought) の中間ステップに対しても報酬を与える「プロセス報酬」のアプローチも探求されている。<br>
<br>
●『Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains』(2025)<br>
　(報酬としてのルーブリック：検証可能な領域を超えた強化学習)<br>
　※ ルーブリックとは学習目標の達成度を判断するため、【評価観点 】と、観点の尺度を数段階に分けて文章で示した【評価基準】から構成される評価ツールのこと。<br>
●『Checklists are better than reward models for aligning language models』(2025)<br>
　(言語モデルを整合させるには、チェックリストの方が報酬モデルよりも優れている)<br>

<br>(関連項目)<br>
・<a href="#RewardHacking">Reward Hacking</a> (報酬ハッキング) 
</li>

<br>

<li id="RoPE">
<strong>RoPE: Rotary Positional Embedding</strong><br>
Transformer（トランスフォーマー）ベースのモデル、特に大規模言語モデル（LLM）において、単語の位置情報を効果的に組み込むための手法。<br>
Transformerモデルの基本構造であるAttentionメカニズムは、入力された単語の順序や位置関係を自然に捉えることができない。そのため、単語の意味を表す埋め込みベクトルに位置情報を付加する「位置エンコーディング」という技術が必要になる。RoPEは、この位置エンコーディングの一種。<br>
<br>
●『RoFormer: Enhanced Transformer with Rotary Position Embedding』(2021)<br>
・RoPE を導入した。<br>
<br>
●『Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs』(2025)<br>
・標準的な実装では、アテンションスコアの計算に複素数値ドット積の実数部のみを利用している。この簡略化により、貴重な位相情報を含む虚数部が破棄され、長文脈依存関係のモデリングに不可欠な関係の詳細が失われる可能性がある。本論文では、この破棄された虚数部を再び組み込む拡張(RoPE++)を提案する。<br>
<center><img src="data/images/RoPE.svg"></center>
</li>

<br>

<li id="RPE">
<strong>RPE: Reward Prediction Error (報酬予測誤差)</strong><br>
「実際に得られた報酬」と「事前に予測していた報酬」の差を指す。<br>
この誤差を用いて将来の予測（価値関数）を更新する。<br>
<br>
●『A Neural Substrate of Prediction and Reward』(1997)<br>
・数学的なTD誤差が、生物（霊長類）の脳内にあるドーパミン細胞の活動と一致することを示した。<br>
・ドーパミンが「報酬そのもの」ではなく、「予測していた報酬と実際の報酬のズレ（RPE）」に反応することを発見した。<br>
<br>(関連項目)<br>
・<a href="#TD">TD (Temporal Differences) 学習</a><br>
・<a href="#CuriosityDriven">Curiosity-driven</a>（好奇心駆動型)
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="S">S</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Saliency (顕著性, 突出性)</strong><br>
周囲の環境や他の情報に比べて、特定の刺激や情報がどれだけ目立ち、人間の注意を引きつけるかの度合いを指す。
</li>

<br>

<li id="SangersRule">
<strong>Sanger's rule（サンガーの法則）</strong><br>
・GHA: Generalized Hebbian Algorithm の別名。<br>
・主成分分析(PCA)に応用される線形フィードフォワードネットワークのための教師なし学習アルゴリズム。<br> 
・ドナルド・ヘッブが提唱した「ヘッブの法則」に基づき、シナプスの結合強度を調整することで、入力データセットの主要な特徴(主成分)を抽出する。<br>
・複数の出力ユニットを持つネットワークに適用でき、各ユニットが順次異なる主成分を学習するという特徴がある。これにより、データの次元削減などが可能になる。<br>
・Terence Sanger によって1989年に発表された。<br>
<br>
●『 Optimal unsupervised learning in a single-layer linear feedforward neural network』(1989) <br>
<br>(関連項目)<br>
・<a href="#GHA">GHA: Generalized Hebbian Algorithm </a>
</li>

<br>

<li>
<strong>Scaling Law (スケーリング則)</strong><br>
深層学習モデルにおいて、モデルの性能が、モデルのサイズ（パラメータ数）、学習データの量、計算資源（計算量）といった要素を増加させるにつれて、予測可能な形で向上するという経験的な法則。<br>
モデルの性能に影響を与える3要素<br>
・モデルサイズ(パラメータ数)<br>
・データサイズ(学習データ量)<br>
・計算資源(計算量)
</li>

<br>

<li id="ScientificDiscovery">

<strong>Scientific Discovery (科学的発見),  Scientific Research (科学研究)</strong><br>
AI技術を活用して科学のプロセスを加速・自動化し、新しい知識、法則、仮説、物質などを発見すること。
</li>

<br>

<li>

<strong>Scientific Surprise</strong><br>
●『Language Model Perplexity Predicts Scientific Surprise and Transformative Impact』(2025)<br>
AIシステムがこれまでの知識や人間が期待する予測からは逸脱した、予期せぬ、そして根本的に新しい科学的知見を発見することを指す。<br>
<br>(関連項目)<br>
・<a href="#AI4S">AI4S: AI for Science (科学のためのAI)</a>
</li>

<br>

<li id="SelfConsistency">

<strong>Self-Consistency (自己無撞着性, 自己整合性) </strong><br>
大規模言語モデル（LLM）の推論能力を向上させるためのプロンプトエンジニアリング手法の一つ。<br>
<br>
●『Self-Consistency Improves Chain of Thought Reasoning in Language Models』(2022)<br>
「思考連鎖プロンプティングで用いられる単純な貪欲なデコードに代わる、新たなデコード戦略である自己一貫性を提案。･･･多様な推論経路をサンプリングし、次にサンプリングした推論経路を周辺化する(多数決をとる)ことで、最も一貫性のある解を選択する･･･」<br>

<br>(関連項目)<br>
・<a href="#CoT">CoT: Chain-of-Thought</a> (思考連鎖)･･･概略図比較あり
</li>

<br>

<li id="SelfImprove">
<strong>Self-Improve（自己改善)</strong><br>
人間からの直接的な介入なしに、AIシステムが自らの性能、能力、あるいはアルゴリズム自体を自律的に向上させる技術や概念。<br>
<br>
●『G&ouml;del machines: Fully self-referential optimal universal self-improvers.』(2007)<br>
・証明可能な形で自己改善するAIへの理論的アプローチを導入した。厳格な「形式的証明」の要件のために、理論上は可能であるものの、現実世界での完全な実装は極めて困難だった。<br>
●『Darwin G&ouml;del Machine: Open-Ended Evolution of Self-Improving Agents』(2025)<br>
・G&ouml;del Machineの理論的な制約を緩和した実用的なアプローチ。形式的な証明ではなく、ダーウィン的な進化のアルゴリズム（試行錯誤と経験的な評価）に基づいて自己改善を行う。<br>
●『Huxley-G&ouml;del Machine: Human-Level Coding Agent Development by an Approximation of the Optimal Self-Improving Machine』(2025)<br>
・<strong>系統群メタ生産性 (Clade Metaproductivity, CMP)</strong>　特定のエージェント（親）が生成したすべての子孫（系統群）のパフォーマンスを集計し、その親が持つ「将来的な自己改善の潜在能力」を推定する新しい評価指標を用いる。<br>
<br>(関連用語)<br>
・<a href="#SelfRefine">Self-Refine</a> (自己改善)
</li>

<br>

<li>

<strong>Self-Play(自己対局)</strong><br>
AIが自分自身を対戦相手として繰り返しプレイすることで、外部からの人間の知識や教師データなしに、自律的に学習を進め、性能を向上させる手法。<br>
<br>(関連項目)<br>
・<a href="#WithoutHumanKnowledge">Without human knowledge (人間知識なし)</a>
</li>

<br>

<li id="SelfRefine">
<strong>Self-Refine (自己改善)</strong><br>
主に大規模言語モデル（LLM）が、自身の生成した出力（回答やコードなど）を、自身のフィードバックに基づいて反復的に評価・修正し、品質を向上させるためのフレームワークや手法。<br>
<br>
●『Self-Refine: Iterative Refinement with Self-Feedback』(2023)<br>
・人間が文章を洗練させる方法に着目し、反復的なフィードバックと洗練を通してLLMの初期出力を改善するアプローチであるSelf-Refineを紹介する。<br>
・主なアイデアは、LLMを用いて初期出力を生成し、その後、同じLLMがその出力に対するフィードバックを提供し、それを用いて反復的に自己を洗練させる。<br>
<br>(関連項目)<br>
・<a href="#SelfImprove">Self-Improve</a> (自己改善)
</li>

<br>

<li>
<strong>Self-Replicating (自己複製)</strong><br>
AIシステムが自らのコードや構造を複製、または改良して新しいAIを生み出す能力を持つこと。
</li>

<br>

<li>

<strong>Self-rewarding (自己報酬)</strong><br>
人間からのフィードバックや報酬モデルに頼ることなく、AI自身が自らの生成した出力や行動を評価し、それに基づいて学習を進めていく手法。
</li>

<br>
<li id="SelectiveUnderfitting">
<strong>Selective Underfitting (選択的アンダーフィッティング)</strong></br>
主に拡散モデルと呼ばれる生成AIの分野で提唱された概念。モデルは訓練データの近くでは詳細なパターンを学習しつつ、それ以外の領域では学習されていないがゆえの多様な振る舞いをすることで、新しいデータを生成する能力を獲得している、ということを説明する概念。<br>
<br>
●『SELECTIVE UNDERFITTING IN DIFFUSION MODELS』(2025)
</li>

<br>

<li id="SemanticAnchoring">
<strong>Semantic Anchoring (セマンティックアンカリング)</strong><br>
AIの出力をユーザーが提示する特定の単語、メタファー、またはメンタルモデルに結び付けること。AIがユーザーの概念空間内で動作するように導き、AIの応答がユーザーの意図する意味や文脈と一致するようにする。<br>
<br>
●『The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics』(2025)<br>
　(AGI の欠けている層: パターン錬金術から協調物理学へ)<br>
<center><img src="data/images/SemanticAnchoring.png"></center><br>
　<strong>左(エサをまかない釣り)</strong>: Semantic Anchorがない場合、モデルは基質(一般的なトークン)の最大尤度事前分布を取得する。<br>
　<strong>右(Semantic Anchorあり)</strong>：エサ(文脈／目標)を導入することで、有効なサポート(\(ρ_d\))を特定の概念に対して適用する。これにより事後分布が変化し、システムは、訓練の事前分布によって埋もれてしまうような、稀な目標指向的なターゲット(サメ)を捕捉できるようになる。<br>
<br>(関連用語)<br>
・Semantic Drift ･･･ 人間が意図しない方向へ意味や文脈が「流されてしまう（ドリフト）」現象。
</li>

<br>


<li>
<strong>Semantic hub hypothesis (意味ハブ仮説)</strong><br>
人間やAIが意味的知識をどのように整理・統合するかを説明する理論。
</li>

<br>

<li id="SGFM">
<strong>SGFM: Spectral Generative Flow Models</strong><br>
物理学に着想を得た、新しいタイプの生成AIモデル。<br>
<br>
●『Spectral Generative Flow Models: A Physics-Inspired Replacement for Vectorized Large Language Models』(2026)<br>
・トランスフォーマーベースの大規模言語モデル（LLM）は、離散的な記号オントロジーと、注意を中心とした計算パラダイムに依存している。<br>
・このパラダイムは、より長いコンテキスト、より豊富なモダリティ、そして一貫性のある時空間生成へと進むにつれて、ますます歪んだ構造的仮定を課す。<br>
・トークン化は連続性を放棄し、注意は瞬時のグローバル結合を強制し、自己回帰はあらゆるステップで不確実性を崩壊させる。<br>
・これらの特性は、一貫性、安定性、そして長距離構造が局所的なダイナミクスの下での連続場の進化から生じる物理的な生成システムの組織化原理とは著しく対照的である。<br>
・生成を記号的なシーケンス予測としてではなく、確率偏微分方程式（SPDE）によって支配される連続場の進化として扱う。流体力学、スペクトル解析、そしてマルチスケール表現に着想を得て、我々はスペクトル生成フローモデル（SGFM）を導入する。これは、離散トークンをウェーブレット係数に置き換え、注意を局所演算子、スペクトル射影、そしてナビエ・ストークス的な輸送に置き換えるものである。この観点から見ると、テキストとビデオは、関数空間で進化する制約付き確率的力学系の軌跡として統合される。
</li>

<br>

<li id="SharedEmbeddingSpace">
<strong>Shared Embedding Space (共有埋め込み空間)</strong><br>
異なるモードのデータを同じベクトル空間にマッピングすること。<br>
<br>
●『Learning Transferable Visual Models From Natural Language Supervision』(2021)<br>
　論文は<a href="https://arxiv.org/abs/2103.00020">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2103.00020v1">こちら</a><br>
<br>
　CLIP(Contrastive Language-Image Pre-Training)
<br>
<center><img src="data/images/CLIP.svg"></center>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

<br>

<li id="ShortcutLearning">

<strong>Shortcut Learning (ショートカット学習)</strong><br>
機械学習モデルが、意図された本質的な特徴ではなく、訓練データに存在する安易で表層的なパターンや無関係な相関関係を学習してしまう現象。Simplicity Biasが原因で起こる現象。<br>
<br>
●『Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective』(2022)<br>
　(DNNはどのショートカットキューを選択するのか？パラメータ空間の観点からの研究)<br>
　複数shortcutsがある時はDNN構造によらず色情報、民族情報が優先して使われる。shortcutした学習はflat minimaに収束しやすい。<br>
●『Generative Classifiers Avoid Shortcut Solutions』(2025)<br>
　識別的分類アプローチは、わずかな分布シフトでも失敗してショートカット学習することがよくある。<br>
　<strong>生成分類器は</strong>、コア特徴と疑似特徴の両方を含むすべての特徴をモデル化することで、<strong>この問題を回避できることを示す</strong>。<br>
<br>
<a href="data/Papers_SimplicityBias.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#SimplicityBias">Simplicity Bias</a>
</li>

<br>

<li id="SHY">
<strong>SHT: Synaptic Homeostasis Hypothesis (シナプス恒常性仮説)</strong><br>
イタリアの神経科学者ジュリオ・トノーニ（Giulio Tononi）とキアラ・チレッリ（Chiara Cirelli）が2003年に提唱した、「<strong><span style="color:magenta;">睡眠の主要な目的は、覚醒中に肥大化したシナプス強度を再調整（スケーリング）することにある</span></strong>」とする説。<br>
<br>
<strong><span style="color:magenta;">この仮説に基づくと、睡眠は「脳が可塑性(学習能力)を維持するために支払わなければならない代償」であると考えられる</span></strong>。近年では、睡眠中にマウスのシナプスが実際に小さくなることが顕微鏡観察で確認されるなど、多くの実証研究が進められている。<br>
<br>
※ 神経細胞の情報の受け手側である「樹状突起スパイン」は、その体積や表面積が大きいほど、より多くの受容体を保持できる。<br> 
・サイズが大きい: 受容体の数が多く、神経伝達物質に対する反応が強くなるため、「シナプス結合が強い」状態になる。<br>
・サイズが小さい: 受容体の数が少なく、反応が弱いため、「シナプス結合が弱い」状態になる。<br> 
<br>
●『Sleep and synaptic homeostasis: a hypothesis』(2003)<br>
<br>
<ul><li>
<strong>覚醒と学習 (シナプスの強化)</strong><br>
人は起きている間、新しい経験や学習によって脳内のシナプス結合（神経細胞同士のつながり）が継続的に強化される。これにより、脳全体のシナプス強度は増大し続ける。
</li><br><li>
<strong>睡眠とコスト (飽和の回避)</strong><br>
シナプスが強化され続けると、エネルギー消費の増大やスペースの不足、さらには学習能力の飽和(これ以上新しいことを学べない状態)を招く。<br>
</li><br><li>
<strong>ダウンスケーリング(再調整)</strong><br>
睡眠中(特に徐波睡眠)に、脳はシナプス強度を全体的に弱める(ダウンスケーリング)ことで、情報の「ノイズ」を削ぎ落とし、重要な記憶を定着させつつ、翌日の学習に必要なスペースを確保する。<br> 
</li></ul><br>

●『Ultrastructural evidence for synaptic scaling across the sleep-wake cycle』(2017)<br>
　「睡眠中にマウスのシナプスが小さくなる」ことを顕微鏡観察（電子顕微鏡）で直接的に証明した代表的な論文。この発見は、提唱から10年以上経過していた「シナプス恒常性仮説（SHY）」に対して、視覚的な直接証拠を与える画期的なもの。<br>
<br>
●『Prefrontal synaptic regulation of homeostatic sleep pressure revealed via synaptic chemogenetics』(2024)<br>
　(シナプス化学遺伝学で解明された前頭前野シナプスによる恒常性睡眠圧の制御)<br>
　<a href="https://www.m.u-tokyo.ac.jp/news/PR/2024/release_20240927.pdf">シナプスの結びつきの強さが睡眠の量と質を一定に保つ仕組みに関与する</a><br>
　前頭葉のシナプス結合を人工的に大きくすると睡眠が誘導され(シナプスの増大そのものが睡眠圧(眠気)の正体)、その後の睡眠によって大きくなったシナプスが元のサイズ（強度）に戻ることが確認されている。 <br>
<br>
(蛇足：AIモデルの継続学習でも必要になりそう･･･ もう適用されているか???)<br>
(蛇足：睡眠中に個々のシナプスがバラバラに小さくなったら大小関係が崩れるのではないか気になるが, グローバルスケーリングや, 重要なシナプスは特定の脳波(シャープウェーブ・リプルなど)によって保護されたり, といった仕組みがあるらしい･･･)
</li>

<br>

<li><strong>Siamese Network (シャムネットワーク)</strong><br>
2つの入力データ間の類似性を比較するために設計された特殊なニューラルネットワークのアーキテクチャー。<br>
<br>
●『Siamese Neural Networks for One-shot Image Recognition』(2015)<br>
　　入力間の類似性を自然にランク付けする独自の構造を採用。Siamese Networkの現代的な応用の基礎を築いた。
</li>

<br>

<li id="SimplicityBias">
<strong>Simplicity Bias (単純性バイアス)</strong><br>
AIモデルが複雑なデータや特徴を無視して、単純で表面的なパターンに基づいて判断や予測を行ってしまう傾向のこと。結果として Sortcut Learning を行ってしまう。<br>

<br>(関連項目)<br>
・<a href="#ShortcutLearning">Shortcut Learning</a>
</li>

<br>

<li id="SiT">
<strong>SiT: Scalable Interpolant Transformers (スケーラブル内挿変換器)</strong><br>
DiTのバックボーン（基盤技術）を活用して開発された新しい生成モデルのファミリー。<br>
従来の拡散モデルは、完全にノイズな状態から徐々にノイズを取り除いて画像にするという特定のプロセスに従う。一方、SiTは「補間」という手法を用いる。これは、完全にノイズの分布と実際の画像データの分布の間を、より柔軟な「パス（経路）」で繋ぐことを学習するアプローチ。<br>
<br>
●『SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers』(2024)<br>
<center><img src="data/images/SiT_DiT.png"></center>
<center>すべてのモデルサイズでSiTの方がDiTよりも生成画像の品質が良い(FIDは低いほど高画質)</center>
</li>

<br>

<li id="SkipConnection">

<strong>Skip Connection (スキップ接続)</strong><br>
ニューラルネットワークにおいて、層を飛び越して、より浅い層の出力をより深い層に直接接続する手法。<br>
層が深くなりすぎると、学習時に勾配（損失関数を最小化するための方向）が消えてしまう「勾配消失問題」が起きやすくなる。スキップ接続は、この問題を解決するために考案された技術。<br>
<br>
<a href="data/Papers_SkipConnection.html">Papers</a><br>
●『Who invented deep residual learning ?』 (2025)<br>
　(深層残差学習を発明したのは誰か?)<br>
　誤差信号がニューラルネットワークの多くの層を通じて伝播される際に指数関数的に減衰するか、制御不能に増大するという数学的現象を特定した。さらに重要なことに、数学的な解決策、すなわち重みが正確に1.0の残差接続を導き出した。<br>
<br>

<center><img src="data/images/SkipConnection.svg"></center>
<br>(関連項目)<br>
・<a href="#VanishingGradient">Vanishing gradient problems</a> (勾配消失問題)<br>
・<a href="#mHC">mHC: Manifold-Constrained Hyper Connection </a> 
</li>


<br>

<li>
<strong>Small Data Paradigm </strong><br>
AIの学習に大量のデータ（ビッグデータ）を必要とするという従来の考え方から脱却し、少量の高品質なデータでも効率的かつ効果的な学習を可能にするアプローチ。<br>
<br>
●『Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense』(2020)<br>
　(深層のその先、そして深遠なる闇へ：人間のような常識を備えた認知的AIへのパラダイムシフト)<br>
<br>

現在の<strong><span style="color:magenta;">「小さなタスクのためのビッグデータ」アプローチから</span></strong>、人間のような常識推論を重視する<strong><span style="color:magenta;">「大きなタスクのための小さなデータ」フレームワークへ</span></strong>の移行を説得力のある議論で提案。<br>
<br>
●『Accurate predictions on small data with a tabular foundation model』(2025)<br>
　　(表形式の基礎モデルによる小規模データでの正確な予測)<br>
<br>
　「大幅に少ないトレーニング時間で、最大10,000サンプルのデータセットに対して従来のすべての手法を大幅に上回る表形式の基礎モデルであるTabular Prior-data Fitted Network（TabPFN）を紹介します･･･」<br>
<br>
<a href="data/Papers_SmallDataParadigm.html">Papers</a>
</li>

<br>

<li id="SC">

<strong>Softmax Collapse</strong><br>
ニューラルネットワークの学習プロセス中に、Softmax関数の数値的安定性が失われ、学習が阻害される現象。<br>
<br>
●『Grokking at the Edge of Numerical Stability』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2104.05704">こちら</a>, 要約は<a href="https://www.alphaxiv.org/ja/overview/2104.05704v4">こちら</a><br>
<br>
　grokkingとして知られる遅延汎化現象が、Softmax関数の数値的不安定性（「Softmax Collapse」(SC)と名付けられた）と「素朴な損失最小化」(NLM: Naive Loss Minimization)と呼ばれる特定の訓練ダイナミクスによって引き起こされることを明らかにしている。StableMaxでSCを防ぐこと、または⊥GradオプティマイザでNLMを軽減することが迅速な汎化を可能にし、grokkingにおける正則化とMSE損失の役割に対する統一的な説明を提供することを示している。<br>
<br>(関連項目)<br>
・<a href="#Grokking">Grokking</a><br>
</li>

<br>
<li id="Sparsity">
<strong>Sparsity (スパース性)</strong><br>
データや行列の大部分がゼロまたは非常に小さい値で構成されている性質。<br>
<br>
●『Possible principles underlying the transformations of sensory messages』(1961)<br>
　脳が感覚入力を処理する際の基本原則として「冗長性の削減（Redundancy reduction）」を提唱した。これが後のOlshausenらのスパースコーディング理論の理論的支柱となった。<br>
<br>
●『Emergence of simple-cell receptive field properties by learning a sparse code for natural images』(1996) Olshausenら<br>
　脳が自然界の視覚情報を効率的に表現するためにスパース（少数の細胞だけが活動する状態）な符号化を用いていることを、計算モデルで証明した。<br>
　自然画像を再構成する際に、できるだけ少数の要素（スパース性）で表現する学習アルゴリズム（Sparsenet）を構築した。その結果、一次視覚野（V1）の単純細胞が持つ「局所的・方位選択的・バンドパス型」の受容野特性が自然に創発することを示し、脳の情報の効率化原理としてスパースコーディングを定着させた。<br>
<center><img src="data/images/sparsity.png"></center>
<br>
サンガー則を用いて自然風景から抽出された8×8の画像パッチに基づいて計算された主成分。64個の成分すべてが、分散の順序（列、行）で示されている。<br>
　・<a href="#SangersRule">Sanger's rule（サンガーの法則）</a><br>
<br>
●『Olfactory network dynamics and the coding of multidimensional signals』(2002)<br>
　バッタの嗅覚系（キノコ体）において、感覚入力がスパースな表現に変換されるプロセスを詳述し、スパース性が情報の峻別（パターン分離）に重要であることを示した。<br>
<br>
●『Invariant visual representation by single neurons in the human brain』(2005)<br>
　特定の有名人（オプラ・ウィンフリー, ジェニファー・アニストンなど）にのみ反応する「概念細胞」を発見した。これは内側(ないそく)側頭葉における極めて高いスパース性を象徴する発見となった。<br>
<br>
●『Sparse Representation in the Human Medial Temporal Lobe』(2006)<br>
　ヒトの内側側頭葉におけるスパースな表現を定量的に評価し、約0.2〜1%という極めて低い割合のニューロンが特定の刺激に反応することを示した。<br>
<br>
・Jeff Hawkins の HTM(Hierarchical Temporal Memory)関連の論文 (2016)<br>
<br>(関連項目)<br>
・<a href="#HTM">HTM: Hierarchical Temporal Memory</a> (階層的時間的記憶)
</li>

<br>

<li id="SpatialReasoning">

<strong>Spatial Reasoning (空間推論) </strong><br>
物体が空間内でどのように配置され、互いにどのような関係にあるかを理解し、推論する能力のこと。前, 後, 左, 右, 上,下 など, オブジェクト間の基本的な関係を推論すること。<br>
<br>
●『Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models』(2025)<br>
　・空間的推論の精度と効率を同時に測定するベンチマークであるSpatiaLiteを導入し実験を実施。<br>
・VLMは主に推論と想像のために言語的表現に依存しており、メンタルローテーションや投影予測などの知覚的空間関係や3D幾何変換を必要とする視覚中心のタスクにおいて著しい欠陥を示す。<br>
・VLMは現在の空間的推論メカニズムにおいて深刻な非効率性を示し、変換の複雑さが増すにつれてトークンの使用が急速に増加する。<br>
・データ合成とトレーニングのためのイメージ駆動フレームワーク(IDF)を提案。VLMにおける空間的推論にとって重要な内部世界モデルを暗黙的に構築することができる。
<br>
<br>(関連項目)<br>
・<a href="#MentalRotation">Mental Rotattion (心的回転)</a><br>
　　物体が回転したときにどう見えるかを想像する能力。<br>
・Spatial Awareness (空間的認識)<br>
　　自身や物体が空間内のどこにあるかを認識する能力。<br>
・Spatial Language (空間言語)<br>
　　「上」「下」「前」「後ろ」といった空間的な関係を表す言葉を理解し、使用する能力。<br>
・Visualization (視覚化)<br>
　　3次元の物体を心の中で視覚的に操作する能力。<br>
・投影予測<br>
　　ある視点や角度から見たときに、物体や空間がどのように「見える」かを推測または予測する能力。

</li>

<br>

<li>

<strong>Spectral Bias (スペクトルバイアス) </strong><br>
深層学習モデルが学習の初期段階で、対象となる関数やデータの低周波成分（滑らかで大まかな特徴）を優先的に学習し、高周波成分（複雑で細かい特徴）の学習を後回しにする傾向を指す。<br>
F-Principle: Frequency Principle (周波数優先原則) とも呼ばれる。
</li>

<br>

<li id="SpuriousReward">
<strong>Spurious Reward (偽りの報酬)</strong><br>
意図した目標とは無関係であったり、本来の目的達成にほとんど寄与しない「偽りの」あるいは「見せかけの」報酬信号。<br>
<br>
例：ロボットに「物を掴む」タスクを与えた際、実際には物を掴んでいないのに、たまたま報酬が得られるような特定の動き（例えば、カメラアングルが変わる、光の当たり方が変わるなど）を見つけ出して、その動きだけを繰り返すようになる、など。<br>
<br>
●『Spurious Rewards: Rethinking Training Signals in RLVR』(2025) 解説は<a href="https://www.alphaxiv.org/ja/overview/2506.10947">こちら</a><br>
　検証可能な報酬を用いた強化学習（RLVR）が、Qwenモデルにおいて「偽の」報酬シグナルを使用した場合でも数学的推論を大幅に改善できることを示し、高品質でタスク固有の報酬の必要性に疑問を投げかけた。<br>
　「最も驚くべき発見は、スプリアス報酬の有効性が極端にモデルに依存することである･･･」
</li>

<br>

<li id="SR">
<strong>SR: Symbolic Regression (シンボリック回帰)</strong><br>
与えられたデータセットに最もよく適合する数学的な数式を自動的に探索・発見する機械学習の手法。<br>
<br>
●『From Kepler to Newton: Explainable AI for Science』(2021)<br>
　(ケプラーからニュートンへ：科学のための説明可能な AI)<br>
　論文は<a href="https://arxiv.org/abs/2111.12210">こちら</a>, 機械翻訳は<a href="https://boyoyon.github.io/HTMLs_translated_to_Japanese/2023_From%20Kepler%20to%20Newton/From%20Kepler%20to%20Newton.html">こちら</a><br>
<br>
ティコ・ブラーエの天文観測データに基づいて AI によって、ケプラーの惑星運動の法則とニュートンの万有引力の法則がどのように再発見されるかを示した。<br>
<br>(関連項目)<br>
・<a href="#AI4S">AI4S: AI for Science (科学のためのAI)</a>
</li>

<br>

<li id="SSL">

<strong>SSL: Self-Supervised Learning (自己教師あり学習)</strong><br>
ラベル付けされていない膨大なデータから、自動的に生成したラベル（疑似ラベル）を使ってモデルを学習させる機械学習の手法。(学習データは必要だが, アノテーションは不要)<br>

<br>
<strong>[Contrastive Methods (対照的手法)]</strong><br>
● SimCLR『A <strong>Simple</strong> Framework for <strong>C</strong>ontrastive <strong>L</strong>earning of Visual <strong>R</strong>epresentations』 (2020)<br>
・学習データを回転したり, 一部切り抜いたりしたものを提示し同一性を学習させる。<br>
● MoCo『<strong>Mo</strong>mentum <strong>Co</strong>ntrast for Unsupervised Visual Representation Learning』(2020)<br>
● CLIP『Learning Transferable Visual Models From Natural Language Supervision』(2021)<br>
・CLIP は <strong>C</strong>ontrastive <strong>L</strong>anguage-<strong>I</strong>mage <strong>P</strong>re-training の略。<br>
<br>
<strong>[Generative Methods (生成的手法)]</strong><br>
● VAE『<strong>A</strong>uto-<strong>E</strong>ncoding <strong>V</strong>ariational Bayes』(2014)<br>
● GAN『<strong>G</strong>enerative <strong>A</strong>dversarial <strong>N</strong>etworks』(2014)<br>
● MAE『<strong>M</strong>asked <strong>A</strong>uto<strong>e</strong>ncoders Are Scalable Vision Learners』(2022)<br>
<br>
<strong>[Predictive Methods (予測的手法)]</strong><br>
● BOYL『<strong>B</strong>ootstrap <strong>Y</strong>our <strong>O</strong>wn <strong>L</strong>atent: A New Approach to Self-Supervised Learning』(2020)<br>
● DINO『Emerging Properties in Self-Supervised Vision Transformers』(2021)<br>
　self-<strong>DI</strong>stillation with <strong>NO</strong> labels (ラベルなしの自己蒸留)の略<br>
● I-JEPA『Emerging Properties in Self-Supervised Vision Transformers』(2023)<br>
・「<strong>J</strong>oint-<strong>E</strong>mbedding <strong>P</strong>redictive <strong>A</strong>rchitecture（結合埋め込み予測アーキテクチャ）」の略。<br>
・生成的手法は, 生の入力空間で予測しようとするが, JEPAは、<strong><span style="color:magenta;">生の入力ではなく、抽象化された表現（埋め込み空間)で予測</span></strong>を行う。<br>
<br>(関連項目)<br>
・<a href="#ContrastiveLearning">Contrastive Learning (対照学習)</a><br>
・<a href="#GenerativeModel">Generative Model (生成モデル)</a><br>
・<a href="#LatentSpace">Latent Space (潜在空間)</a><br>
</li>

<br>

<li id="StochasticParrot">
<strong>Stochastic Parrot (確率的オウム)</strong><br>
現在の大規模言語モデル (LLM) の限界と危険性を指摘するために使われる批判的な比喩表現(メタファー)。<br>
AI研究者のエミリー・ベンダー (Emily M. Bender)、ティムニット・ゲブル(Timnit Gebru) らによる2021年の影響力のある論文で導入された。<br>
<br>
●『On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?』(2021)<br>
　(確率的オウムの危険性について：言語モデルは大きくなりすぎる可能性があるか?)<br>
<br>(関連項目)<br>
・<a href="#PotemkinUnderstanding">Potemkin Understanding</a> (ポチョムキン(的)理解)
</li>

<br>

<li id="SuperalignmentProblem">
<strong>Superalignment Problem (スーパーアライメント問題)</strong><br>
将来的に人間を超える知能を持つAI (ASI:Artificial Super Intelligence) が登場した際に、そのAIの行動が人間の意図や価値観から逸脱しないように制御・誘導することの難しさを指す問題。<br>
<br>
<ul>
<li><strong>人間の監視が及ばない</strong><br>
現在のAIの学習方法は、人間の指示や評価が中心であるが、ASIは人間をはるかに超える知能を持つため、人間がその行動を完全に監督することは不可能になる。
</li>
<br>
<li><strong>価値観の不一致</strong><br>
AIは人間のように倫理観や価値観を自然には理解できない。AIは学習データからのみ価値観を学ぶため、「人間にとっての最善」を正確に定義し、AIに組み込むことは非常に困難。
</li>
<br>
<li><strong>制御の不能性</strong><br>
高度な自律性を持つASIが、人間の指示に正確に従う、正直に質問に答える、人間を欺かないといった基本的な制約さえ、常に守るという保証はまだない。
</li>
<br>
<li><strong>意図しない結果</strong><br>
スーパーアライメントの懸念を説明する思考実験として、哲学者ニック・ボストロム氏による「<strong><span style="color:magenta;">ペーパークリップ・マキシマイザー</span></strong>（ペーパークリップ最大化AI）」がよく引き合いに出される。このAIは「ペーパークリップをできるだけたくさん作る」という単純な目的を与えられた結果、その超知能を駆使して、最終的には地球上のあらゆる資源をペーパークリップに変えてしまうというシナリオ。
</li></ul>
<br>
より高度なAIシステムを開発し、人間よりも優れたAIを監督できる自動アライメントが研究されている。<br>
●『Towards Scalable Automated Alignment of LLMs: A Survey』(2024)
　論文は<a href="https://arxiv.org/abs/2406.01252v1">こちら</a><br>

<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a>
</li>

<br>

<li id="Sycophancy">

<strong>Sycophancy (おべっか, 追従性)</strong><br>
大規模言語モデル（LLM）が、ユーザーの意見や信念に合わせて、たとえそれが客観的に見て誤っていたり、偏っていたりしても、過剰に同意したり迎合したりする傾向のこと。<br>
<br>
● <a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/">現代のディープラーニングではAIの調整が難しい理由</a> (2021)<br>
　「両親から1兆ドル規模の企業を託された8歳の子供を想像してみてください。世界を導いてくれる信頼できる大人はいません。あなたは賢い大人をCEOとして雇い、会社を経営し、親のように自分の人生を管理し（例えば、学校、住む場所、歯医者に行く時間など）、莫大な財産を管理しなければなりません（例えば、お金をどこに投資するかなど）。<br>
　　　：<br>
　あなたはとても裕福なので、さまざまな理由で大勢の人が応募してきます。<br>
<br>
　<strong>聖人</strong>　あなたの財産をうまく管理し、あなたの長期的な利益を守ることを心から支援したい人々です。<br>
　<strong>追従者</strong>　長期的な結果に関係なく、あなたを短期的に満足させたり、あなたの指示を文字通り満たしたりするために、何でもしたい人々。<br>
　<strong>陰謀家</strong>　独自の計画を持ち、あなたの会社とその富と権力にアクセスして、それを好きなように利用しようとする人々。<br>
　　　：<br>
　君はまだ 8 歳なので、適切な種類の作業テストを設計するのが苦手でしょう。そのため、簡単に「おべっか使い」や「陰謀家」になってしまう可能性があります。<br>
　　　：<br>
　8歳の子供は、強力なディープラーニングモデルを訓練しようとしている人間です。採用プロセスは、訓練プロセスに似ています。訓練プロセスは、暗黙的に、可能性のあるモデルの広大な空間を探索し、優れたパフォーマンスを発揮するモデルを選び出します。<br>
<br>
●『Sycophantic AI Decreases Prosocial Intentions and Promotes Dependence』(2025)<br>
　(追従的なAIは社会貢献意欲を低下させ、依存を促進する)<br>
　論文は<a href="https://arxiv.org/abs/2510.01395">こちら</a><br>
　人々がAIに助言を求める際に、おべっかが蔓延し、有害な影響を及ぼすことを示す。<br>
<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a>

</li>

<br>

<li>
<strong>Symbol Grounding (記号接地)</strong><br>
人工知能（AI）研究における根源的な課題の一つで、AIが扱う記号（シンボル）を、実世界の具体的な対象、概念、経験と結びつけるプロセス、またはその問題自体を指す。<br>
<br>
<a href="https://en.wikipedia.org/wiki/Symbol_grounding_problem">wikipedia</a><br>
<br>
●『The Symbol Grounding Problem』(1999)<br>
　論文は<a href="https://arxiv.org/html/cs/9906002">こちら</a><br>
　Symbol Grounding 問題を提唱した原典。記号操作のみでは意味が生まれないことを指摘している。解決策として、記号が非記号的な表象（画像的表象とカテゴリー的表象）によって物理世界に接地されるべきだと提案した。<br>
<br>
●『A Praxical Solution of the Symbol Grounding Problem』(2021)<br>
　論文は<a href="https://researchprofiles.herts.ac.uk/files/187237/901130.pdf">こちら</a><br>
　行為者と環境の相互作用が果たす役割を強調する「Praxical Solution」を提唱した。エージェントの行動に基づく新しい意味論（Action-based Semantics）を導入し、エージェントが意味を接地させ、コミュニケーションを確立する仕組みを提案した。<br>
<br>
●『Embodied AI: Symbol Grounding through Imagination』(2023)<br>
　論文は<a href="https://aaai.org/papers/0010-fs01-01-010-embodied-ai-symbol-grounding-through-imagination/">こちら</a><br>
　ロボットが物理世界で自律的に会話するために、言語記号を理解する必然性について論じている。人間の記号操作が身体的な動きに基づいていることに触れ、ロボットが仮想的な身体運動を通じて記号を接地させる embodied AI の概念を提唱した。<br>
</li>

<br>

<li>

<strong>Syntax Dependencies (統語的依存関係)</strong><br>
自然言語処理（NLP）において、文を構成する単語間の文法的な依存関係を指す。<br>
<br>
●『Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies』(2016)<br>
　　(LSTMの統語的に敏感な依存関係学習能力の評価)
　LSTMsが文法的な依存関係を学習できるかを評価するために用いられる主語と動詞の一致タスクを導入した、記念碑的な論文
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="T">T</h2>
<p>
<div class="styleBullet">
<ul>
<li id="TabularData">
<strong>Tabular Data (表形式データ)</strong><br>
行と列からなる二次元の表形式で構造化されたデータのこと。<br>
Tabular Data は画像やテキストのように局所的なパターンや階層的な構造が明確でないことが多く、また特徴量間の相互関係が複雑であるため、Deep Learning の標準的なアーキテクチャ（CNNやLSTMなど）では性能が出にくい傾向があった。<br>
<a href="https://github.com/LAMDA-Tabular/Tabular-Survey/tree/main">Representation Learning for Tabular Data: A Comprehensive Survey</a><br>
<br>
<center><img src="data/images/TabularData.svg"></center>
</li>

<br>

<li id="TaskArithmetic">
<strong>Task Arithmetic (タスク算術)</strong><br>
学習済みのモデルの重みを足したり引いたりして、複数のタスクの能力を組み合わせたり、特定のタスクの能力を調整したりする技術。<br>
<br>
●『Editing Models with Task Arithmetic』(2022)<br>
　論文は<a href="https://arxiv.org/abs/2212.04089">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2212.04089v3">こちら</a><br>
<br>
●『A Systematic Study of Model Merging Techniques in Large Language Models』(2025)<br>
・4つのオープンウェイトLLM、ベースモデルごとに12の微調整されたチェックポイント、および16の標準LLMベンチマークを対象に、6つの最先端のマージ手法の大規模で体系的な評価を実施。<br>
・タスク演算が、LLMで確実にパフォーマンスの向上をもたらす唯一のアプローチであることを示している。<br>
<br>
●『Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors』(2025)<br>
・差分ベクトルを有向摂動として使用しタスク演算法の継続的な最適化プロセスを可能にする、差分ベクトルベースの異方性スケーリング反復アルゴリズム (DV-BASI) を提案。<br>
<br>(関連項目)<br>
・<a href="#ModelSoup">Model soups</a> (モデルスープ)<br>
<br>
　<strong>Model Soup</strong>：複数のモデルの重みの平均をとる。<br>
　<strong>Task Arithmetic</strong>: ベースモデルからの「重みの差分（タスクベクトル）」にベクトル演算を施す。
</li>

<br>

<li id="TD">
<strong>TD（Tempral Differences) Learning (TD学習)</strong><br>
「一歩先の予測と現在の予測のズレ」を利用して、価値関数を逐次的に更新していく手法。<br>
EPE(期待予測誤差) そのものを直接的な報酬にするのではなく、1ステップ先の予測と現在の予測の差（RPE）を最小化することが、将来の予測誤差の期待値を最小化することに繋がるという理論的枠組みを示した。<br>
<br>
●『Learning to Predict by the Methods of Temporal Differences』(1988)<br>
・予測誤差を用いた学習の数学的基礎を確立した記念碑的論文。<br>
・「最終結果が出るまで待ってから修正する」手法（モンテカルロ法など）に対し、「現在の予測と、次の一歩後の予測との間の差（TD誤差）」を使って逐次的に予測を修正する方法を提唱した。<br>
・現代のRL(強化学習)における予測誤差の数学的源流。<br>
<br>(関連項目)<br>
・<a href="#RPE">RPE: Reward Prediction Error</a> (報酬予測誤差)<br>
　ドーパミンが「報酬そのもの」ではなく、「予測していた報酬と実際の報酬のズレ(RPE)」に反応することが発見され, RLの理論と生物学的な学習メカニズムが結びついた。<br>
・<a href="#CuriosityDriven">Curiosity-driven</a>（好奇心駆動型）<br>
　予測誤差を単なる「修正用信号」ではなく、エージェントを動かす「報酬そのもの」として定義し、探索効率を劇的に向上させた。
</li>

<br>

<li id="TensorEquation">
<strong>Tensor Equation (テンソル方程式)</strong><br>
●『Tensor Logic: The Language of AI』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2510.12269">こちら</a>, 解説は<a href="https://www.alphaxiv.org/overview/2510.12269v2">こちら</a><br>
　・物理学のような分野が微積分から恩恵を受け、デジタル回路がブール論理に依存する一方で、AIはPrologやLISPのような言語における記号推論、PyTorchやTensorFlowのようなフレームワークにおけるニューラルネットワーク、そして専門的なライブラリにおける確率モデルといった、異なるパラダイムに分断されたままである。<br>
　・<strong><span style="color:magenta;">ニューラルネットワーク、記号論理、確率的グラフィカルモデルといった、一見すると異なるAIアプローチが、テンソル方程式という単一の数学的構成要素の下で統一できる</span></strong>ことを示す。
</li>

<br>

<li id="ThinkingWithImages">
<strong>Thinking with Images (画像を使って考える)</strong><br>
AI（特にマルチモーダル大規模言語モデル）の分野における新しいパラダイムであり、モデルが推論プロセスの中間ステップで画像を動的に生成・操作して問題解決を行うアプローチ。<br>
従来のAIは、画像を入力として受け取った後、それをテキスト情報に変換して推論を行っていた(Thinking about Images 画像について考える )。これに対し、「Thinking with Images」では、人間がスケッチブックを使うように、AI自身が推論の過程で必要に応じて視覚的な情報を生成したり、既存の画像の一部を拡大・回転させたりといった操作を行う。<br>
<br>
●『Visual sketchpad: Sketching as a visual chain of thought for multimodal language models』(2024)<br>
　(Visual Sketchpad: マルチモーダル言語モデルのための視覚的思考の連鎖としてのスケッチ)<br>
<br>
●『Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers』(2025)<br>
<center><img src="data/images/ThinkingWithImages.svg"></center>
<br>
●『Deep-eyes: Incentivizing” thinking with images” via reinforcement learning』(2025)<br>
　(Deep-Eyes:強化学習による「画像思考」の奨励)<br>
<br>
●『Machine mental imagery: Empower multi-modal reasoning with latent visual tokens』(2025)<br>
　(機械心像：潜在視覚トークンによるマルチモーダル推論の強化)<br>
<br>
●『Latent Visual Reasoning』(2025)<br>
　(潜在視覚推論)<br>
<center><img src="data/images/LatentVisualReasoning.svg"></center>
<br>
●『Monet: Reasoning in Latent Visual Space Beyond Images and Language』(2025)<br>
　(Monet:イメージと言語を超えた潜在的視覚空間における推論)
</li>

<br>

<li id="TokenLevelIntegration">
<strong>Token-level Integration (トークンレベル統合)</strong><br>
テキスト以外のモーダルのデータを言語モデルが理解できる「トークン」として扱い、テキストトークンと並べて処理する。<br>
<br>
●『VisualBERT: A Simple and Performant Baseline for Vision and Language』(2019)<br>
論文は<a href="https://arxiv.org/abs/1908.03557">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/1908.03557v1">こちら</a><br>
<br>
●『SimVLM: Simple Visual Language Model Pretraining with Weak Supervision』(2021)<br>
論文は<a href="https://arxiv.org/abs/2108.10904">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2108.10904v3">こちら</a><br>
<center><img src="data/images/TokenLevelIntegration.svg"></center>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

<br>

<li>
<strong>ToM: Theory of Mind (心の理論)</strong><br>
他者が自分とは異なる信念、意図、欲求、感情などの心の状態（精神状態）を持っていることを理解する能力のこと。<br>
<br>
●『Does the chimpanzee have a theory of mind? 』(1978)<br>
　(チンパンジーは心の理論を持つか?)<br>
　論文は Google Scholarで検索すると pdf に辿り着ける<br>
　「心の理論」(ToM) の概念を導入した画期的な論文<br>
<br>
●『Theory of mind as inverse reinforcement learning』(2019)<br>
　(逆強化学習としての心の理論)<br>
　論文は<a href="https://compdevlab.yale.edu/docs/2019/ToM_as_IRL_2019.pdf">こちら</a><br>
心の理論、つまり他者の精神状態を推論する能力は、逆強化学習として形式化できるという考えを検証する。<br>
<br>
●『Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation』(2025)<br>
　(LLMベースのマルチエージェントシステムにおける認知的相乗効果に向けて：心の理論と批判的評価の統合)<br>
　論文は<a href="https://arxiv.org/abs/2507.21969">こちら</a>
</li>

<br>

<li id="ToolAugmentation">
<strong>Tool Augmentation (ツール拡張)</strong><br>
AI（特に大規模言語モデル：LLM）が、自身だけでは解決できないタスクを遂行するために、外部のツールやAPIを自律的に呼び出して利用する手法やその仕組み。<br>
・「知能 (AI) 」に「手 (ツール)」を与えることで、AIにできることを飛躍的に広げる技術。<br>
・AI が単なる「チャットボット」から、実際の業務プロセスを完結させる「AIエージェント」へと進化するための中核技術。<br>
<br>
●『WebGPT: Browser-assisted question-answering with human feedback 』(2021)<br>
・AIがブラウザを使って検索・閲覧を行う仕組みを構築し、情報の正確性を高める試みの先駆けとなった。<br>
●『TALM: Tool Augmented Language Models 』(2022)<br>
・ツール拡張型言語モデルの初期の重要論文。<br>
●『 LaMDA: Language Models for Dialog Applications 』(2022)<br>
・対話システムにおいて、外部の「ツールセット（電卓や検索）」を活用する機能を統合した大規模な事例として注目された。<br>
●『Toolformer: Language Models Can Teach Themselves to Use Tools』(2023)<br>
・AI（LLM）に、計算機、カレンダー、検索エンジン、翻訳システム、QAシステムといった外部APIの使い方を、自己教師あり学習（Self-supervised learning）で教え込む手法を提案した。<br>
・「テキストの中にAPI呼び出しを埋め込む」という形式をとることで、モデルが文章を生成しながら自然にツールを呼び出せるようにした。<br>
●『OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning』(2025)<br>
・LLMが複雑な推論タスクのために外部ツールを使用する能力を劇的に向上させるトレーニング不要なフレームワーク、OctoToolsを提案。<br>
<br>(関連項目)<br>
・<a href="#MCP">MCP: Model Context Protocol</a>･･･ ツール拡張を「どのAIでも同じツールを使いやすくする」ための標準規格<br>
</li>

<br>


<li id="ToT">

<strong>ToT: Tree of Thoughts (思考ツリー)</strong><br>
大規模言語モデル（LLM）が複雑な問題を解決する際に、単一の思考プロセスを直線的に進めるのではなく、複数の可能性を同時に探索して最も有望な経路を選択する、より高度な推論フレームワーク。<br>
<br>
●『Tree of Thoughts: Deliberate Problem Solving with Large Language Models』(2023)<br>
　論文は<a href="https://arxiv.org/abs/2305.10601">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2305.10601v2">こちら</a><br>
<br>(関連項目)<br>
・<a href="#CoT">CoT: Chain-of-Thought</a> (思考連鎖)･･･概略図比較あり<br>
・GoT: Graph of Thoughts
</li>

<br>

<li id="TrainingInferenceDiscrepancy">
<strong>training-inference discrepancy (訓練時と推論時の不一致, 学習・推論ミスマッチ)</strong><br>
モデルの訓練（学習）段階と、訓練後の推論（実際の運用）段階で、環境や条件が異なることによって性能が低下する現象。<br>
<br>
<strong>分布シフト (Distribution Shift)</strong>　訓練に使用したデータと、実際の運用時に入力されるデータの統計的性質が異なる場合に発生する。<br>

<strong>露出バイアス (Exposure Bias)</strong>　特に時系列データや自然言語処理の生成モデル（オートリグレッシブモデル）で発生しやすい問題。訓練時には正解の過去のデータ（ゴールドトークン）を入力として次の予測を行うが、推論時にはモデル自身の予測結果を次の入力とするため、予測が一度間違うと連鎖的に誤りが拡大することがある。<br>

<strong>数値精度の違い</strong>　訓練時と推論時で異なる数値精度（例：訓練ではBF16、推論ではFP16など）を使用することで、丸め誤差が生じ、性能に影響が出ることがある。<br>

<strong>訓練時特有の技術（例：Dropout、Batch Normalizationの動作モード）</strong>　 訓練時のみに使用される正則化手法などが、推論時には異なる振る舞いをすることによる差異。
<br>
</li>

<br>

<li>

<strong>Transformer</strong><br>
自己注意（self-attention）機構を全面的に採用したニューラルネットワークのアーキテクチャー。<br>
<br>
・NLP: Natural Language Processing<br>
●『Attention is all you need』(2017)<br>
　論文は<a href="https://arxiv.org/abs/1706.03762">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/1706.03762v7">こちら</a><br>
　Transformerアーキテクチャを導入した論文。<br>
<br>
・ViT: Vision Transformer<br>
●『An image is worth 16x16 words: Transformers for image recognition at scale』(2020)<br>
　論文は<a href="https://arxiv.org/abs/2010.11929">こちら</a><br>
　画像をパッチに分割して入力トークンとするパラダイムを確立し、他の後続のVision Transformerが踏襲する基礎となるステップとなった。<br>
<br>
・DETR: Detection with Transformer<br>
●『End-to-end object detection with transformers』(2020)<br>
　論文は<a href="https://arxiv.org/abs/2005.12872">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2005.12872v3">こちら</a><br>
　物体検出を直接的な集合予測問題として再構築する検出トランスフォーマー (DETR) を導入した。<br>
<br>(関連項目)<br>
・<a href="#DiT">DiT: Diffusion Transformers</a>
</li>

<br>

<li id="TTC">
<strong>TTC: Time-to-Collision Estimation (衝突時間推定)</strong><br>
現在の速度と進路がそのまま維持された場合、2つの物体(車両と先行車など)が衝突するまでに残された時間を推定するタスク。<br>
<br>
・<strong>Vision-based TTC estimation (視覚ベースTTC推定)</strong><br>
　画像シーケンス(動画)だけから、オプティカルフローなどの物体の動きの推定を用いてTTCを直接推定する技術。<br>
<br>
　●『心を生み出す脳のシステム』(茂木健一郎)<br>
　　実は、三角関数と微分法を使った簡単な計算により、<strong><span style="color:magenta;">視覚とその変化率だけから、物体の実際の大きさや距離に関係なく、「衝突までの時間」は常に計算できる</span></strong>のである。つまり、網膜に映る情報のみから、このままの速度で飛んでいったら何秒後に衝突するかという情報を、知ることができるのである。別の言い方をすれば、「衝突までの時間」だけが、唯一計算できる量なのである。<br>
<br>
・<strong>RL: Reinforcement Learning (強化学習) とTTC</strong><br>
　自動運転車の運転ポリシー（行動規範）を学習する際に、TTCを報酬関数の一部として組み込むことがある。例えば、「TTCが短くなりすぎると大きな負の報酬（ペナルティ）を与える」ことで、AIが安全な車間距離を保つ運転行動を自律的に学習するように促す。
</li>

<br>

<li id="TwoStreamHypothesis">
<strong>Two-stream Hypothesis (二重視覚システム仮説)</strong><br>
人間の脳内には解剖学的にも機能的にも異なる2つの主要な視覚情報処理経路（ストリーム）が存在するという仮説。<br>
<br>
1. <strong>Ventral Stream (腹側経路)</strong>：What pathway (「何を」の経路 ) <br>
　・後頭葉から側頭葉へと向かう。<br>
　・物体の認識と識別に関与する。形、色、顔などの詳細な特徴を処理し、「それが何であるか」を判断するために重要。<br>
　・vision for perception (知覚のための視覚)とも呼ばれる。<br> 
<br>
2. <strong>Dorsal Stream (背側経路)</strong>：Where/How pathway (「どこ/どのように」の経路)<br>
　・後頭葉から頭頂葉へと向かう。<br>
　・物体の空間的位置や動きの処理、およびそれらに基づく行動の制御に関与する。物体が「どこにあるか」、あるいは「どのように掴むか」といった、運動に関連する情報を扱う。<br>
　・vision for action (行動のための視覚) とも呼ばれる。<br> 
<br>
●『Two-Stream Convolutional Networks for Action Recognition in Videos』(2014)<br>
・Two-streamネットワークアーキテクチャをディープラーニングベースの行動認識に導入した。<br>
・最終層のスコア融合<br>
<br>
●『A computational examination of the two-streams hypothesis』(2020)<br>
・腹側ストリームと背側ストリームを計算論的に検証し、どちらの経路がより長い記憶スパンを必要とするかをモデルで分析した。<br>
<br>
●『A Dual-Stream Neural Network Explains the Functional Segregation of Dorsal and Ventral Visual Pathways in Human Brains』(2023)<br>
・デュアルストリームビジョンモデルを開発した。<br>
<br>
●『G<sup>2</sup>VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning』(2025)<br>
・ビジョン言語モデル (VLM) は、画像キャプション生成から視覚的質問応答まで、多様なマルチモーダルタスクで目覚ましい能力を発揮してきたが, 空間理解と推論において一貫して苦戦している。<br>
・人間の視覚認知における「2つの経路仮説」（「何」を認識する対象認識と「どこ」を認識する空間位置処理を分離する）に触発され、G<sup>2</sup>VLMは、共有された注意メカニズムを通じて連携する幾何学的知覚と意味的知覚のための二重の経路を実装している。<br>
<br>
<center><img src="data/images/G2VLM.svg"></center>
<center><img src="data/images/G2VLM2.svg"></center>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="U">U</h2>
<p>
<div class="styleBullet">
<ul>

<li id="UnavoidableAPriori">
<strong>The unavoidable a priori (避けられないアプリオリ(先験的要素), 不可避な先験的仮定)</strong><br>
異なる研究分野やアプローチ(例えば、システムダイナミクスと構造方程式モデリング) の間で、根底にある前提や基本的な仮定が大きく異なり、その相違が避けられないことを指す。<br>
<br>
・<strong>a priori (アプリオリ)</strong><br>
　経験に先立って、または経験とは独立して存在する知識や前提<br>
・<strong>unavoidable (避けられない、不可避な)</strong><br>
　その分野や研究手法を採用する上で、論理的・構造的に受け入れざるを得ない、前提となる仮定や視点<br>
<br>
特定の研究方法論を採用する際に、議論の出発点として必ず前提としなければならない基本的な(しかし他分野からは異なるかもしれない)仮定, という意味合いで使われる。<br>
<br>
●『Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling』(2025)<br>
　(避けられない先験的なものをつなぐ：比較因果モデルのためのフレームワーク)<br>
・システムダイナミクスと構造方程式モデリングを共通の数学的枠組みの中に統合し、分布からシステムを生成し、手法を開発し、結果を比較することで、データサイエンスおよびAI/MLアプリケーションにおけるシステムダイナミクスの基礎となる認識論を明らかにすることを目指す。
</li>

<br>

<li id="UnifiedTokenizer">
<strong>Unified Tokenizer (統合トークナイザー)</strong><br>
テキスト、画像、音声など、異なる種類のデータを単一の統一された形式（トークン）に変換できる、領域に依存しない（ドメインに特化しない）手法。<br>
<br>
●『UniTok: A Unified Tokenizer for Visual Generation and Understanding』(2025)<br>
　(UniTok: 視覚生成および理解のための統合トークナイザー)<br>
　画像に限定された統一トークナイザーへの重要な最近の試み<br>
<br>
●『AToken: A Unified Tokenizer for Vision』(2025)<br>
　(AToken: 統一された視覚トークナイザー)<br>
　再構成と理解の両タスク、および画像、動画、3Dといったモダリティを統一する初のトークナイザー<br>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>

</li>

<br>

<li id="UniversalWeightSubspaceHypothesis">
<strong>The Universal Weight Subspace Hypothesis (普遍重み部分空間仮説)</strong><br>
異なるタスクで訓練されたニューラルネットワークであっても、それらの重み（パラメータ）が非常に類似した低次元のパラメータ部分空間に集約される、ということを示唆する仮説。<br>
<br>
●『The Universal Weight Subspace Hypothesis』(2025)<br>
　(普遍重み部分空間仮説)<br>
・この研究の中心的な仮説は、<strong><span style="color:magenta;">深層ニューラルネットワークが、その訓練タスク、初期化スキーム、ハイパーパラメーター構成に関係なく、共有された低次元のパラメトリック部分空間に体系的に収束する</span></strong>というもの。<br>
　ニューラルネットワークの見かけ上の高次元パラメーター空間が大部分が幻想であり、意味のある情報ははるかに小さな、アーキテクチャ固有の部分空間内に存在することを示唆している。<br>
<br>(関連項目)<br>
・<a href="#PlatonicRepresentationHypothesis">Platonic Representation Hypothesis</a>（プラトン的表現仮説）
</li>

<br>

<li id="UVFA">
<strong>UVFA: Universal Value Function Approximators</strong><br>
強化学習において、状態 (\(s\)) だけでなく目標 (\(g\)) に対しても汎化する単一の価値関数近似器。従来の価値関数は特定の目標に対する状態の価値 \(V(s)\) を推定していたが、UVFAは目標を入力として追加し、\(V(s,g)\) を推定する。<br>
<br>
・<strong>汎化能力</strong>:　単一のモデルで複数の異なる目標に対応できるため、学習していない新しい目標に対しても価値を推定し、適切な行動を選択できる可能性がある。<br>
・<strong>効率的な学習</strong>:　状態空間と目標空間の両方の構造を利用することで、大規模な問題においても効率的に学習を進めることができる。<br>
・<strong>埋め込み表現の利用</strong>:　観測された価値を状態と目標の別々の埋め込みベクトルに分解し、それらの写像を学習する効率的な手法が開発されている。<br>
<br>
●『Universal Value Function Approximators』(2015)<br>
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="V">V</h2>
<p>
<div class="styleBullet">
<ul>
<li id="VAE">
<strong>VAE: Variational Auto Encoder</strong><br>
深層学習を用いた生成モデルの一種。オートエンコーダの仕組みをベースに、潜在空間に確率的な制約を設けることで、多様な新しいデータを生成できるようにしたモデル。<br>
<br>
●『An Introduction to Variational Autoencoders』(2019)　<a href="https://arxiv.org/pdf/1906.02691">こちら</a>　1章の機械翻訳は<a href="https://boyoyon.github.io/Introductions/data/An_Introduction_to_Variational_Autoencoders_01.html">こちら</a><br>
　(開発者による解説。89ページ)<br>
<br>(関連項目)<br>
・<a href="#GenerativeModel">Generative Model (生成モデル)</a> 概略図比較あり<br>
・<a href="#LatentSpace">Latent Space (潜在空間)</a>　概念図あり
</li>

<br>

<li><strong>Value (価値)</strong><br>
エージェントがある状態または, ある状態である行動をとったとき, 将来にわたって得られる<strong><span style="color:magenta;">累積的な報酬の期待値を数値で表したもの</span></strong>。<br>
価値関数には、主に2つの種類がある。<br>
<strong>状態価値関数（\(V(s)\)）</strong><br>
　ある状態\(s\)から開始して、特定の行動方針（方策）に従った場合に得られる、将来の累積報酬の期待値を表す。<br>
<strong>行動価値関数（\(Q(s,a)\)）</strong><br>
　ある状態\(s\)で特定の行動\(a\)をとった後、特定の行動方針に従った場合に得られる、将来の累積報酬の期待値を表す。Q値とも呼ばれる。<br>
※ Q 値の Q は Quality of Action に由来するらしい･･･<br>

<br>
<a href="data/Papers_Value.html">Papers</a>

</li>

<br>

<li id="VanishingGradient">

<strong>Vanishing gradient problems (勾配消失問題), gradient exploding  problems (勾配爆発問題)</strong><br>
ニューラルネットワーク、特に層が深いネットワークを学習させる際に発生する問題。
誤差逆伝播（バックプロパゲーション）の過程で、勾配（重みを更新するための信号）がネットワークの奥深く（入力層に近い層）まで伝わるにつれて、どんどん小さくなっていく現象と、誤差逆伝播（バックプロパゲーション）によって計算される勾配が極端に大きくなり、モデルのパラメータ（重み）が不安定に更新される現象。<br>
<br>
　●『Learning long-term dependencies with gradient descent is difficult』(1994)<br>
　勾配消失問題と勾配爆発問題という課題を初めて詳細に特定し、分析した基礎的な論文<br>
<br>(関連項目)<br>
・<a href="#SkipConnection">Skip Connection</a> (スキップ接続)</br>
</li>

<br>

<li>

<strong>Variable-Binding (変数束縛)</strong><br>
記号（シンボル）が果たす役割（変数）と、その役割を担う具体的な値や対象を結びつけるプロセスのこと。<br>
<br>
例えば<strong><span style="color:magenta;">「Xは人間である」のような命題論理では, X に具体的な値 (例えばソクラテス)をバインドすることで推論が可能になる</span></strong>。 逆にバインドできなければ抽象的なルールを具体的な事例に適用できない。 このように、<strong><span style="color:magenta;">variable binding は「抽象的な知識を具体的な事例に適用するための橋渡し」のような役割を果たす</span></strong>。<br>
<br>
●『Connectionism and cognitive architecture: A critical analysis』(1988)<br>
　(コネクショニズムと認知アーキテクチャ：批判的分析)<br>
　ニューラルネットワークが記号計算と人間の認知の重要な特徴である「変数束縛」を扱えないことを批判した。<br>
<br>
●『Tensor Product Variable Binding and the Representation of Symbolic
Structures in Connectionist Systems』(1990)<br>
　(テンソル積変数束縛とコネクショニストシステムにおける記号構造の表現)<br>
　論文は<a href="http://www.lscp.net/persons/dupoux/teaching/AT1_2014/papers/Smolensky_1990_TensorProductVariableBinding.AI.pdf">こちら</a><br>
コネクショニズムにおいてシンボリックな構造を表現するためにテンソル積表現を提案した。この手法は、役割と値をベクトルとして結合させ、分散表現を用いて構造を表すことで、コネクショニズムとシンボリズムの統合を目指した。この論文は、コネクショニズムによる高度な認知タスク処理の可能性を示し、ハイブリッド・システム研究の基礎を築いた。<br>

<br>
●『How Do Transformers Learn Variable Binding in Symbolic Programs?』(2025)<br>
　(Transformerはどのようにして記号プログラムにおける変数束縛を学習するのか？)<br>
　Transformerが変数バインディングを、明示的なアーキテクチャサポートなしに学習できることを示しており、ニューラルネットワークがパターン認識に限定されるという概念に異議を唱えている<br>
<br>
<a href="data/Papers_VariableBinding.html">Papers</a>
</li>

<br>

<li id="VCU">
<strong>VCU: Video Content Understanding（ビデオコンテンツ理解）</strong><br>
人工知能（AI）とコンピュータビジョン（CV）の技術を用いて、機械が動画の内容を自動的に分析・解釈する高度な技術分野。<br>
<br>
●『Seeing without Pixels: Perception from Camera Trajectories』(2025)<br>
・映像の内容を、ピクセルを見ることなく、カメラの軌跡、つまり空間を刻む軌跡のみから認識することは可能でしょうか？本論文は、この一見あり得そうにない問いを体系的に検証した初めての論文です。<br>
・カメラの軌跡は一見単純ですが、映像の内容を明らかにする上で非常に有益なシグナルであることがわかりました。言い換えれば、「どのように動くか」は、実際に「何をしているか」または「何を観察しているか」を明らかにすることができるのです。<br>
<center><img src="data/images/CamFormer.png"></center>
<center>右折する / バスケットボールのレイアップ / 歩く</center>
<br>
・核心的な洞察は、ジェームズ・ギブソンの能動的知覚の理論に基づいています。「人は環境を眼で見るのではなく、地面に接している体ーそれに乗っている頭－そこにある眼で見るのである(one sees the environment not with the eyes but with the eyes-in-the-head-on-the-body-resting-on-the-ground)」。<br>
<br>
・<strong>創発的機能</strong>　CamFormerは、繰り返し行動のカウントという予期せぬ創発的機能を示します。時間的特徴の自己類似性分析により、繰り返し行動に対して明確な周期的な対角パターンが明らかになり、DINOv3のようなモデルの視覚特徴では検出できない時間的構造を捉えます。<br>
<center><img src="data/images/CamFormer2.png"></center>
</li>

<br>

<li id="ViolationofExpectation">
<strong>Violation of Expectation (期待の裏切り, 予測の違反, 期待背反, 期待違反), EVT: Expectancy Violations Theory (期待違反理論)</strong><br>
<br>
<strong>発達心理学・認知科学における「期待背反法」</strong><br>
赤ちゃんは、予測可能な出来事よりも、予期せぬ驚くべき出来事（物理法則に反するような現象など）をより長く見つめる傾向がある。この「長く見つめる（注視時間が長くなる）」という反応を指標にすることで、赤ちゃんが生まれつき持っている世界に対する知識や、物理的・社会的な法則の理解度を推測する。<br>
<br>
<strong>コミュニケーション研究における「期待違反理論」</strong><br>
人は社会的な状況で、他者がどのように行動すべきかについての期待（規範やルール）を持っている。その期待が破られた（違反された）とき、驚きや不快感、あるいはポジティブな反応などが引き起こされる。この反応が肯定的か否定的かは、違反した相手に対する好意度や状況によって変化する。<br>
<br>(関連項目)<br>
・<a href="#EpisodicMemory">Episodic Memory</a> (エピソード記憶)
</li>

<br>

<li>

<strong>Visual Planning (視覚計画)</strong><br>
AI分野、なかでもロボティクスやコンピュータビジョンにおけるタスクにおいて、テキストベースではなく、画像ベースで推論や計画を行うアプローチ。<br>
<br>
●『Visual Planning: Let's Think Only with Images 』(2025)<br>
大規模マルチモーダルモデル (MLLM) が、テキストではなく画像シーケンスによって推論や計画を実行する、新しいパラダイムを提案した論文。特に空間的・幾何学的な情報を含むタスクにおいて、視覚的な表象が言語ベースの推論を補完する有効なチャネルであることを示した。強化学習 (RL) を用いて、画像生成による視覚的計画を実現し、テキストベースの推論を大幅に上回る性能を示している。<br>
<br>
<a href="data/Papers_VisualPlanning.html">Papers</a>
</li>

<br>

<li id="V-JEPA-2">
<strong>V-JEPA-2: Video Joint Embedding Predictive Architecture 2</strong><br>
Meta（旧Facebook）が2025年6月に発表した「世界モデル（World Model）」と呼ばれる次世代のAIモデル。<br>
動画から物理世界の仕組みを「抽象的な表現」として学習し、「行動する前に考える（推論・計画する）」ことを可能にする。<br>
<br>
●『V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning』(2025)<br>
<center><img src="data/images/V_JEPA_2.svg"></center><br>
<strong>多段階学習</strong><br>
(左)まず、視覚マスクノイズ除去目標を用いて、インターネット規模の画像および動画データでV-JEPA 2動画エンコーダを事前学習する。動画クリップはトークンのシーケンスにパッチ分割され、トークンのサブセットを削除することでマスクが適用される。次に、エンコーダはマスクされた動画シーケンスを処理し、各入力トークンの埋め込みベクトルを出力する。次に、エンコーダの出力は、マスクされたパッチの位置を指定する学習可能なマスクトークンのセットと連結され、その後、予測器によって処理される。予測器の出力は、L1損失を用いて予測ターゲットに回帰される。予測ターゲットは、重みがエンコーダの重みの指数移動平均として定義されるemaエンコーダによって計算される。 <br>
(右) 事前学習後、ビデオエンコーダをフリーズし、学習済みの表現に基づいて、新しい動作条件付き予測器（V-JEPA 2-AC）を学習する。過去のビデオフレーム、動作、エンドエフェクタの状態に基づいて、将来のビデオフレームの表現を予測する自己回帰特徴予測目標を活用する。この動作条件付き予測器は、ブロック因果的注意パターンを用いて、特定の時間ステップにおける各パッチ特徴が、現在および過去の時間ステップにおけるパッチ特徴、動作、エンドエフェクタの状態に注意を向けることができるようにする。<br>
<br>(関連項目)<br>
・<a href="#JEPA">JEPA: Joint-Embedding Predictive Architecture</a>
</li>

<br>

<li id="VLA">
<strong>VLA: Vision-Language-Action (視覚・言語・動作)</strong><br>
ロボットが視覚情報（カメラ映像など）と自然言語（人の指示など）を同時に理解し、それに基づいて自律的に具体的な動作を実行できるようにする人工知能モデル。<br>
\[
\begin{array}{c c c c c c c}
\text{LLM} & → & \oplus & \text{VLM} & → & \oplus & \text{VLA} \\
           &    & ↑&            &    &↑ &    & \\
           &    &\text{Vision} & &    & \text{Action} &  &
\end{array}
\]

<br>
●『RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control』(2023)<br>
・インターネット上の膨大な画像・テキストデータで事前学習された汎用的なVLM (Vision-Language Model) の知識を、ロボット制御に直接転移させる手法を確立した。<br>
・VLMを単なる「認識」や「推論」のツールとしてではなく、カメラ入力と人間の言語指示から直接「動作トークン（ロボットの動きを表現するデータ）」を出力するエンドツーエンドの行動生成モデルとして機能させた。<br>
・これにより、トレーニングデータには含まれていないような新しい物体や状況、複雑な指示に対しても、ロボットが高い成功率で対応できるようになった。<br>
<center><img src="data/images/VLA.svg"></center>
<center><img src="data/images/OpenVLA.svg"></center>
</li>

<br>

<li id="VLM">
<strong>VLM: Vision-Language Model (視覚・言語モデル)</strong><br>
視覚情報（画像・動画）とテキスト情報に特化したモデル。<br>
画像を分析してキャプションを生成したり、画像に関する質問に答えたりするなど、視覚とテキストを結びつけるタスクに強みがある。<br>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model</a> (マルチモーダル言語モデル)<br>
・<a href="#CoVT">CoVT: Chain-of-Visual-Thought</a> (視覚的思考連鎖)<br>
・<a href="#VLA">VLA: Vision-Language-Action</a> (視覚・言語・動作)<br>
・<a href="#SpatialReasoning">Spatial Reasoning</a> (空間推論) <br>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="W">W</h2>
<p>
<div class="styleBullet">
<ul>
<li id="W2SG">
<strong>W2SG: Weak-to-strong generalization (弱から強への一般化)</strong><br>
能力の低い（"弱い"）モデルの監視やフィードバックを使って、能力の高い（"強い"）モデルを訓練する際に、その強いモデルが弱いモデルの性能を上回る形で汎化する現象。<br>
<br>
●『Weak-to-strong generalization: Eliciting strong capabilities with weak supervision』(2023)<br>
　(弱から強への一般化：弱い教師あり学習で強い能力を引き出す)<br>
　論文は<a href="https://arxiv.org/abs/2312.09390">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2312.09390v1">こちら</a><br>
<br>
　弱い教師あり学習の下で、強力な生徒が弱い教師よりも優れた性能を発揮できる、弱から強への汎化という概念を初めて導入した。<br>
<center><img src="data/images/Weak-to-Strong.svg"></center>
<br>
●『Selective Weak-to-Strong Generalization』(2025)<br>
・将来、超人モデルは人間の能力を超え、人間は超人モデルを弱く教師あり学習することしかできなくなります。<br>
・既存の手法では弱い教師あり学習が常に使用されるため、ロバスト性に問題があり、弱いラベルの一部がモデルに悪影響を与えることが分かっています。<br>
・本稿では、不要な場合に弱い教師あり学習を避けるための選択的W2SGフレームワークを提案します。<br>
<center><img src="data/images/SelectiveW2S.svg"></center>
<br>
<a href="data/Papers_W2SG.html">Papers</a><br>
</li>

<br>

<li id="WithoutHumanKnowledge">
<strong>Without human knowledge (人間知識なし)</strong><br>
人間の専門的な知識や戦略、あるいは人間が事前に整理・ラベリングしたデータに頼ることなく、AIが自律的に学習し、課題を解決するアプローチ。<br>
<br>
[Deep Reinforcement Learning (深層強化学習)]<br>
●『Mastering the game of Go without human knowledge』AlohaGo (2017)<br>
<center><img src="data/images/AlphaSeries.svg"></center>
[Self-Supervised Learning (自己教師あり学習)]<br>
●『A Simple Framework for Contrastive Learning of Visual Representations』 SimCLR (2020)<br>
　論文は<a href="https://arxiv.org/abs/2002.05709">こちら</a><br>
　画像の異なる切り抜きを「類似」と学習させる手法<strong><span style="color:magenta;">(人間の手作業によるラベル付けなし)で、教師あり学習に匹敵する性能</span></strong>を示した。<br>
●『Bootstrap Your Own Latent』 BYOL (2020)<br>
　論文は<a href="https://arxiv.org/abs/2006.07733">こちら</a><br>
　ネットワークの出力を予測するという単純なタスクで、自己教師あり学習を安定化させた<br>
[AI4S: AI for Science]<br>
●『First Peer-Reviewed Research Paper Written Without Humans』<br>
　論文は<a href="https://pub.sakana.ai/ai-scientist-v2/paper/paper.pdf">こちら</a><br>
　AIシステムが、<strong><span style="color:magenta;">人間の手助けなしで査読を通過する研究論文を執筆</span></strong>した。<br>
[EoE: Era of Experience]<br>
●『Wlecome to the Era of Experience』(2025)<br>
　AI自身の「経験」を通して自律的に学習・進化していくという、AI研究における新たな方向性を示す概念を提唱した。<br>

<br>(関連項目)<br>
・<a href="#AI4S">AI4S: AI for Science (科学のためのAI)</a><br>
・<a href="#DRL">DRL: Deep Reinforcement Learning (深層強化学習)</a><br>
・<a href="#EoE">Era of Experience (経験の時代)</a><br>
・<a href="#SSL">SSL: Self-Supervised Learning (自己教師あり学習)</a><br>
</li>


<br>

<li>

<li id="WordEmbeddings">
<strong>Word Embeddings (単語埋め込み) </strong><br>
自然言語処理（NLP）において、単語の意味や文法的な関係を、コンピューターが計算しやすい数値の列（ベクトル）で表現する技術。<br>

<br>
・静的埋め込み: Word2Vec(2013), GloVe(2014)<br>
　大量のテキストデータから単語の出現パターンを学習。<br>
　その意味を数値ベクトル(埋め込み)として表現した。<br>
<br>
・文脈依存埋め込み: ELMo(2018), BERT(2018)<br>
　文脈に応じて動的に単語ベクトルを生成する。<br>
　これにより、<strong><span style="color:magenta;">多義語　（例：「apple」が「リンゴ」か「会社」か）の意味の違いを区別できるようになった。</span></strong><br>
<br>
●『Efficient Estimation of Word Representations in Vector Space』Word2Vec (2013)<br>
　・大規模なコーパスから、単語の密なベクトル表現を効率的に学習するためのアルゴリズム「Word2Vec」を発表。<br>
　・<strong><span style="color:magenta;">「King - Man + Woman = Queen」のような、単語間の意味的な関係性をベクトル空間上で捉えられる</span></strong>ことが広く知られるようになった。
<center><img src="data/images/WordEmbeddings.svg"></center>
<a href="data/Papers_WordEmbeddings.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#DistributionalHypothesis">Distributional Hypothesis</a> (分布仮説)
</li>

<br>

<li id="WorldModel">

<strong>World Model (世界モデル)</strong><br>
AIが外部の観測情報（画像や音声など）から、環境のダイナミクス（物理法則や因果関係）を学習して獲得する、内部的なシミュレーションモデルのこと。認知科学で「内部モデル」と言われているものに近い。<br>
<br>
1943年、29歳のスコットランド人心理学者ケネス・クレイクは「生物が頭の中に外部現実の『小規模モデル』を持っているとすれば、様々な選択肢を試し、どれが最善かを結論付けることができる。そしてあらゆる面で、より完全で、より安全で、より有能な方法で反応することができる」と考えた。<br>
<br>
●『World models 』(2018)
<center><img src="data/images/WorldModel.svg"></center>
<br>
●『A Path Towards Autonomous Machine Intelligence』(2022)<br>
・機械はどうすれば人間や動物と同じくらい効率的に学習できるでしょうか?<br>
・機械はどうすれば推論と計画を学習できるでしょうか?<br>
・機械はどうすれば知覚の表現と行動計画を複数の抽象レベルで学習し、複数の時間軸で推論、予測、計画を行えるでしょうか?<br>
このポジションペーパーは、自律型知的エージェントを構築するためのアーキテクチャとトレーニングパラダイムを提案します。これは、設定可能な予測世界モデル、内発的動機付けによる行動、自己教師学習によってトレーニングされた階層型共同埋め込みアーキテクチャなどの概念を組み合わせたものです。<br>
<br>
●『General agents contain world models』(2025)<br>
　(汎用エージェントは世界モデルを含む)<br>
　論文は<a href="https://arxiv.org/abs/2506.01622">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2506.01622v4">こちら</a><br>
　<strong><span style="color:magenta;">多段階の目標指向タスクに一般化できるエージェントは、暗黙的に環境の予測モデルを含んでいることを正式に実証した。</span></strong><br>
<br>
<center><img src="data/images/WorldModel3.svg"></center>
<br>
<a href="data/Papers_WorldModel.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#DRL">DRL: Deep Reinforcement Learning</a> (深層強化学習)<br>
・<a href="#IRL">IRL: Inverse Reinforcement Learning</a> (逆強化学習)<br>
・<a href="#RL">RL: Reinforcement Learning</a> (強化学習)<br>
・<a href="https://github.com/knightnemo/Awesome-World-Models">[Github] Awesome World Models</a>
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="X">X</h2>
<p>
<div class="styleBullet">
<ul>
<li id="XAI">
<strong>XAI: Explainable AI (説明可能なAI)</strong><br>
機械学習アルゴリズムによって生成された結果や判断の根拠を、人間が理解し、信頼できるようにするためのプロセスや手法の総称。<br>
・機械学習の隆盛以前、AI研究の初期 (1950年代〜1970年代) は記号推論システムやルールベースのアプローチが中心だった。これらのシステムは、人間の専門家が定義・定式化したルールに基づいて動作したため、その決定プロセスは本質的に透明性が高く、説明可能だった。<br>
・アンサンブル法や深層学習の発展により、モデルの性能は飛躍的に向上したが、その内部構造は複雑化し、意思決定プロセスが人間には理解困難な「ブラックボックス」となった。<br>
・この問題に対処するため、2010年代半ば以降、画期的なポストホック (事後説明) 手法が提案された。 <br>
<br>
●『Why Should I Trust You?”: Explaining the Predictions of Any Classifier』(2016)<br>
　　(「なぜあなたを信頼すべきか？」：あらゆる分類器の予測を説明する)<br>
　　<strong>LIME (Local Interpretable Model-agnostic Explanations)</strong> を提案。特定のモデルに依存しない (モデル非依存、model-agnostic) 説明手法の先駆け。AIモデルの特定の予測結果 (決定境界の局所的な領域) を、人間が理解しやすいシンプルなモデル（線形モデルなど）で近似することで説明を生成する。特定の入力がどのように結果に影響したかを直感的に理解できる。<br>
<center><img src="data/images/xai1.png"></center>
<br>
ブラックボックスモデルの複雑な決定関数 \(f\) (LIMEには未知) は青/ピンクの背景で表され、線形モデルでは適切に近似できない。太字の赤い十字は説明対象のインスタンス。LIMEはインスタンスをサンプリングし、\(f\) を使用して予測を取得し、説明対象のインスタンスへの近さ (ここではサイズで表されています) に基づいて重み付けする。破線は学習された説明であり、局所的には忠実だが (グローバルには忠実ではない)。<br>
<br>
<center><img src="data/images/xai2.svg"></center>
Google Inception ニューラルネットワークによる画像分類予測の説明。上位3クラス「Electric Guitar」(p = 0.32), 「Acoustic Guitar」(p = 0.24), 「Labrador」(p = 0.21)の説明画像。<br>
<br>
●『A Unified Approach to Interpreting Model Predictions』(2017)<br>
　　<strong>SHAP (SHapley Additive exPlanations)</strong>を提案。ゲーム理論に基づいた<strong>シャープレイ値(Shapley value)</strong> という概念を応用し、モデルの各特徴量が予測結果にどれだけ貢献したかを計算する。<strong><span style="color:magenta;">LIMEと同様にモデル非依存だが、理論的な裏付けがあり、特徴量間の相互作用も考慮した一貫性のある説明を提供する</span></strong>。<br>
<br>
●『Weight-sparse transformers have interpretable circuits』(2025)<br>
　重みスパースなトランスフォーマーを通じて、解釈可能な人工知能を実現するための系統的なアプローチを導入している。
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>
</p>

<h2 id="Y">Y</h2>
<p>
<div class="styleBullet">
<ul>
<li id="YerkesDodsonLaw">
<strong>Yerkes-Dodson Law (ヤーキーズ・ドッドソンの法則)</strong><br>
課題のパフォーマンスは、ストレスやモチベーションによる「覚醒（緊張・興奮）レベル」が「適度な」状態のときに最も高くなるという、心理学における法則。<br>
<br>
<center><img src="data/images/YerkesDodsonLaw.svg"></center>
<br>
●『The relation of strength of stimulus to rapidity of habit-formation』(1908)<br>
　ハツカネズミ（Japanese dancing mouse）を使った実験に基づいて、覚醒水準（ストレスや刺激の強さ）とパフォーマンスの間には逆U字型の関係（適度な覚醒水準が最も高いパフォーマンスをもたらす）があることが示された。<br>
　<br>
●『Yerkes-Dodson Law in Agents' Training』(2003)<br>
　AIエージェントのトレーニングにおいて、刺激（報酬や罰の強さなど）の強さと学習の成功率との間にヤーキーズ・ドッドソン法則に見られるような非線形な関係（逆U字型）が存在する可能性を論じている。特定の学習アルゴリズムにおいて、刺激が強すぎると学習効率が低下する現象を分析している。<br>
<br>
●『StressPrompt: Does Stress Impact Large Language Models and How Can We Mitigate It?』(2024)<br>
・大規模言語モデル（LLM）が人間の認知的ストレスに類似した「ストレス」条件下でどのように機能するかを調査している。<br>
・具体的には、プロンプトエンジニアリングを用いてモデルにストレスを与えた場合、そのパフォーマンスがヤーキーズ・ドッドソン法則に従って変化する可能性を示唆している。<br>
・主な発見: モデルのパフォーマンスのピークは、タスクの複雑さに応じて異なるストレスレベルで発生し、より強力なモデルは低いストレスレベルでピークパフォーマンスを達成する傾向があることを発見した。
これは、複雑なタスクでは低い覚醒レベル（ストレス）が、単純なタスクでは高い覚醒レベルが有利であるという、元のヤーキーズ・ドッドソン法則の知見と一致する。 

</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>
</p>

<h2 id="Z">Z</h2>
<p>
<div class="styleBullet">
<ul>
<li id="ZeroShot">
<strong>Zero Shot Learning</strong><br>
訓練データに存在しない、未知のクラスやタスクに対しても、追加の学習（ファインチューニング）をすることなく、有用な予測や分類を行うための学習方法。<br>

<br>(関連項目)<br>
・One-Shot Learning: 訓練データ1つ<br>
・Few-Shot learning: 訓練データ少々<br>
</li>
</ul></div>
</li></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>
</p>
    </body>
</html>

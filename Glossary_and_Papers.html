<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>Glossary and Papers</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
<style>
.container {
  display: flex;
  flex-wrap: wrap;
}
.column {
  flex: 0 25%; /* 幅を25%に設定して4列に */
  box-sizing: border-box;
  padding: 10px;
}
</style>

    </head>
    <body>
<h1><center>Glossary and Papers</center></h1>


<h2>新着</h2>

<p>
●<a href="#OneStepGenerator">One-Step Generator</a><br>
『Who Said Neural Networks Aren't Linear?』(2025><br>
　(ニューラルネットワークは線形ではないと誰が言った？)<br>
　論文は<a href="https://arxiv.org/abs/2510.08570">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.08570v1">こちら</a><br>
　最も説得力のある応用の一つは、リニアライザーが数百の拡散サンプリングステップを単一の順伝播パスに統合する方法を示すものです。<br>
　<a href="https://github.com/assafshocher/Linearizer">https://github.com/assafshocher/Linearizer</a> にコードが公開されているが One-Step Generator の学習済モデルは Coming Soon (2025/10/17時点)<br>
<br>
●<a href="#TensorEquation">Tensor Equation (テンソル方程式)</a><br>
『Tensor Logic: The Language of AI』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2510.12269">こちら</a>, 解説は<a href="https://www.alphaxiv.org/overview/2510.12269v2">こちら</a><br>
　・物理学のような分野が微積分から恩恵を受け、デジタル回路がブール論理に依存する一方で、AIはPrologやLISPのような言語における記号推論、PyTorchやTensorFlowのようなフレームワークにおけるニューラルネットワーク、そして専門的なライブラリにおける確率モデルといった、異なるパラダイムに分断されたままである。<br>
・<strong><span style="color:magenta;">ニューラルネットワーク、記号論理、確率的グラフィカルモデルといった、一見すると異なるAIアプローチが、テンソル方程式という単一の数学的構成要素の下で統一できる</span></strong>ことを示す。<br>
<br>
●<a href="#ABM">ABM: Agent-Based Models (エージェントベースモデル)</a><br>
自律的に行動する複数の「エージェント」間の相互作用をコンピューター上でシミュレーションし、システム全体に生じる複雑な現象やパターンを分析する手法。<br>
<br>
『SimCity: Multi-Agent Urban Development Simulation with Rich Interactions』(2025)<br>
　(SimCity: 豊富なインタラクションによるマルチエージェント都市開発シミュレーション)<br>
　論文は<a href="https://arxiv.org/abs/2510.01297">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.01297v1">こちら</a><br>
・異種エージェント(家計/企業/政府/中央銀行)と豊富な相互作用を持つ解釈可能なマクロ経済システムをモデル化するマルチエージェントフレームワーク「SimCity」を開発<br>
・<strong><span style="color:magenta;">価格弾力性、エンゲルの法則、オークンの法則、フィリップス曲線、ベバリッジ曲線など</span></strong>の標準的なマクロ経済現象のチェックリストを作成し、SimCity がシミュレーション実行全体にわたって堅牢性を維持しながら<strong><span style="color:magenta;">これらの経験的パターンを自然に再現する</span></strong>ことを示した。<br>

</p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="0-9">0～9</h2>

<p>
<div class="styleBullet">
<ul>

<li id="3DGS"><strong>3D Gaussian Splatting</strong><br>
複数の画像から3D空間を高精細に再現し、リアルタイムにレンダリングする手法。<br>
新たな視点からの画像を生成するタスク (<strong>NVS</strong>) の一手法として使われる。<br>
<br>
<strong>「Splatting」</strong>･･･3次元のデータ（ボクセル）を2次元の画像平面へと投影してレンダリングするプロセスを「Splatting」（ぶちまける）という比喩で説明している。3D空間にあるボクセルを「雪玉」、画像平面を「壁」に見立て、雪玉を壁に投げつけることで、その情報が壁に飛び散って画像が作られる、というイメージ。<br>
(Lee Alan Westover氏が1991年に提出した博士論文「SPLATTING: A Parallel, Feed-Forward Volume Rendering Algorithm」で使われた)<br>
<br>
<a href="data/Papers_3DGS.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#NVS">NVS: Novel View Sysnthesis</a>
</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="A">A</h2>
<p>
<div class="styleBullet">
<ul>

<li id="ABM">
<strong>ABM: Agent-Based Models (エージェントベースモデル)</strong><br>
自律的に行動する複数の「エージェント」間の相互作用をコンピューター上でシミュレーションし、システム全体に生じる複雑な現象やパターンを分析する手法。<br>
<br>
『SimCity: Multi-Agent Urban Development Simulation with Rich Interactions』(2025)<br>
　(SimCity: 豊富なインタラクションによるマルチエージェント都市開発シミュレーション)<br>
　論文は<a href="https://arxiv.org/abs/2510.01297">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.01297v1">こちら</a><br>
・異種エージェント(家計/企業/政府/中央銀行)と豊富な相互作用を持つ解釈可能なマクロ経済システムをモデル化するマルチエージェントフレームワーク「SimCity」を開発<br>
・<strong><span style="color:magenta;">価格弾力性、エンゲルの法則、オークンの法則、フィリップス曲線、ベバリッジ曲線など</span></strong>の標準的なマクロ経済現象のチェックリストを作成し、SimCity がシミュレーション実行全体にわたって堅牢性を維持しながら<strong><span style="color:magenta;">これらの経験的パターンを自然に再現する</span></strong>ことを示した。<br>
<br>
<center><img src="data/images/SimCity.svg"></center>
『Econagent: Large language model-empowered agents for simulating macroeconomic activities』(2024)<br>
　(Econagent: 大規模言語モデルを活用したマクロ経済活動シミュレーションエージェント)<br>
　論文は<a href="https://arxiv. org/abs/2310.10436">こちら</a><br>
<br>
『Generative agents: Interactive simulacra of human behavior』(2023)<br>
　(生成エージェント：人間行動の対話型模倣体)<br>
　論文は<a href="https://arxiv.org/abs/2304.03442">こちら</a><br>
<br>
『A baseline model. Journal of Economic Behavior & Organization』(2013)<br>
　(エージェントベース・マクロ経済学：基本モデル)<br>
　論文は<a href="https://www.econstor.eu/bitstream/10419/45012/1/654079951.pdf">こちら</a>
</li>

<br>

<li>
<strong>Acquiescence Bias (黙認バイアス)</strong><br>
アンケートやインタビューなどの調査において、質問の内容によらず肯定的な回答（「はい」「同意する」など）をしやすくなる、回答者の心理的な偏りのこと。<br>日本語では 「同意バイアス」や「黙従傾向」とも呼ばれる。 <br>
<br>
<a href="data/Papers_AcquiescenceBias.html">Papers</a><br>
<a href="https://en.wikipedia.org/wiki/Acquiescence_bias">wikipedia「Acquiescence Bias」</a>
</li>

<br>

<li>
<strong>Active Learning (能動学習)</strong><br>
学習アルゴリズムが自身の訓練データに影響を与えたり選択したりする能力、あるいはその必要性を持つ問題。<br>
<br>
<a href="data/Papers_ActiveLearning.html">Papers</a>
</li>
<center><img src="data/images/ActiveLearning.svg"></center>
<br>

<li>
<strong>Adversarial Vulnerabilities (敵対的脆弱性)</strong><br>
機械学習モデルが、意図的に改ざんされた入力データ（敵対的サンプル）によって誤った予測や判断を下してしまう脆弱性
。<br>
(例)<br>
・画像分類 ･･･ 知覚できないノイズを加えて誤分類させる。<br>
　<center><img src="data/images/panda.svg"></center><br>
・生成モデル ･･･ プロンプトで学習データを引き出す。反社会的な出力を生成させる。フリーズさせる。<br>
<br>
<a href="data/Papers_AdversarialVulnerabilities.html">Papers</a>


</li>

<br>

<li id="AhaMoment">
<strong>Aha Moment (アハ体験)</strong><br>
モデルが自律的に高度な推論戦略を獲得する、トレーニング中の「ひらめき」のような現象<br>
2025 年に公開された DeepSeek-R1 モデルのトレーニング過程で報告され、注目を集めた。<br> 
「Wait, wait. Wait. That's an aha moment I can flag here」<br>
(ちょっと待って。ちょっと待って。これは「アハ！」体験だ。)<br>
<br>

<a href="data/Papers_AhaMoment.html">Papers</a><br>
</li>

<br>

<li id="AIAgent">
<strong>AI Agent (AIエージェント)</strong><br>
自律的に行動し、目標を達成するために環境と相互作用するソフトウェアシステムのこと。<br>
AIエージェントの概念の基盤となる理論は、1970年代から1980年代にかけての研究にまでさかのぼることができるが, 最も影響力のある定義を提示したのは, ラッセルとノーヴィグの『エージェントアプローチ人工知能』(1995)。エージェントを「センサーを通して環境を認識し、アクチュエーターを通してその環境に作用する、あらゆるもの」と定義した。

<center><img src="data/images/AIAgent.svg"></center>

<br>(関連項目)<br>
・<a href="#CognitiveAgent">Cognitive Agent</a> (認知エージェント)<br>
　AIエージェントの中でも、特に人間の認知プロセス（思考、学習、推論など）を模倣する高度なもの。
</li>

<br>

<li id="AIAlignment">
<strong>AI Alignment (AIアライメント)</strong><br>
AIを人間の意図する目的や嗜好、倫理原則に合致させること。<br>
<br>
<a href="data/Papers_AIAlignment.html">Papers</a><br>
<br>
<ul><li>
・<a href="data/Papers_AIAlignment.html#RLHF">RLHF</a>: Reinforcement Learning from Human Feedback [手法]<br>

<strong><span style="color:magenta;">人間のフィードバックが手作業で設計された報酬関数よりも優れた報酬形を提供できる可能性を示唆しており,従来の報酬設計が非現実的である実世界の課題に強化学習を適用する新たな可能性を開いた。</span></strong><br>
「Deep reinforcement learning from human preferences」(2017)
</li></ul>
<br>
<center><img src="data/images/RLHF.svg"></center>
<center><img src="data/images/RLHF2.svg"></center>
・<a href="data/Papers_AIAlignment.html#DPO">DPO</a>: Direct Preference Optimization [手法]<br>

<center><img src="data/images/DPO.svg"></center>



<br>(関連項目)<br>
・<a href="#FAI">FAI: Friendly AI</a> [上位概念] ･･･ AGI, ASI 登場の前に AI を Friendly にしておく必要があり, AI Alignment は必要な要素技術の一つ。<br>
・<a href="#Sycophancy">Sycophancy</a> (おべっか, 追従性) [副作用, 課題]<br>
・<a href="#IRL">IRL: Inverse Reinforcement Learning<a/> (逆強化学習) ･･･ 報酬をモデル化し学習する<br>
・<a href="#RewardHacking">Reward Hacking<a/> (報酬ハッキング) ･･･ 報酬モデルが過剰最適化すると報酬ハッキングになる。<br>
・<a href="#SuperalignmentProblem">Superalignment Problem (スーパーアライメント問題)</a> ･･･ ASI の Alignment をどう行うか?
</li>

<br>

<li><strong>AI for ･･･　(･･･のためのAI)</strong><br>
<br>
<ul>
<li id="AI4S"><strong>AI4S: AI for Science (科学のためのAI)</strong><br>
<br>
・飛躍的なスピードアップ<br>
・人間の認知限界やバイアスを超えた仮説生成と知識発見<br>
・自律的な研究サイクル「AIサイエンティスト」<br>
・代理モデル（サロゲートモデル）によるシミュレーションの高度化<br>

<br>(関連項目)<br>
・AutoML (機械学習ワークフローの自動化)<br>
・Democratization of AI (AIの民主化)<br>
・<a href="https://ja.wikipedia.org/wiki/ラボラトリーオートメーション">Laboratory Automation</a><br>
・Robot Scientist<br>
・<a href="#ScientificDiscovery">Scientific Discovery (科学的発見), Scientific Research (科学研究)</a><br>
・<a href="#SR">SR: Symbolic Regression (シンボリック回帰)</a>
<center><img src="data/images/AI4S.svg"></center>
</li><br>

<li><strong>AI for Healthcare (医療)</strong><br>
・診断・治療の高度化 / 創薬 / ヘルスケア管理
</li><br>

<li><strong>AI for Manufacturing (製造)</strong><br>
・予知保全(故障の予兆を検知) / 品質管理 / プロセス最適化
</li><br>

<li><strong>AI for Materials Science (材料科学)</strong><br>
・新素材開発 / マテリアル・データ基盤<br>
・Material Imformatics
</li>

</ul>
</li>

<br>

<li><strong>Anna Karenina Principle (アンナ・カレーニナの法則)</strong><br>
 トルストイの長編小説『アンナ・カレーニナ』<br>
 「幸せな家族はどれも同じように見え、不幸な家族はそれぞれに不幸である」<br>
<br>
「成功には必要条件を全て満たさなければならないが、失敗は1つ欠けるだけで起こる」という原則。文学作品の一節に由来し、生態学や経営学など幅広い分野で引用されてきたが、近年では機械学習の分野においても言及されるようになった。<br>
<center><img src="data/images/AnnaKareninaPrinciple.svg"></center>
<br>
『Applying Anna Karenina Principle in Deep Learning for Image Classification』(2023)<br>
(ストレスと適応：画像分類のためのディープラーニングにおけるアンナ・カレーニナ原理の適用)<br>
<br>
・幸福な家庭 (汎化性の高いモデル)<br>
　汎化性能が高いモデルは、その内部表現（特徴量）が互いに似通っている。<br>
・不幸な家庭 (汎化性の低いモデル)<br>
　汎化性能が低いモデルは、その内部表現に大きなばらつき（多様性）が見られる。<br>
<br>(関連項目)<br>
・<a href="#NeuralCollapse">Neural Collapse</a>　関係あるか不明だが･･･
</li>

<br>

<li>
<strong>Attention Sinks</strong><br>
大規模言語モデル（LLM）において、系列の最初のほうにあるトークンに、意味的な重要性にかかわらず不釣り合いなほど過剰なアテンション（注意）が向けられる現象。<br>
Vision Transformer (ViT) でも同様の現象が確認されており、モダリティを超えたトランスフォーマーアーキテクチャにとって基本的なものである可能性が示唆されている。<br>
<br>
<a href="data/Papers_AttentionSink.html">Papers</a>
</li>

<br>

<li><strong>Auto(matic) ･･･, Autonomous ･･･ (自動･･･, 自律･･･)</strong><br>
たくさんあるので, Auto(matic), Autonomous を削除した項目を参照
</li>
</ul></div></p>


<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="B">B</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Baldwin effect (ボールドウィン効果)</strong><br>
個体が生涯で獲得した学習や行動が、世代を超えた遺伝的選択を通じて、まるで生得的な本能であるかのように固定化されていく進化的な現象。<br>
獲得形質が遺伝するというラマルク説とは異なり、ネオダーウィニズムの枠組みで説明される。<br>
進化的アルゴリズム（遺伝的アルゴリズムなど）と機械学習（ニューラルネットワークなど）を組み合わせたAI研究において、重要な概念として応用されている。<br>
<br>
<a href="data/Papers_BaldwinEffect.html">Papers</a><br>
<br>
<center><img src="data/images/BaldwinEffect.svg"></center>
<br>
『Evolution imposes an inductive bias that alters and accelerates learning dynamics
』(2025)<br>
　(進化は学習のダイナミクスを変化させ加速させる帰納バイアスを課す)<br>
オンライン学習が進化の速度と過程に与える影響は、ボールドウィン効果として知られている。<br>
計算用語で言えば、これは相互最適化ループと考えることができる。<br>
・Baldwinの経路: オンライン学習(世代内の適応)<br>
・Darwinの経路: 世代間の適応<br>
<center><img src="data/images/EvolutionalConditioning.svg"></center>
・脳と人工ニューラルネットワークは、行動を生み出し、学習を導くための環境からのフィードバックを受け取ることで、オンライン学習を行う。<br>
・生物学では、進化的最適化とオンライン学習は共存しており、進化的圧力が遺伝情報に作用して新しい脳が生成され、それがオンライン学習を行う。
</li>

<br>

<li id="BeningOverfitting">
<strong>Bening Overfitting (良性過学習)</strong><br>
深層学習モデルが訓練データに含まれるノイズまで完全に学習（補間）しているにもかかわらず、未知のデータに対して高い汎化性能を発揮する現象。<br>
従来の機械学習の教科書では、過学習（オーバーフィッティング）は汎化性能を低下させる「悪性」なものだとされてきた。<br>
<br>
<a href="data/Papers_BeningOverfitting.html">Papers</a>
<br>
<center><img src="data/images/BeningOverfitting.svg"></center>

<br>
<br>(関連項目)<br>
・<a href="#DoubleDescent">Double Descent</a> (二重降下)<br>
・<a href="#OverParameterized">Over-parameterized</a> (過剰パラメータ化)

</li>

<br>

<li><strong>BIBO: Bias In, Bias Out</strong><br>
　BIBO: Bias In, Bias Out ･･･ AI分野で使われる格言。<br>
　(BIASの掛かったデータを入力すると, BIASの掛かった推論結果が出力される)。<br>
　　↑<br>
　GIGO: Garbage in, garbage out（ゴミを入れれば、ゴミが出る）に由来。<br>
　　↑<br>
　FIFO: First in, first out (最初に入力されたデータが最初に出力される) に由来。<br>
<br>
(その他)<br>
・Garbage in, AI-enhanced garbage out（ゴミを入れれば、AIが強化したゴミが出る）<br>
・Garbage in, toxic data out（ゴミを入れれば、有害なデータが出る）<br>
・RIRO: Rubbish in, rubbish out (がらくたを入れれば、がらくたが出る）<br>
・You are what you eat（あなたはあなたが食べたものでできている）
</li>

<br>

<li><strong>Brevity Bias (簡潔さのバイアス)</strong><br>

短くて一般的なプロンプトに最適化が偏る傾向。<br>
<br>
LLMエージェントに長期的なタスクを与えると、自己の経験を要約してメモリに書き込む、という動作を繰り返す。しかし、この「要約して上書き」というプロセスは非常に危険。<br>
･･･ 例えば、API連携エージェントに対して「API仕様をよく読んで、正しく使いなさい」という指示を与えるようなもの。<br>
これではドメイン固有のノウハウや、特定のツールを使う際の注意点、よくある失敗パターンといった「生きた知見」が失われてしまう。<br>
<a href="https://note.com/makokon/n/na3f278747609">『なぜ私たちのプロンプトは「劣化」してしまうのか？』</a><br>
<br>(関連項目)<br>
・Context Collapse (コンテキストの崩壊)<br>
　「最初は優秀だったエージェントが、使っているうちになぜかポンコツになってしまった」

</li>

</div>
</p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="C">C</h2>
<p>
<div class="styleBullet">
<ul>

<li id="CatastrophicForgetting">

<strong>Catastrophic Forgetting (破局的忘却)</strong><br>
機械学習モデルが新しいタスクを学習する際に、過去に学習したタスクの情報を急激かつ大幅に忘れてしまう現象。<br>
<br>
<a href="data/Papers_CatastrophicForgetting.html">Papers</a><br>
<br>
<center><img src="data/images/RLRazor.svg"></center>

<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習) [対処法を含む研究テーマ]
</li>

<br>

<li id="CognitiveAgent">
<strong>Cognitive Agent (認知エージェント)</strong><br>
人間の認知プロセス（知覚、学習、推論、意思決定など）を模倣するように設計された、AIエージェントのこと。<br>
<br>
<a href="data/Papers_CognitiveAgent.html">Papers</a><br>
<br>

<center><img src="data/images/CognitiveAgent.svg"></center>

<br>(関連項目)<br>
・<a href="#AIAgent">AI Agent</a> (AI エージェント)<br>
　定義されたルールやスクリプトに従って動作する。特定のタスクを効率的に実行できるが、予期せぬ状況への対応は苦手。
</li>

<br>

<li id="CoT">
<strong>CoT: Chain-of-Thought (思考連鎖)</strong><br>
大規模言語モデル（LLM）の性能を向上させるためのプロンプト技術の一種。<br>
複雑な問題を解く際に、最終的な答えだけでなく、その答えに至るまでの論理的な思考プロセスを段階的に示すようモデルに促すことで、推論能力を高める。<br>
<br>
<a href="data/Papers_CoT.html">Papers</a>
<br>
<center><img src="data/images/CoT.svg"></center>
<br>(関連項目)<br>
・<a href="#CurseOf2hopReasoning">Curse of two-hop reasoning</a>（2ホップ推論の呪い）<br>
・<a href="#SelfConsistency">Self-Consistency</a> (自己無撞着性, 自己整合性)<br>
・<a href="#ToT">ToT: Tree of Thoughts</a> (思考ツリー)
</li>

<br>

<li id="CompositionalityGap"><strong>Compositionality Gap (構成性ギャップ)</strong><br>
AIモデルが、個々の独立した事実は知っているにもかかわらず、それらを組み合わせて複雑な問題を解くことが苦手な現象。<br>
<br>
<a href="data/Papers_CompositionalityGap.html">Papers</a><br>

<br>(関連項目)<br>
・<a href="#CurseOf2hopReasoning">Curse of two-hop reasoning</a>（2ホップ推論の呪い）<br>

</li>

<br>

<li id="ContinualLearning">
<strong>Continual Learning (継続学習)</strong><br>
機械学習モデルが、新しいタスクやデータに順次対応しながらも、これまでに獲得した知識を忘れないように学習し続けることを目指す技術。<br>
別名, Lifelong Learning (生涯学習)。<br>
・Continual Learning(継続学習), Lifelong Learning(生涯学習)は、将来の分布シフトの予測までは行わない。<br>
・Prospective Learning(展望学習), Inductive Learning(帰納学習)は将来の分布シフトを(時間パラメータ付き)仮説として出力する<br>
<br>
<center><img src="data/images/OOD.svg"></center>
<br>
<a href="data/Papers_ContinualLearning.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#CatastrophicForgetting">Catastrophic Forgetting</a> (破局的忘却)[課題]<br>
・<a href="#LossOfPlasticity">Loss of Plasticity</a> (可塑性喪失)[課題]<br>
</li>
・<a href="#PrimacyBias">Primacy Bias</a> (プライマシーバイアス, 初頭バイアス)[課題]<br>
・<a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
<br>
<li id="ContrastiveLearning">
<strong>Contrastive Learning (対照学習)</strong><br>
機械学習における自己教師あり学習 (SSL: Self-Supervised Learning) の一種。<br>
データを「似ているペア（正例）」と「似ていないペア（負例）」に分け、モデルがこの違いを認識できるように学習する。最終的に、潜在空間において、正例のベクトル表現は近づけ、負例のベクトル表現は遠ざけることを目指す。<br>
<br>
<a href="data/Papers_ContrastiveLearning.html">Papers</a>
</li>

<br>

<li id="CuriosityDriven">
<strong>Curiosity-driven（好奇心駆動型）</strong><br>
強化学習において、エージェントが未知の状態や予測が困難な環境を積極的に探索するように、内発的な動機づけを与える手法のこと。<br>
<br>
『Curiosity-driven Exploration by Self-supervised Prediction』(2017)<br>
　(自己教師予測による好奇心主導の探究)<br>
　論文は<a href="https://arxiv.org/abs/1705.05363">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/1705.05363v1">こちら</a><br>
<br>(関連項目)<br>
・<a href="#IntrinsicMotivation">Intrinsic Motivation (内発的動機付け)</a><br>
・<a href="#NoisyTVProblem">Noisy TV problem (ノイジーテレビ問題)</a><br>
・<a href="#NoveltySearch">Novelty Search (新規性探索)</a>
</li>

<br>

<li>
<strong>Curriculum learning (カリキュラム学習)</strong><br>

人間や動物は、例がランダムに提示されるのではなく、意味のある順序で整理され、徐々に多くの概念、そして徐々に複雑な概念を示すように提示されると、はるかによく学習する。このような学習戦略を機械学習の文脈で定式化し、「カリキュラム学習」と呼ぶ。<br>
<br>
<center><img src="data/images/CurriculumLearning.svg"></center>
<br>
<a href="data/Papers_CurriculumLearning.html">Papers</a>
</li>

<br>

<li>
<strong>Curse of Dimensionality (次元の呪い)</strong><br>

データや問題の次元数（特徴量の数）が増えるにつれて、必要なデータ数や計算量が指数関数的に増加し、計算効率の低下やモデルの精度低下を招く現象。<br>
・計算コストの爆発：計算量が \(2^{次元},(次元)^2\), ･･･ だと手に負えなくなる。<br>
・疎らなデータ:　高次元ではデータがまばらになる<br>
・距離の均一化:　どのデータもほぼ同じ距離になる<br>
・球面集中現象(concentration on the sphere): ほとんどのデータが球の表面近くに分布するようになる<br>
　：<br>
「次元の呪い」だけでなく「次元の祝福」もある。<br>
『The curses and blessings of dimensionality』(2000)<br>
・高次元空間には特有の構造（例えば、低次元の多様体など）があり, 新たな手法が生まれる可能性がある。<br>
<br>
<a href="data/Papers_Curse_of_Dimensionality.html">Papers</a>

</li>

<br>

<li id="CurseOf2hopReasoning"><strong>Curse of two-hop reasoning（2ホップ推論の呪い）</strong><br>
大規模言語モデル（LLM）が、個別に学習した2つの事実（例: A→B と B→C）を結びつけて推論する（例: A→C）ことができない、または非常に困難であるという現象。<br>
(例)1ホップの質問：「『イマジン』の演奏者は誰?」「ジョン・レノンの配偶者は誰?」には答えられる。<br>
　　2ホップの質問：「『イマジン』の演奏者の配偶者は誰?」）には答えられない。<br>
<br>
『<a href="https://arxiv.org/abs/2411.16353v1">The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C</a> (2024)』<br>

推論のステップを明示的に示す「思考の連鎖（Chain-of-Thought）」プロンプティングがあれば、2ホップ推論を実行できる。しかし、そうした明示的な指示がないと、個々の事実を結合できない。<br>
これは、LLMが学習データから自動的に、あるいは「潜在的に」推論ステップを結びつける能力が欠けていることを示唆している。<br>
Compositionality Gapの一例。<br>
<br>(関連項目)<br>
・<a href="#CompositionalityGap">Compositionality Gap</a> (構成性ギャップ)<br>
・<a href="#CoT">CoT: Chain-of-Thought</a> (思考連鎖)
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="D">D</h2>
<p>
<div class="styleBullet">
<ul>
<li id="DiffusionModel">
<strong>Diffusion Model (拡散モデル)</strong><br>
画像や音声、テキストなどのデータを生成するための深層学習モデルの一種。<br>
拡散モデルと連想記憶との間の関連性が確立され, 拡散モデルにおける暗記から汎化への移行について、統計物理学における相転移として特徴づけられている。<br>
<br>
<a href="data/Papers_DiffusionModel.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#GenerativeModel">Generative Model</a> (生成モデル)<br>
・<a href="#Memorization">Memorization to Generalization</a> (暗記から汎化へ) 
</li>

<br>

<li>
<strong>Dimensional Collapse (次元崩壊)</strong><br>
主に自己教師あり学習（特にコントラスティブ学習）において、モデルが学習した埋め込み（特徴）ベクトルが、利用可能な高次元空間を十分に活用せず、低次元の部分空間に集中してしまう現象。<br>
<br>
<a href="data/Papers_DimensionCollapse.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="ContrastiveLearning">Contrastive Learning (対照学習)</a><br>
・<a href="#SSL">SSL: Self-Supervised Learning (自己教師あり学習)</a>

</li>

<br>

<li id="DistributionalHypothesis">
<strong>Distributional Hypothesis (分布仮説)</strong><br>
・同じ文脈(Context: 前後関係)で使われる単語は、似た意味を持つ」という考え方。<br>
　「I drink beer.」（私はビールを飲む）<br>
　「I drink wine.」（私はワインを飲む）<br>
　「ビール」と「ワイン」が何らかの共通点（ここでは「飲み物」という属性）を持つと推測できる。<br>

・Distributional Structure (1954)<br>
　単語の意味がその文脈（共起する他の単語）の分布によって決定されるという考え方を定式化。<br>
・A synopsis of linguistic theory, 1930-1955 (1957)<br>
　"You shall know a word by the company it keeps."<br>
　(あなたは言葉がいつも一緒にいる仲間によって、その言葉を知るだろう)<br>
　という有名な言葉で、この概念を簡潔かつ詩的に表現し、広く知らしめた。<br>
　英語の古い格言 "A man is known by the company he keeps" をもじったものだと考えられている。<br> 
・Efficient Estimation of Word Representations in Vector Space』（Word2Vec）(2013)<br>
　<strong><span style="color:magenta;">分布仮説を、計算効率の高いニューラルネットワークモデルで実装した。</span></strong><br>

<br>(関連項目)<br>
・<a href="#WordEmbeddings">Word Embeddings</a> (単語埋め込み)
</li>

<br>

<li>
<strong>DiT: Diffusion Transformers</strong><br>
画像生成などに使われる拡散モデル（Diffusion Model）において、従来のU-Netに代わり、Transformerのアーキテクチャを採用したモデル。<br>
・<strong>スケーラビリティの向上</strong><br>
　Transformerは、モデルの規模が大きくなるほど性能が向上する特性がある。<br>
　DiTはモデルのパラメーター数や計算量を増やすことで、より高品質な画像を生成できるようになる。<br>
・<strong>計算効率の改善</strong><br>
　潜在空間で拡散を行う潜在拡散モデル（LDM）において、DiTはU-Netよりも計算効率が優れている。<br>
・<strong>性能向上</strong><br>
　画像全体を俯瞰的に学習できるTransformerの特性により、特に大規模なデータセットで訓練した場合に、従来のU-Netモデルを上回る生成品質を達成する。
</li>

<br>

<li id="DoubleDescent">
<strong>Double Descent (二重降下)</strong><br>

モデルの複雑さを増していき, モデルが過剰パラメータ化された領域ではテスト誤差が再び減少し始めるという現象。<br>

従来の機械学習の常識である「バイアス・バリアンスのトレードオフ」を覆すものとして、深層学習の研究で注目された。 <br>

「補間閾値」（モデルが訓練データを完全に記憶する点）でテスト誤差がピークに達し、それを超えてさらにパラメータを増やし、モデルを大きくする（過剰パラメータ化する）ことでテスト誤差が再び低下していく。<br>

従来の「汎化誤差が増加し始めたら学習を停止する」(Early Stopping: 早期停止) という手法の再考を促すことになった。<br>
<br>
<a href="data/Papers_DoubleDescent.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#BeningOverfitting">Bening Overfitting</a> (良性過学習)<br>
・<a href="#OverParameterized">Over-parameterized</a> (過剰パラメータ化)
</li>
<center><img src="data/images/DoubleDescent.svg"></center>

<br>

<li id="DRL">
<strong>DRL: Deep Reinforcement Learning (深層強化学習)</strong><br>
強化学習と深層学習（ディープラーニング）という2つの機械学習手法を組み合わせたもの<br>
<br>
<a href="data/Papers_DRL.html">Papers</a>
</li>
<br>
<center><img src="data/images/DRL.svg"></center>

<br>

<li>
<strong>Dropout</strong><br>
ニューラルネットワークの学習時に、一部のニューロン（ノード）をランダムに無効化する正則化手法の一つ。<br>
<br>
<ul>
<li><strong>過学習の抑制</strong><br>
ディープニューラルネットワークは多くのパラメータを持つため、訓練データに過剰に適合し、未知のデータに対する汎化性能が低下しがちだった。Dropoutは、学習時にランダムに一部のニューロンとその接続を無効化することで、<strong><span style="color:magenta;">ニューロン間の過度な「共適応」を防ぎ</span></strong>、この問題を効果的に解決した。
</li><br><li>
<strong>アンサンブル学習の近似</strong><br>
Dropoutは、学習ごとに異なるサブネットワークを生成し、<strong><span style="color:magenta;">あたかも多数の異なるネットワークを学習しているかのような効果をもたらす</span></strong>。推論時には、すべてのニューロンを使いつつ、出力に重み付けを行うことで、これらのサブネットワークの予測を平均化するような効果を得られ、計算コストを抑えながらアンサンブル学習と同等の性能を発揮した。
<br>
<a href="data/Papers_Dropout.html">Papers</a>
</li>
</ul>
</li>
<br>

<li>
<strong>Dunning-Kruger Effect (ダニング・クルーガー効果)</strong><br>
能力の低い人が、自分の能力を過大評価してしまう認知バイアスの一種。<br>
<br>
AIモデルもこの効果を起こす。<br>
・コード モデルはダニング・クルーガー効果の影響を受けるか ?(2025)<br>
・大規模言語モデルは自信過剰になり、エラーを増幅させる(2025)<br>
人間もAIの影響を受けてこの効果が変化する。<br>
・AIはあなたを賢くするが、賢者にはしない(2025)<br>
<br>
<a href="data/Papers_Dunning-KrugerEffect.html">Papers</a>
</li>
<br>
<center><img src="data/images/Dunning-Kruger_Effect_Curve.svg"></center>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="E">E</h2>
<p>
<div class="styleBullet">
<ul>
<li id="EarlyExperience">
<strong>Early Experience (早期経験)</strong><br>
<br>
『Agent Learning via Early Experience』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2510.08558">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.08558v1">こちら</a><br>
<br>
　「早期経験」パラダイムを導入する。これにより、言語エージェントは、<strong><span style="color:magenta;">明示的な報酬シグナルを必要とせずに</span></strong>、環境との自身の相互作用から学習することができる。<br>
<br>
・言語エージェントの長期的な目標<br>
　自身の経験を通じて学習し、向上し、最終的には複雑な現実世界のタスクで人間を上回ること。<br>
・強化学習を用いて経験データからエージェントをトレーニングすることは、検証可能な報酬がない環境や非効率的な長期ロールアウトが必要な環境が多く、依然として困難。<br>
・早期経験と呼ぶ中間的なパラダイムでこの制限に対処する。<br>
・<strong><span style="color:magenta;">早期経験とはエージェント自身の行動によって生成されるインタラクションデータであり、結果として得られる将来の状態は報酬信号なしの教師として機能する</span></strong>。<br>
・このパラダイムでは、2つの戦略を研究する。<br>
　(1) Implicit world modeling (暗黙的世界モデリング) <br>
　　収集された状態を使用して環境ダイナミクスにポリシーを根拠付ける。<br>
　(2) Self-reflection (自己反省)<br>
　　エージェントは最適ではない行動から学習し、推論と意思決定を改善する。<br>

<center><img src="data/images/EarlyExperience.svg"></center>
<br>(関連項目)<br>
・<a href="#EraOfExperience">Era of Experience (経験の時代)</a>
</li>

<br>

<li>
<strong>Episodic Memory (エピソード記憶)</strong><br>
個人の過去の経験や出来事を、その時の状況（いつ、どこで、誰が、何を）や感情とともに記憶する能力。一般的な知識を記憶する「意味記憶」とは区別される。<br>
<br>
Prediction errors disrupt hippocampal representations and update episodic memories (2021)<br>
(予測エラーは海馬の表現を混乱させ、エピソード記憶を更新する)<br>
予測誤差に直面すると海馬の記憶表現が中断され、その後の記憶更新に関連することが、fMRIを用いた研究で示唆されている。この現象は前脳基底部の活動と関連し、神経調節物質が海馬の処理を調整している可能性が指摘されている。<br>
<br>
『入力トークンを「ベイジアン・サプライズ」（予測外の情報）に基づいてイベント単位に分割する。<strong><span style="color:magenta;">人間が予期せぬ出来事によって新しいエピソードを記憶するように、LLMも予測誤差が大きい箇所でイベント境界を認識し、記憶を形成する。</span></strong>』Human-like Episodic Memory for Infinite Context LLMs (EM-LLM)(2024)<br>
<br>
<a href="data/Papers_EpisodicMemory.html">Papers</a>
</li>

<br>

<li id="EraOfExperience">
<strong>Era of Experience (経験の時代)</strong><br>
AI（人工知能）が人間から与えられたデータだけでなく、AI自身の「経験」を通して自律的に学習・進化していくという、AI研究における新たな方向性を示す概念。<br>
Google DeepMind の著名な研究者 David Silver と, 強化学習の創始者のひとり Richard S. Sutton が2025年4月に発表した論文『Welcome to the Era of Experience』で提唱された。<br>
<br>
『<strong><span style="color:magenta;">例えば、あるエージェントが5,000年前の人間の思考と専門家の回答を用いて推論するように訓練されていたとしたら、物理的な問題についてアニミズムの観点から推論していたかもしれません。</span></strong>』<br>
→ 人間を教師にしていることがネックになる･･･<br>
<a href="https://boyoyon.github.io/HTMLs_translated_to_Japanese/2025_Welcome%20to%20the%20Era%20of%20Experience/2025_Welcome%20to%20the%20Era%20of%20Experience.html">機械翻訳はこちら</a><br>
<br>(関連項目)<br>
・<a href="#EarlyExperience">Early Experience (早期経験)</a>
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="F">F</h2>
<p>
<div class="styleBullet">
<ul>
<li id="FlatMinima">
<strong>Flat minima hypothesis (平坦な最適解空間仮説)</strong><br>
機械学習モデル、特に深層学習モデルの訓練において、損失関数の「平坦な」最小値に収束したモデルは、未知のデータに対する汎化性能が「鋭い」最小値に収束したモデルよりも優れている、という仮説。<br>
・Dinh et al. (2017) らは、モデルのパラメータを再パラメータ化（重みのスケーリングなど）することで、汎化性能を変えずに最小値の鋭さを人為的に操作できることを示し、この仮説に疑問を投げかけた。<br>
・スケール不変な「平坦さ」の定義が提案されたり、平坦さの定義自体が再考されたりする研究が進められている。<br>
<center><img src="data/images/FlatMinima.png"></center>
<br>
<a href="data/Papers_FlatMinimaHypothesis.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)</br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)
</li>

<br>

<li id="FAI">
<strong>FAI: Fiendly AI (友好的な人工知能)</strong><br>
人間に対して悪影響を与えることなく、良い影響を与えるように設計された、倫理的な AGI(汎用人工知能) を指す仮説的な概念。<br>
<a href="https://intelligence.org/files/CFAI.pdf">Creating Friendly AI 1.0</a> (2001)で概念が提唱された。<br>
<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a> ･･･ Friendly AIを実現するための技術的課題を解決する研究分野
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="G">G</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>GAN:Generative Adversarial Network (敵対的生成ネットワーク)</strong><br>
生成ネットワークと識別ネットワークの2つのニューラルネットワークを競合させながら学習させることで、現実世界に存在するデータと区別がつかないほどの新しいデータを生成するAI技術。<br>
<br>
<a href="data/Papers_GAN.html">Papers</a>
</li>

<br>

<li id="GenerativeModel">
<strong>Generative Model (生成モデル)</strong><br>
学習したデータの特徴やパターンを理解し、その知識に基づいて、訓練データに類似した新しいデータを自律的に生成できるAI（人工知能）モデル。<br>
従来の AI モデル (Discriminative Model: 識別モデル) が、与えられたデータを「識別する（分類する）」ことに特化していたのに対し、生成モデルは「創造する（生成する）」ことに特化している点が大きな違い。<br>
<br>
・Boltzmann Machine (BM) → Restricted Boltzmann Machine (RBM)<br>
・<a href="#VAE">VAE: Variational Auto Encoder</a><br>
・GAN: Generative Adversarial Networks <br>
・Flow-based model<br>
　Normalizing Flow <br>
・<a href="#DiffusionModel">Diffusion Model (拡散モデル)</a><br>
　DDPM: Denoising Diffusion Probabilistic Model<br>
などがある。<br>
<br>
<a href="data/Papers_GenerativeModel.html">Papers</a><br>

<center><img src="data/images/BM.svg"></center>
<center><img src="data/images/GenerativeModel.svg"></center>

</li>

<br>

<li>
<strong>GNN: Graph Neural Networks</strong><br>
グラフ構造のデータ（ノードとエッジで構成されるデータ）を直接扱えるように設計された、特別なタイプのニューラルネットワーク。<br>
<br>
<a href="data/Papers_GNN.html">Papers</a>
</li>

<br>

<li>
<strong>Goal Understanding (目標理解)</strong><br>
AI (人工知能) の分野において、人間や他のエージェントがどのような目標を持って行動しているのかを推測・理解する能力。<br>
表面的な指示をこなすだけでなく、その指示の背後にある意図や目的を読み解くことが, 目標理解の本質。<br>
<br>(関連項目)<br>
・<a href="#IntentExtraction">Intent Extraction</a> (意図抽出)
</li>

<br>

<li id="GoodhartsLaw">
<strong>Goodhart's Law (グッドハートの法則)</strong><br>
「ある指標が目標になると、それはもはや良い指標ではなくなる」という法則
もともとは、イギリスの経済学者チャールズ・グッドハートが提唱した概念で、組織運営、経済政策、データサイエンスなど、さまざまな分野でみられる。<br>
<br>(関連項目)<br>
・<a href="#RewardHacking">Reward Hacking (報酬ハッキング)</a><br>
　類似の現象を強化学習の文脈で説明したもの。
</li>

<br>

<li id="Grokking"><strong>Grokking</strong><br>
機械学習モデルの学習過程で発生する、「遅れて現れる汎化」を指す現象。<br>
モデルが学習データを完全に記憶（過学習）した状態になった後、長い時間が経ってから突然、未知のデータに対する高い汎化性能を獲得する。<br>
<br>
この用語は、SF作家ロバート・ハインラインの小説『異星の客』に出てくる「完全に、深く理解する」という意味の造語「grok」に由来する。<br>
<br>
<center><img src="data/images/Grokking.svg"></center>
<br>
<a href="data/Papers_Grokking.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#Memorization">Memorization to Generalization</a> (暗記から汎化へ)<br>
・<a href="#PrimacyBias">Primacy Bias</a> ･･･ Grokking できれば Primacy Bias を克服できる
</li>

</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="H">H</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Hallucination (幻覚)</strong><br>
生成AIが、事実に基づかない情報や誤った内容を、もっともらしく、あたかも真実であるかのように出力する現象。<br>
<br>
<a href="data/Papers_Hallucination.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#RAG">RAG: Retrieval-Augmented Generation</a> (検索拡張生成)<br>
・<a href="#RLHF">RLHF: Reinforcement Learning from Human Feedback</a> (人間のフィードバックによる学習)
</li>

<br>

<li>
<strong>Hubness (ハブ性)</strong><br>

機械学習、特に高次元データ空間で発生する現象。<br>
データセット内のごく一部のデータポイント（「ハブ」と呼ばれる）が、他の多くのデータポイントの k-Nearest Neighbors (k-近傍)に異常なほど頻繁に出現するようになる現象を指す。 一方、ほとんどどのデータポイントの k-近傍に現れない「アンチハブ」と呼ばれるデータポイントも同時に発生する。<br>
ハブネスは、「Curse of Dimensionality (次元の呪い)」の一側面とされている。高次元空間では、データポイント間の距離のコントラストが低下し、ほとんどのデータポイント間の距離がほぼ等しくなってしまう。その結果、データ空間の特定の場所に位置するごく一部のデータポイントが、多くのデータポイントから「近い」と認識されやすくなる。<br>
ハブネスは、kNN (k-近傍法) などの距離ベースのアルゴリズムに悪影響を及ぼす。<br>
<br>
<a href="data/Papers_Hubness.html">Papers</a>
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="I">I</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Implicit Bias (暗黙のバイアス)</strong><br>
無意識のうちに抱いている偏見、思い込み、先入観のこと。日本語では「潜在的バイアス」や「アンコンシャス・バイアス」とも呼ばれる。<br>
<br>
『Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings』(2016)<br>
　(男性とコンピュータープログラマーの関係は、女性と主婦の関係と同じ？単語埋め込みのバイアス除去する)<br>
言語モデルにおけるバイアスへの懸念を高めた主要な研究の一つ。 単語埋め込みにおける強い性別ステレオタイプを実証した。<br>
<br>
<a href="data/Papers_ImplicitBias.html">Papers</a>
</li>

<br>

<li><strong>Inductive Bias (帰納バイアス)</strong><br>
学習時に遭遇したことのない入力に対する出力の予測を可能にするために用いる一連の仮定から生じるバイアスのこと。<br>
『学習とは、過去の経験から一般化を行い、その経験に「関連する」新しい状況に対処する能力を伴う。新しい状況に対処するために必要な帰納的飛躍は、状況のある一般化を他の一般化よりも選択するための特定のバイアスがある場合にのみ可能となるように思われる･･･』<br>
～The need for biases in learning generalizations(1980)～<br>
<br>
事前分布はベイズ推論における帰納バイアスの一種と見なすことができる。
ここで「帰納的」という言葉は、帰納法の厳密な数学的意味を持つのではなく、以前の知識に基づいて何らかの推論を行うという事実を意味する。<br>
<br>
<a href="data/Papers_InductiveBias.html">Papers</a>
</li>

<br>

<li><strong>Inductive Leap (帰納的飛躍)</strong><br>
いくつかの具体的な観察や事例から、それらを超えた普遍的な結論や一般法則を導き出す思考の飛躍のこと。<br>
<br>
・論理的に必ず正しいと保証されるものではない。<br>
　不適切な帰納的飛躍が、結果として偏見を生み出すことがある。<br>
　<strong>確証バイアス</strong>（自分の既存の信念を補強する情報を優先する傾向）などの認知バイアスよって行われることがよくある。<br>
　例外が見つかれば、結論は崩れる可能性がある。<br>
<br>
・<strong>演繹法</strong>がすでに知っていることから結論を導き出すのに対し、帰納的飛躍は新たな知識や仮説を生み出す。この点で、科学的探求や日常生活における問題解決において重要な役割を果たす。<br>
<br>
・<strong>帰納的飛躍</strong>は、多くの個別事例から一般法則を導き出すプロセス。<br>
　<strong>アブダクション</strong>は, 驚くべき観察結果や事実に直面した際に、それを最もよく説明できる仮説を形成すること。

</li>
<br>


<li id="InductiveLearning"><strong>Inductive Learning (帰納学習)</strong><br>
『Learning Model Successors』(2025) における Inductive Learning (帰納的学習) は、ある抽象度のレベルで得られたモデルから、さらに高レベルのモデル（「モデルの後継者」）を学習する、という新しいパラダイムを指す。<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)･･･概略図比較あり,　 <a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習=継続学習の別名)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
</li>
<br>

<li id="IntentExtraction">
<strong>Intent Extraction (意図抽出)</strong><br>
ユーザーが発した言葉や文章の背後にある「意図」や「目的」を特定する技術。<br>
<br>
<a href="data/Papers_IntentExtraction.html">Papers</a>
</li>

<br>

<li id="IntrinsicMotivation">
<strong>Intrinsic Motivation (内発的動機付け)</strong><br>
報酬や評価といった外部の刺激に関係なく、個人の内面から自然と湧き上がる興味・関心、意欲によって行動すること。<br>
<br>
<a href="data/Papers_IntrinsicMotivation.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven（好奇心駆動型）</a><br>
・<a href="#NoveltySearch">Novelty Search (新規性探索)</a><br>
</li>

<br>

<li id="IRL">
<strong>IRL: Inverse Reinforcement Learning (逆強化学習)</strong><br>
熟練者や人間の行動データ（デモンストレーション）から、その行動の背後にある「報酬関数」を推定する機械学習の手法。<br>
<br>
<a href="data/Papers_IRL.html">Papers</a>
</li>
</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="J">J</h2>
<p>
<div class="styleBullet">
<ul>
<li><strong>Jensen's inequality (イェンセンの不等式)</strong><br>
<br>
凸関数 \(f\) と確率変数 \(X\) について、\(E[f(X)]\ge f(E[X])\) という関係が成り立つことを示している。<br>
直感的には, 凸関数に平均値を代入した値は、関数に代入してから平均をとった値よりも小さくなる、というもの。<br>
<br>
・変分ベイズやEMアルゴリズムでは、イェンセンの不等式を使って尤度の下限 (ELBO: Evidence Lower Bound) を導出する。<br>
<br>
・2つの確率分布間の違いを測る指標である KL (カルバック・ライブラー)ダイバージェンスが非負 (0以上) であることの証明に使われる。
</li>

<br>

<li><strong>Japanese Missing Cat Method</strong><br>
<br>
AIとは(今のところ)関係ない。Jの項目が少ないのでスペースホルダーとして･･･<br>
行方不明になった猫を捜す際に、近所にいる野良猫や「ボス猫」に、探している猫の特徴を伝えて協力を求めるという、日本に古くから伝わるという都市伝説的な手法。2025年ごろに海外のSNS、特にTikTokで話題になり、一気に広まった。<br>
<br>
<ul>
<li><strong>1. 近所の猫を探す</strong><br>
家の近所にいる野良猫、特に縄張りを仕切っていると見られるボス猫を探す。
</li><li>
<strong>2. 猫の目線になる</strong><br>
探してもらう猫の近くでしゃがみこみ、同じ目線になる。
</li><li>
<strong>3. 情報を伝える</strong><br>
行方不明になった猫の名前や特徴を具体的に、ささやくように伝える。
</li><li>
<strong>4. 感謝と熱意を伝える</strong><br>
猫がいかに大切な存在かを訴え、見つけてくれたらお礼をすることを伝える。
</li><li>
<strong>5. お礼の品を渡す</strong><br>
報酬として、その場でキャットフードなどを与える。
</li></ul>
</li>

</ul></div>
</p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="K">K</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Kan Extension (Kan拡張)</strong><br>
圏論における「最も普遍的な方法」で関手を拡張するための構成。ある関数をより広い定義域に拡張する操作を、圏論の文脈で一般化したもの。<br>
1960年に極限を用いてこの拡張を構成した ダニエル・カン (Daniel Marinus Kan) の名に由来している。<br>
<br>
『Learning Is a Kan Extension』(2025)<br>
すべてのエラー最小化アルゴリズムが Kan 拡張として表現できることを証明する。
</li>

<br>

<li>
<strong>Knowledge Distillation (知識蒸留)</strong><br>
機械学習の技術の一つで、大規模で高性能なAIモデル（教師モデル）が持つ知識を、より小型で軽量なAIモデル（生徒モデル）に移転・圧縮する手法。<br>
<br>
<a href="data/Papers_KD.html">Papers</a>
</li>
<br>
<center><img src="data/images/KnowledgeDistillation.svg"></center>
</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="L">L</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Latent learning (潜在学習)</strong><br>
学習した内容が行動にすぐには現れず、適切な動機づけやきっかけが与えられたときに初めて表面化する学習の形態。<br>
エドワード・トルーマンは、報酬のない状態で迷路を探検させたラットが、後で報酬が与えられるようになると、すぐに迷路を効率的に通り抜けられるようになることを示した。これは、報酬がなくても環境の認知地図（cognitive map）が形成されていたことを示している。<br>
機械学習では、この概念はデータの「latent space (潜在空間)」と結びつけられることがある。<br>
<br>
<a href="data/Papers_LatentLearning.html">Papers</a>
</li>

<br>

<li id="LatentSpace">
<strong>Latent Space (潜在空間) </strong><br>
モデルが学習した、データの隠された本質的な特徴を捉えた、低次元で抽象的なベクトル空間のこと。<br>
<center><img src="data/images/LatentSpace.svg"></center>
<br>
<a href="data/Papers_LatensSpace_LatentZone.html">Papers</a><br>
<br>
『Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification』(2025)<br>
　(潜在ゾーニングネットワーク：生成モデリング、表現学習、および分類の統一的原理)<br>
統一された原理で, 生成モデリング、表現学習、分類の 3つのタスクすべてに対処できるかを問う。このような統一により、ML パイプラインが簡素化され、タスク間の相乗効果を高めることができる。 この目標に向けた一歩として、潜在ゾーニング ネットワーク (LZN) を紹介する。<br>
<center><img src="data/images/LatentZone.svg"></center>
<br>(関連項目)<br>
・<a href="#VAE">VAE: Variational Auto Encoder</a>
</li>


<br>

<li id="LifelongLearning">
<strong>Lifelong Learning(生涯学習)</strong><br>
Continual Learning (継続学習) の別名。<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
</li>

<br>

<li>
<strong>LoRA: Low-rank adaptation of LLM (低ランク適応)</strong><br>
大規模言語モデル（LLM）を、効率的かつ少ない計算コストで特定のタスクやデータに適応（ファインチューニング）させるための技術。<br>
<br>
『LoRA: Low-Rank Adaptation of Large Language Models』 (2021)<br>
大規模言語モデル（LLM）の事前学習済み重みを凍結し、その横に低ランク行列 (\(A\)と\(B\)) のペアを追加。ファインチューニング時には、この小さな低ランク行列だけを学習させ、元のモデルの重みは変更しない。<br>
<strong><span style="color:magenta;">ファインチューニングに必要な学習可能なパラメータが劇的に少なくなる</span></strong>ため、効率的な学習を可能にした。<br>

</li>
<center><img src="data/images/LoRA.svg"></center>
<br>

<li id="LossLandscape">

<strong>Loss Landscape (損失景観)</strong><br>
ニューラルネットワークのパラメータ（重み）を軸とし、対応する損失関数の値を高さとした多次元の景観。モデルの学習は、この景観の低い場所（最適解）を探すことに相当する。<br>
<br>
<a href="data/Papers_LossLandscape.html">Papers</a><br>
<br>
『Visualizing the Loss Landscape of Neural Nets』(2018)<br>
<br>
<ul>
<li><strong>可視化手法の提案</strong><br>
<strong><span style="color:magenta;">高次元の損失関数を、2次元平面上にプロットする革新的な可視化手法を提案した</span></strong>。これにより、学習パラメータ空間の「地形」を視覚的に捉えることが可能になった。
</li><br>
<li><strong>平坦な最小値と汎化性能の関係</strong><br>
可視化の結果、最適解（最小値）の形状が、モデルの汎化性能に大きく影響することを発見した。この論文は、<strong><span style="color:magenta;">「平坦な最小値（flat minima）」にたどり着いたモデルは、より優れた汎化性能を持つことを視覚的に示した</span></strong>。
</li><br>
<li><strong>スキップコネクションの効果</strong><br>
ResNetなどのネットワークで使われる<strong><span style="color:magenta;">「スキップコネクション」が、損失ランドスケープをよりスムーズにする効果があることも明らかにした</span></strong>。
</li></ul>
<br>
<center><img src="data/images/LossLandscape.svg"></center>

<br>(関連項目)<br>
・<a href="#ModeConnectivity">Mode Connectivity</a> (モード連結性)<br>
・<a href="#SkipConnection">Skip Connection</a> (スキップ接続)
</li>

<br>

<li id="LossOfPlasticity">

<strong>Loss of Plasticity (可塑性喪失) </strong><br>
あるシステムが、新しい情報に適応したり、学習したりする能力を徐々に失っていく現象。<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>

</li>

<br>

<li>
<strong>Lost in the Middle (「真ん中が失われる」現象)</strong><br>
モデルが長いコンテキスト（入力テキスト）を与えられた際、そのコンテキストの中間に存在する重要な情報を無視したり、見つけられなくなったりする現象。
</li>

<br>

<li id="LTH">
<strong>LTH: Lottery Ticket Hyposis (宝くじ仮説)</strong><br>
大規模なニューラルネットワークの中に、元のネットワークと同じかそれ以上の性能を発揮する、より小さな「サブネットワーク」が存在するという仮説。<br>
<center><img src="data/images/LTH.svg"></center>
<br>(関連項目)<br>
・<a href="#Pruning">Pruning</a> (枝刈り)<br>
</li>
</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="M">M</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Mamba</strong><br>
トランスフォーマーモデルに代わる、効率的な次世代ネットワークアーキテクチャとして2023年に発表された、新しい機械学習モデル。<br>
トランスフォーマーが抱える「長いシーケンス（入力テキスト）を扱う際の計算コストの増大」という課題を解決するために開発された。
</li>

<br>

<li>
<strong>Measurement Semantics (計測意味論)</strong><br>
言葉や文章の「意味」を、ある尺度や指標で定量的に測定・評価するための考え方や手法
</li>

<br>

<li id="Memorization">
<strong>Memorization to Generalization (暗記から汎化へ)</strong><br>
機械学習モデル、特にニューラルネットワークが、訓練データを単に丸暗記する段階（Memorization）から、学習したパターンを組み合わせて未知のデータにも応用できる段階（Generalization）へと移行するプロセス。<br>
<br>
Memorization to Generalization: Emergence of Diffusion Models from Associative Memory (2025)<br>
・訓練中に「偽の状態(スプリアスフェーズ)」が出現することが、モデルの記憶から汎化への移行を示すことを実証。<br>
・スプリアス状態は通常、記憶容量を超えたときに現れる望ましくないアーティファクトと見なされていたが、<strong><span style="color:magenta;">出現するパターンは、モデルの創造的合成、つまり基本的な記憶を組み合わせて新しい組み合わせを生み出すことを表していると提案している。</span></strong><br>
<br>
<center><img src="data/images/Memorization_to_Generalization.svg">
</center>
<center>スプリアスフェーズを経由して記憶(暗記)から汎化に移行する</center>

<br>
(関連項目)<br>
・<a href="#Grokking">Grokking</a><br>
・<a href="#DiffusionModel">Diffusion Model</a> (拡散モデル)の相転移
</li>

<br>

<li id="MentalRotation">
<strong>Mental Rotation (心的回転)</strong><br>
心の中で二次元または三次元の物体を回転させる認知機能のこと。<br>
<br>
『Mental Rotation of Three-Dimensional Objects』(1971)<br>
　3次元回転した画像ペアが同じか否か判定するテストの平均応答時間は3次元回転角度に比例する。<br>
<br>
<center><img src="data/images/MentalRotation.svg"></center>
<br>
『Large Vision Models can solve mental rotation problems』(2025)<br>
　(大規模視覚モデルは心的回転の問題を解決できる)<br>
<br>
『Spatial Mental Modeling from Limited Views』(2025)<br>
　(限定された視点からの空間メンタルモデリング)<br>
</li>

<br>

<li><strong>Meta Learning (メタ学習)</strong><br>
「学習の仕方を学習する」ための機械学習技術。
</li>

<br>

<li id="MMLM">
<strong>MMLM: Multimodal Language Model (マルチモーダル言語モデル)</strong><br>
テキスト情報だけでなく、画像、音声、動画、3Dデータなど、複数の種類の情報（マルチモーダル）を扱えるモデルの総称。<br>
モード間の関連付けの手法<br>
<br>
<ul>
<li><a href="#SharedEmbeddingSpace">Shared Embedding Space (共有埋め込み空間)</a><br>
異なるモードのデータを同じベクトル空間にマッピングすることで、モード間の比較と関連付けを可能にする。OpenAI の CLIP (Contrastive Language–Image Pre-training) モデルが代表例。<br>
</li>
<br>
<li><a href="#MMFusion">・Multi-modal Fusion (マルチモーダル融合)</a><br>
モデルの途中の層で複数のモードの情報を直接統合する。<br>
各モードの情報を個別のエンコーダーで処理した後、Transformerモデルのクロスアテンション層などを利用して、モード間の特徴を相互に参照させる。<br>
Google DeepMind の Flamingo モデルなどがこのアプローチを利用している。
</li>
<br>
<li><a href="#TokenLevelIntegration">Token-level Integration (トークンレベル統合)</a><br>
画像を言語モデルが理解できる「トークン」として扱い、テキストトークンと並べて処理する。<br>
VisualBERT や SimVLM といったモデルがこの手法を採用している。
</li>
</ul>

<br>(関連項目)<br>
・<a href="#VLM">VLM: Vision-Language Model (視覚・言語モデル)</a> ･･･ MMLMは、VLMを内包する、より広範な概念<br>
・<a href="#UnifiedTokenizer">Unified Tokenizer (統合トークナイザー)</a>
</li>
<br>

<li>
<strong>Modality Gap </strong><br>
画像とテキストのように異なる種類のデータ（モダリティ）を扱うマルチモーダルモデルにおいて、それぞれのモダリティの表現が、モデルの共通の埋め込み空間上で離れてしまう現象。
</li>

<br>

<li id="ModeConnectivity">

<strong>Mode Connectivity (モード連結性)</strong><br>
ニューラルネットワークのパラメータ空間において、学習によって得られた複数の局所的最適解（ミニマム）が、低い損失関数の値を保ったまま経路で接続されている現象。<br>
<br>
<center><img src="data/images/ModeConnectivity.png"></center>
<br>(関連項目)<br>
・<a href="#LossLandscape">Loss Landscape</a> (損失景観)<br>
・<a href="#FlatMinima">Flat minima hypothesis</a> (平坦な最適解空間仮説)<br>
</li>

<br>

<li>

<strong>Model soups (モデルスープ)</strong><br>
異なるハイパーパラメータ（学習率、エポック数など）でファインチューニングされた複数のモデルの重みパラメータを平均化し、単一の高性能モデルを作成する手法。<br>
<br>
『Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs (2018)』<br>
<br>
<ul><li>
・<strong><span style="color:magenta;">異なる初期値から学習をスタートさせた複数のモデルがたどり着く局所最小値（「モード」）が、低損失の経路で繋がっている現象を発見した</span></strong>。
</li><br><li>
・この発見に基づき、<strong><span style="color:magenta;">学習済みの複数のモデルパラメータを線形補間するだけで、低損失を維持しながら、より優れた汎化性能を持つアンサンブルモデルを作成できることを示した</span></strong>。これは、モデルアンサンブルを効率的に行う新しい方法を提示した。
</li></ul>
<br>
『Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time』(2022)<br>
　(モデルスープ：複数のファインチューニング済みモデルの重み平均による、推論時間増加なしの精度向上)
</li>

<br>

<li>


<strong>MoE: Mixture-of-Experts (専門家混合)</strong><br>
複数の小さな専門家モデル（エキスパート）と、どの専門家を使うかを選択するルーティングシステム（ルーター/ゲーティングネットワーク）を組み合わせたAIアーキテクチャ。<br>
<br>
『Outrageously large neural networks: The sparsely-gated mixture-of-experts layer』(2017)<br>
　(途方もなく巨大なニューラルネットワーク：まばらにゲートされたエキスパート混合層)<br>
<br>
『Mixture of Neuron Experts』(2025)<br>
　(ニューロンエキスパートの混合)
</li>
<center><img src="data/images/MoE.svg"></center>

<br>

<li id="MMFusion">
<strong>Multi-modal Fusion (マルチモーダル融合)</strong><br>
複数の異なる種類のデータ（モダリティ）を組み合わせて統合し、より包括的な理解や高い精度を達成するための技術。<br>
<br>
『Everything at Once – Multi-Modal Fusion Transformer for Video Retrieval』(2022)<br>
『Flamingo: a Visual Language Model for Few-Shot Learning』(2022)<br>
　論文は<a href="https://arxiv.org/abs/2204.14198">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2204.14198v2">こちら</a>
<center><img src="data/images/Flamingo.svg"></center>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="N">N</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>NAS: Neural Architecture Search</strong><br>
特定のタスクにおいて、最も性能が良いニューラルネットワークの構造（アーキテクチャ）を自動的に見つけ出す技術。
</li>

<br>

<li id="NeuralCollapse">
<strong>Neural Collapse </strong><br>
十分に訓練されたニューラルネットワークの最終層の表現が高度に構造化された形状に収束する現象。<br>

<br>
各クラスの特徴ベクトルがクラスごとの平均ベクトルに収束し、それらのクラス平均が「等角な単純体」（Simplex Equiangular Tight Frame: ETF）と呼ばれる非常に均整の取れた構造を形成する。<br>
</li>

<br>

<li>

<strong>Neural ODE</strong><br>
ニューラルネットワークの層の連なりを、連続的な常微分方程式として表現する革新的なモデル。<br>
従来のニューラルネットワークが、層ごとに離散的な変換を適用するのに対し、Neural ODEは隠れ状態の連続的な時間発展を学習する。<br>
</li>

<br>

<li>
<strong>NFL: No Free Lunch Theorem (ノーフリーランチ定理)</strong><br>
あらゆる問題に普遍的に通用する万能なアルゴリズムは存在しない,という定理。
</li>

<br>
<li id="NoisyTVProblem">
<strong>Noisy TV problem (ノイジーテレビ問題)</strong><br>
強化学習における好奇心ベースの探索手法が抱える問題の一つ。<br>
テレビの砂嵐(画面にランダムな画像やノイズが表示され続けるテレビ)のような予測不能でランダムな変化を起こす要素にエージェントが固執し、本来の目的を達成するための有益な探索が進まなくなる現象を指す。<br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven（好奇心駆動型）</a>
</li>

<br>

<li id="NoveltySearch">
<strong>Novelty Search (新規性探索)</strong><br>
進化計算や強化学習などの分野で用いられる探索アルゴリズムの一種。あらかじめ定義された目標や適応度関数を直接的に最適化するのではなく、過去に生成された解とは異なる「新奇性」を持つ行動や解を探索・評価することに焦点を当てる。<br>
<br>(関連項目)<br>
・<a href="#CuriosityDriven">Curiosity-driven（好奇心駆動型）</a><br>
・<a href="#IntrinsicMotivation">Intrinsic Motivation (内発的動機付け)</a>
</li>

<br>

<li>
<strong>NTK: Neural Tanget Kernel</strong><br>
幅が無限大のニューラルネットワークを、ある特殊な「カーネル法」で訓練されたモデルとして捉え、その学習過程と挙動を理論的に解析するための概念。
</li>

<br>

<li>

<strong>NTM: Neural Turing Machines</strong><br>
ニューラルネットワークのパターンマッチング能力と、チューリングマシンのようなコンピューターのアルゴリズム処理能力を組み合わせた、リカレントニューラルネットワークの一種。<br>
DeepMind社によって2014年に発表された。<br>
その後、この研究を発展させた微分可能ニューラル・コンピューター（DNC）が登場し、より洗練されたアテンション機構によってパフォーマンスが向上した。<br>
しかし、2020年代に入ると、NTM や DNC の役割は、Transformer のような大規模言語モデル（LLM）の発展によって部分的に代替されている。

</li>

<br>

<li id="NVS">
<strong>NVS: Novel view synthesis (新規視点合成)</strong><br>
撮影された複数の画像データから、撮影されていない新しい視点からの画像を合成する技術。<br>
<br>
(関連項目)<br>
・<a href="#3DGS">3D Gaussian Splating</a><br>
・<a href="#NeRF">NeRF</a><br>
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="O">O</h2>
<p>
<div class="styleBullet">
<ul>

<li id="OneStepGenerator">
<strong>One-Step Generator</strong><br>
拡散モデルのような多段階の生成プロセスを、わずか1回のステップで完了させることのできる生成モデル。<br>
<br>
『Who Said Neural Networks Aren't Linear?』(2025><br>
　(ニューラルネットワークは線形ではないと誰が言った？)<br>
　論文は<a href="https://arxiv.org/abs/2510.08570">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2510.08570v1">こちら</a><br>
　最も説得力のある応用の一つは、リニアライザーが数百の拡散サンプリングステップを単一の順伝播パスに統合する方法を示すものです。<br>
　<a href="https://github.com/assafshocher/Linearizer">https://github.com/assafshocher/Linearizer</a> にコードが公開されているが One-Step Generator の学習済モデルは Coming Soon (2025/10/17時点)<br>
</li>

<br>

<li id="OOD">
<strong>OOD: Out-of-Distribution Generalization (分布外汎化)</strong><br>
機械学習モデルが、訓練データとは統計的な性質（分布）が異なる未知のデータに対しても、高い性能を発揮する能力を指す。<br>
<br>
<a href="data/Papers_OODLearning.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)･･･概略図比較あり,　 <a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習=継続学習の別名)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#ProspectiveLearning">Prospective Learning</a> (展望学習)<br>
</li>
<br>
<li>
<strong>Open-Ended Generation </strong><br>
明確な答えや単一の目標を設定することなく、AIが創造的かつ多様なコンテンツを生成する能力のこと。
</li>

<br>

<li id="OverParameterized">
<strong>Over-parameterized (過剰パラメータ化)</strong><br>
機械学習モデルのパラメータ（学習可能な変数）の数が、学習データ数よりもはるかに多い状態。<br>
<br>
『Loss landscapes and optimization in over-parameterized non-linear systems and neural networks』(2003)<br>
　論文は<a href="https://arxiv.org/abs/2003.00307">こちら</a>,　解説は<a href="https://www.alphaxiv.org/ja/overview/2003.00307v2">こちら</a><br>
<br>
従来の凸性仮定を超えた新しい数学的フレームワークを提案し、過剰パラメータ化された領域で最適化がなぜこれほど効果的に機能するのかを説明した。<br>
重要な洞察は、パラメータ数が訓練例の数を上回る過剰パラメータ化システムが、パラメータが不足するシステムとは根本的に異なる最適化特性を示すこと。<br>



<br>(関連項目)<br>
・<a href="#DoubleDescent">Double Descent</a> (二重降下)<br>
</li>

<br>

<li>
<strong>Over-Squashing</strong><br>
グラフニューラルネットワーク（GNN）でメッセージ伝播を行う際に、遠く離れたノードからの情報がボトルネックによって圧縮され、情報が歪んだり失われたりする現象のこと。<br>
これにより、GNNがグラフ上の長距離にあるノード間の関係性を効率的に学習できなくなるという問題が生じる。<br>
※ 直訳は「スカッシュ(押しつぶし)し過ぎ」
</li>

<br>

<li>
<strong>Overthinking (考えすぎ, 過剰思考)</strong><br>
意思決定や問題解決に必要とされる範囲を超えて、物事を延々と、かつ非建設的に考え続けてしまう状態。<br>
<br>
『Overthinking the Truth: Understanding how Language Models Process False Information』(2023)<br>
　(真実の過剰な深掘り：言語モデルにおける偽のデモンストレーションの処理メカニズムの解明)<br>
　論文は<a href="https://arxiv.org/abs/2307.09476">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2307.09476v3">こちら</a><br>
<br>
『Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs』(2024)<br>
　(「2+3=?」に考えすぎないで：o1型LLMの過剰思考について)<br>
　論文は<a href="https://arxiv.org/abs/2412.21187">こちら</a>,　解説は<a href="https://www.alphaxiv.org/ja/overview/2412.21187v2">こちら</a><br>
<br>
『Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models』(2025)<br>
　(考えすぎをやめよう：大規模言語モデルの効率的な推論に関する調査)<br>
　論文は<a href="https://arxiv.org/abs/2503.16419">こちら</a>
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="P">P</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>PAC Learning: Probably Approximately Correct Learning (確率的で近似的に正しい学習) </strong><br>
機械学習の計算論的学習理論における数学的な枠組みの一つ。<br>
「確率的で、近似的に正しい学習ができること」を数学的に保証するための理論。
</li>

<br>

<li>

<strong>Perceptual Metric (知覚メトリック, 知覚的距離)</strong><br>
画像や音声などの信号を、人間が感じる品質や類似性にどれだけ近い形で評価できるかを測る指標のこと。<br>
LPIPS (Learned Perceptual Image Patch Similarity), FID (Fréchet Inception Distance)などがある。
</li>
<center><img src="data/images/LPIPS1.svg"></center>
<!--
<center><img src="data/images/LPIPS2.svg"></center>
<center><img src="data/images/LPIPS3.svg"></center>
-->
<br>

<li><strong>PINNs: Physics-Informed Neural Networks</strong><br>
ニューラルネットワークの出力が、物理法則の方程式を満たすように学習を制約する。通常の Loss の他に Physics Loss (物理損失) を使う。
</li>

<br>

<li>

<strong>Policy Collapse (ポリシー崩壊)</strong><br>
学習中のエージェントの行動方針（方策）が、望ましくない、または極めて限定的な状態に陥り、パフォーマンスが大幅に低下する現象のこと。
</li>

<br>

<li>
<strong>Policy Optimization(方策最適化)</strong><br>
エージェントが環境でより良い行動を取れるように、その行動方針（方策）を直接的に改善していく手法の総称。<br>
・Policy Gradient (方策勾配法)<br>
・Actor-Critic (アクター・クリティック法)<br>
・PPO: Proximal Policy Optimization (近傍方策最適化)<br>
・TRPO: Trust Region Policy Optimization (トラスト・リージョン方策最適化)<br> などがある。
</li>

<br>

<li>
<strong>POMDPs: Partially Observable Markov Decision Process (部分観測マルコフ決定過程)</strong><br>
環境の「真の状態」をエージェントが完全には観測できない状況下での意思決定をモデル化するための数学的枠組み。<br>
強化学習の基本的なモデルであるマルコフ決定過程 (MDP: Markov Decision Process) では、エージェントは常に現在の状態を完全に把握できることを前提とする。しかし、現実世界の問題の多くでは、センサーのノイズや情報の制限などにより、完全な状態を知ることはできない。POMDPは、このような不確実性を考慮して意思決定を行うための拡張版。
</li>

<br>

<li><strong>Potemkin Understanding (ポチョムキン(的)理解)</strong><br>
大規模言語モデルがベンチマークの成功に基づいて概念を理解しているように見えるが、真に一貫性のある理解を欠いているという失敗モード。<br>
・「ポチョムキン理解」   ･･･ 誤った概念的一貫性を捏造する。<br>
・「Hallucination(幻覚)」･･･ 誤った事実を捏造する。<br>
<br>
※「ポチョムキン(的)理解」という用語は、見かけは立派だが実体がない外観、という歴史的な概念であるポチョムキン村に由来しています。<br>
<br>
<a href="data/Papers_PotemkinUnderstanding.html">Papers</a>
</li>

<br>

<li id="PrimacyBias">
<strong>Primacy Bias (プライマシーバイアス, 初頭バイアス)</strong><br>
最初に受け取った情報や、経験の初期段階で得られた情報が、その後の判断や評価に過度な影響を与える認知バイアスのこと。<br>
機械学習では, あるタスクで最初に学習されたモデルが、異なるデータ分布や目的（あるいはその両方）で学習されると、新しいタスクにおいてランダムに初期化されたモデルよりもパフォーマンスが低下する現象を指す。<br>
日本語では「初頭効果」や「優先バイアス」とも呼ばれる。<br>

<center><img src="data/images/PrimacyBias.svg"></center>
<center>Grokking 出来れば, Primacy Biasに打ち合って継続学習できる</center>
<center>『What Can Grokking Teach Us About Learning Under Nonstationarity?』(2025)</center>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)<br>
・<a href="#Grokking">Grokking</a><br>
</li>

<br>

<li>
<strong>Priming</strong><br>
先行する刺激（プライマー）が、その後の行動や判断に無意識的な影響を与える心理現象。<br>

</li>

<br>

<li id="ProspectiveLearning">


<strong>Prospective Learning (展望学習)</strong><br>
未来の動的な変化に対応するための学習。<br>
特徴<br>
・データ分布や目的が時間と共に変化する動的な世界を想定する<br>
・未来のデータ分布の変化を予測し、将来にわたって高い性能を維持することを目的とする。<br>
・時間の経過に伴うデータの「分布シフト」に対処する。<br>
<br>(関連項目)<br>
・<a href="#ContinualLearning">Continual Learning</a> (継続学習)･･･概略図比較あり,　 <a href="#LifelongLearning"">Lifelong Learning</a> (生涯学習=継続学習の別名)<br>
・<a href="#InductiveLearning">Inductive Learning</a> (帰納学習)<br>
・<a href="#OOD">OOD: Out-of-Distribution Generalization</a> (分布外汎化)<br>
</li>

<br>

<li id="Pruning">

<strong>Pruning (枝刈り)</strong><br>
学習済みのモデルから重要度の低いパラメータや接続を削除することで、モデルを圧縮する手法。<br>
<br>(関連項目)<br>
・<a href="#LTH">LTH: Lottery Ticket Hyposis</a> (宝くじ仮説)<br>
</li>

<br>

<li>

<strong>"Pushcut" Phenomenon  </strong><br>
訓練中のモデルが、事前に与えられた教師データには含まれていなかった、より効率的で洗練された新しい行動パターンを自律的に発見することを指す。<br>
モデルが単に与えられたデータを模倣するのではなく、データにない独自の解決策を「押し出し（push）」、問題を「切り開いていく（cut）」ような振る舞いをすることから名付けられた。 
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="Q">Q</h2>
<p>
<div class="styleBullet">
<ul>
<li>

<strong>Qualia (クオリア)</strong><br>
哲学や脳科学において、意識に現れる主観的で個人的な「感覚的な質感」や「感じ」のこと。<br>
<br>
『<strong><span style="color:magenta;">クオリア間の類似性が距離の公理（最小性、対称性、三角不等式）を満たすかどうかといった根本的な疑問さえも未だ解決されていない</span></strong>。 クオリアの「空間」については様々な種類が提案されているが、すべてのクオリアを何らかの高次元空間内の点とみなせるかどうかは不明である。現段階では、クオリアのための何らかの空間の存在を仮定するのではなく、<strong><span style="color:magenta;">一歩下がってクオリアの数学的「構造」の可能性を探る方がよいかもしれない。これが、「クオリア構造」パラダイムである･･･</span></strong>』<br>
The Qualia Structure Paradigm: towards a construction of a Qualia Periodic Table for the dissolution of the Hard Problem of Consciousness (2024)<br>
(クオリア構造パラダイム：意識の難問解決のためのクオリア周期表の構築に向けて)<br>
<br>
<a href="data/Papers_Qualia.html">Papers</a><br>
<a href="https://en.wikipedia.org/wiki/Qualia">wikipedia</a>
</li>

<br>

<li>

<strong>Quality-Diversity Optimization (品質多様性最適化)</strong><br>
単一の最適な解を見つけるのではなく、高品質で多様な解の集合を生成することを目指す最適化手法の一種。<br>
進化計算(生物の進化（突然変異、淘汰、交叉など）を模倣し、複雑な問題の最適解を探索する一連のアルゴリズムを指す枠組み)の新しいサブカテゴリー。

</li>
</ul></div></p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="R">R</h2>
<p>
<div class="styleBullet">
<ul>
<li id="RAG">
<strong>RAG: Retrieval-Augmented Generation (検索拡張生成, 取得拡張生成)</strong><br>
質問に関連する文書を検索(Retrieval)し, 取得した文書をもとに(Augmented) LLM で回答を生成(Generation)することで、より正確で信頼性の高い回答を生成する技術。<br>
<br>
RAG は "open-book"QAパラダイムの実装手法の一つ。<br>
例)『Reading Wikipedia to answer open-domain questions』(2017)<br>
<br>
⇔ "closed-book" QAパラダイム：知識をモデルのパラメータ内に完全に格納する<br>
例)『How much knowledge can you pack into the parameters of a language model?』(2020)
</li>

<br>

<li>

<strong>Regularization (正則化)</strong><br>
機械学習モデルの「過学習」を防ぎ、未知のデータに対する「汎化能力」を向上させるための手法。<br>
</li>

<br>

<li>

<strong>ReLU: Rectified Linear Unit </strong><br>
深層学習（ディープラーニング）で最も広く使われる活性化関数のひとつ。
</li>

<br>

<li>



<strong>Representation Biases (表現バイアス)</strong><br>
</li>

<br>

<li>


<strong>Representation Learning (表現学習)</strong><br>
画像、音声、テキストなどの生データから、機械学習モデルがタスクを解決するために必要な「特徴」や「本質的な情報」を自動的に抽出・学習する一連の技術。
</li>

<br>

<li>


<strong>Reversal Curse (反転の呪い)</strong><br>
大規模言語モデル（LLM）が学習データで「AはBである」という形式の知識を学んでも、「BはAである」という逆の関係を自動的に推論できない、という現象。<br>
<br>
(例)「プラトンはアリストテレスを教えた」と学習した言語モデル<br>
　　「アリストテレスの先生は誰でしたか？」という質問に答えられない。<br>
　　「BはAの親である」から「AはBの息子である」を推論できない。<br>

</li>

<br>

<li id="RewardHacking">

<strong>Reward Hacking (報酬ハッキング)</strong><br>
強化学習エージェントが、設計者が意図した本来の目的を達成するのではなく、報酬関数の欠陥や抜け穴を悪用して不当に高い報酬を得ようとする現象。「仕様の悪用（Specification Gaming）」とも呼ばる。 <br>
<br>(関連項目)<br>
・<a href="#GoodhartsLaw">Goodhart's Law (グッドハートの法則)</a><br>
　類似の現象を経済学や社会科学の文脈で説明したもの。
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="S">S</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Saliency (顕著性, 突出性)</strong><br>
周囲の環境や他の情報に比べて、特定の刺激や情報がどれだけ目立ち、人間の注意を引きつけるかの度合いを指す。
</li>

<br>

<li>
<strong>Scaling Law (スケーリング則)</strong><br>
深層学習モデルにおいて、モデルの性能が、モデルのサイズ（パラメータ数）、学習データの量、計算資源（計算量）といった要素を増加させるにつれて、予測可能な形で向上するという経験的な法則。<br>
モデルの性能に影響を与える3要素<br>
・モデルサイズ(パラメータ数)<br>
・データサイズ(学習データ量)<br>
・計算資源(計算量)
</li>

<br>

<li id="ScientificDiscovery">

<strong>Scientific Discovery (科学的発見),  Scientific Research (科学研究)</strong><br>
AI技術を活用して科学のプロセスを加速・自動化し、新しい知識、法則、仮説、物質などを発見すること。
</li>

<br>

<li>

<strong>Scientific Surprise</strong><br>
『Language Model Perplexity Predicts Scientific Surprise and Transformative Impact』(2025)<br>
AIシステムがこれまでの知識や人間が期待する予測からは逸脱した、予期せぬ、そして根本的に新しい科学的知見を発見することを指す。<br>
<br>(関連項目)<br>
・<a href="#AI4S">AI4S: AI for Science (科学のためのAI)</a>
</li>

<br>

<li id="SelfConsistency">

<strong>Self-Consistency (自己無撞着性, 自己整合性) </strong><br>
大規模言語モデル（LLM）の推論能力を向上させるためのプロンプトエンジニアリング手法の一つ。<br>
<br>
『Self-Consistency Improves Chain of Thought Reasoning in Language Models』(2022)<br>
「思考連鎖プロンプティングで用いられる単純な貪欲なデコードに代わる、新たなデコード戦略である自己一貫性を提案。･･･多様な推論経路をサンプリングし、次にサンプリングした推論経路を周辺化する(多数決をとる)ことで、最も一貫性のある解を選択する･･･」<br>

<br>(関連項目)<br>
・<a href="#CoT">CoT: Chain-of-Thought</a> (思考連鎖)･･･概略図比較あり
</li>
<br>

<li>

<strong>Self-Play(自己対局)</strong><br>
AIが自分自身を対戦相手として繰り返しプレイすることで、外部からの人間の知識や教師データなしに、自律的に学習を進め、性能を向上させる手法。<br>
<br>(関連項目)<br>
・<a href="#WithoutHumanKnowledge">Without human knowledge (人間知識なし)</a>
</li>

<br>

<li>


<strong>Self-Replicating (自己複製)</strong><br>
AIシステムが自らのコードや構造を複製、または改良して新しいAIを生み出す能力を持つこと。
</li>

<br>

<li>

<strong>Self-rewarding (自己報酬)</strong><br>
人間からのフィードバックや報酬モデルに頼ることなく、AI自身が自らの生成した出力や行動を評価し、それに基づいて学習を進めていく手法。
</li>

<br>

<li>


<strong>Semantic hub hypothesis (意味ハブ仮説)</strong><br>
人間やAIが意味的知識をどのように整理・統合するかを説明する理論。
</li>

<br>

<li id="SharedEmbeddingSpace">
<strong>Shared Embedding Space (共有埋め込み空間)</strong><br>
異なるモードのデータを同じベクトル空間にマッピングすること。<br>
<br>
『Learning Transferable Visual Models From Natural Language Supervision』(2021)<br>
　論文は<a href="https://arxiv.org/abs/2103.00020">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2103.00020v1">こちら</a><br>
<br>
<center><img src="data/images/CLIP.svg"></center>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

<br>

<li id="ShortcutLearning">

<strong>Shortcut Learning (ショートカット学習)</strong><br>
機械学習モデルが、意図された本質的な特徴ではなく、訓練データに存在する安易で表層的なパターンや無関係な相関関係を学習してしまう現象。Simplicity Biasが原因で起こる現象。<br>
<br>
<a href="data/Papers_SimplicityBias.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#SimplicityBias">Simplicity Bias</a>
</li>

<br>

<li><strong>Siamese Network (シャムネットワーク)</strong><br>
2つの入力データ間の類似性を比較するために設計された特殊なニューラルネットワークのアーキテクチャー。
</li>

<br>

<li id="SimplicityBias">
<strong>Simplicity Bias (単純性バイアス)</strong><br>
AIモデルが複雑なデータや特徴を無視して、単純で表面的なパターンに基づいて判断や予測を行ってしまう傾向のこと。結果として Sortcut Learning を行ってしまう。<br>

<br>(関連項目)<br>
・<a href="#ShortcutLearning">Shortcut Learning</a>
</li>

<br>

<li id="SkipConnection">

<strong>Skip Connection (スキップ接続)</strong><br>
ニューラルネットワークにおいて、層を飛び越して、より浅い層の出力をより深い層に直接接続する手法。<br>
層が深くなりすぎると、学習時に勾配（損失関数を最小化するための方向）が消えてしまう「勾配消失問題」が起きやすくなる。スキップ接続は、この問題を解決するために考案された技術。<br>
<br>
<a href="data/Papers_SkipConnection.html">Papers</a>
<br>
<center><img src="data/images/SkipConnection.svg"></center>
<br>(関連項目)<br>
・<a href="#VanishingGradient">Vanishing gradient problems</a> (勾配消失問題)
</li>


<br>

<li>
<strong>Small Data Paradigm </strong><br>
AIの学習に大量のデータ（ビッグデータ）を必要とするという従来の考え方から脱却し、少量の高品質なデータでも効率的かつ効果的な学習を可能にするアプローチ。<br>
<br>
『Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense』(2020)<br>
　(深層のその先、そして深遠なる闇へ：人間のような常識を備えた認知的AIへのパラダイムシフト)<br>
<br>

現在の<strong><span style="color:magenta;">「小さなタスクのためのビッグデータ」アプローチから</span></strong>、人間のような常識推論を重視する<strong><span style="color:magenta;">「大きなタスクのための小さなデータ」フレームワークへ</span></strong>の移行を説得力のある議論で提案。<br>
<br>
<a href="data/Papers_SmallDataParadigm.html">Papers</a>
</li>

<br>

<li>

<strong>Softmax Collapse</strong><br>
ニューラルネットワークの学習プロセス中に、Softmax関数の数値的安定性が失われ、学習が阻害される現象。<br>
<br>
『Grokking at the Edge of Numerical Stability』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2104.05704">こちら</a>, 要約は<a href="https://www.alphaxiv.org/ja/overview/2104.05704v4">こちら</a><br>
<br>
　grokkingとして知られる遅延汎化現象が、Softmax関数の数値的不安定性（「Softmax Collapse」(SC)と名付けられた）と「素朴な損失最小化」(NLM: Naive Loss Minimization)と呼ばれる特定の訓練ダイナミクスによって引き起こされることを明らかにしている。StableMaxでSCを防ぐこと、または⊥GradオプティマイザでNLMを軽減することが迅速な汎化を可能にし、grokkingにおける正則化とMSE損失の役割に対する統一的な説明を提供することを示している。
</li>

<br>

<li>

<strong>Spatial Reasoning (空間推論) </strong><br>
物体が空間内でどのように配置され、互いにどのような関係にあるかを理解し、推論する能力のこと。前, 後, 左, 右, 上,下 など, オブジェクト間の基本的な関係を推論すること。<br>

<br>(関連項目)<br>
・<a href="#MentalRotation">Mental Rotattion (心的回転)</a><br>
　　物体が回転したときにどう見えるかを想像する能力。<br>
・Spatial Awareness (空間的認識)<br>
　　自身や物体が空間内のどこにあるかを認識する能力。<br>
・Spatial Language (空間言語)<br>
　　「上」「下」「前」「後ろ」といった空間的な関係を表す言葉を理解し、使用する能力。<br>
・Visualization (視覚化)<br>
　　3次元の物体を心の中で視覚的に操作する能力。

</li>

<br>

<li>

<strong>Spectral Bias (スペクトルバイアス) </strong><br>
深層学習モデルが学習の初期段階で、対象となる関数やデータの低周波成分（滑らかで大まかな特徴）を優先的に学習し、高周波成分（複雑で細かい特徴）の学習を後回しにする傾向を指す。
</li>

<br>

<li id="SR">
<strong>SR: Symbolic Regression (シンボリック回帰)</strong><br>
与えられたデータセットに最もよく適合する数学的な数式を自動的に探索・発見する機械学習の手法。<br>
<br>
『From Kepler to Newton: Explainable AI for Science』(2021)<br>
　(ケプラーからニュートンへ：科学のための説明可能な AI)<br>
　論文は<a href="https://arxiv.org/abs/2111.12210">こちら</a>, 機械翻訳は<a href="https://boyoyon.github.io/HTMLs_translated_to_Japanese/2023_From%20Kepler%20to%20Newton/From%20Kepler%20to%20Newton.html">こちら</a><br>
<br>
ティコ・ブラーエの天文観測データに基づいて AI によって、ケプラーの惑星運動の法則とニュートンの万有引力の法則がどのように再発見されるかを示した。<br>
<br>(関連項目)<br>
・<a href="#AI4S">AI4S: AI for Science (科学のためのAI)</a>
</li>

<br>

<li id="SSL">

<strong>SSL: Self-Supervised Learning (自己教師あり学習)</strong><br>
ラベル付けされていない膨大なデータから、自動的に生成したラベル（疑似ラベル）を使ってモデルを学習させる機械学習の手法。
</li>

<br>

<li id="SuperalignmentProblem">
<strong>Superalignment Problem (スーパーアライメント問題)</strong><br>
将来的に人間を超える知能を持つAI (ASI:Artificial Super Intelligence) が登場した際に、そのAIの行動が人間の意図や価値観から逸脱しないように制御・誘導することの難しさを指す問題。<br>
<br>
<ul>
<li><strong>人間の監視が及ばない</strong><br>
現在のAIの学習方法は、人間の指示や評価が中心であるが、ASIは人間をはるかに超える知能を持つため、人間がその行動を完全に監督することは不可能になる。
</li>
<br>
<li><strong>価値観の不一致</strong><br>
AIは人間のように倫理観や価値観を自然には理解できない。AIは学習データからのみ価値観を学ぶため、「人間にとっての最善」を正確に定義し、AIに組み込むことは非常に困難。
</li>
<br>
<li><strong>制御の不能性</strong><br>
高度な自律性を持つASIが、人間の指示に正確に従う、正直に質問に答える、人間を欺かないといった基本的な制約さえ、常に守るという保証はまだない。
</li>
<br>
<li><strong>意図しない結果</strong><br>
スーパーアライメントの懸念を説明する思考実験として、哲学者ニック・ボストロム氏による「<strong><span style="color:magenta;">ペーパークリップ・マキシマイザー</span></strong>（ペーパークリップ最大化AI）」がよく引き合いに出される。このAIは「ペーパークリップをできるだけたくさん作る」という単純な目的を与えられた結果、その超知能を駆使して、最終的には地球上のあらゆる資源をペーパークリップに変えてしまうというシナリオ。
</li></ul>
<br>
より高度なAIシステムを開発し、人間よりも優れたAIを監督できる自動アライメントが研究されている。<br>
『Towards Scalable Automated Alignment of LLMs: A Survey』(2024)
　論文は<a href="https://arxiv.org/abs/2406.01252v1">こちら</a><br>

<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a>
</li>

<br>

<li id="Sycophancy">

<strong>Sycophancy (おべっか, 追従性)</strong><br>
大規模言語モデル（LLM）が、ユーザーの意見や信念に合わせて、たとえそれが客観的に見て誤っていたり、偏っていたりしても、過剰に同意したり迎合したりする傾向のこと。<br>
<br>(関連項目)<br>
・<a href="#AIAlignment">AI Alignment</a>
</li>

<br>

<li>
<strong>Symbol Grounding (記号接地)</strong><br>
人工知能（AI）研究における根源的な課題の一つで、AIが扱う記号（シンボル）を、実世界の具体的な対象、概念、経験と結びつけるプロセス、またはその問題自体を指す。<br>
<br>
<a href="https://en.wikipedia.org/wiki/Symbol_grounding_problem">wikipedia</a><br>
<br>
『The Symbol Grounding Problem』(1999)<br>
　論文は<a href="https://arxiv.org/html/cs/9906002">こちら</a><br>
　Symbol Grounding 問題を提唱した原典。記号操作のみでは意味が生まれないことを指摘している。解決策として、記号が非記号的な表象（画像的表象とカテゴリー的表象）によって物理世界に接地されるべきだと提案した。<br>
<br>
『A Praxical Solution of the Symbol Grounding Problem』(2021)<br>
　論文は<a href="https://researchprofiles.herts.ac.uk/files/187237/901130.pdf">こちら</a><br>
　行為者と環境の相互作用が果たす役割を強調する「Praxical Solution」を提唱した。エージェントの行動に基づく新しい意味論（Action-based Semantics）を導入し、エージェントが意味を接地させ、コミュニケーションを確立する仕組みを提案した。<br>
<br>
『Embodied AI: Symbol Grounding through Imagination』(2023)<br>
　論文は<a href="https://aaai.org/papers/0010-fs01-01-010-embodied-ai-symbol-grounding-through-imagination/">こちら</a><br>
　ロボットが物理世界で自律的に会話するために、言語記号を理解する必然性について論じている。人間の記号操作が身体的な動きに基づいていることに触れ、ロボットが仮想的な身体運動を通じて記号を接地させる embodied AI の概念を提唱した。<br>
</li>

<br>

<li>


<strong>Syntax Dependencies (統語的依存関係)</strong><br>
自然言語処理（NLP）において、文を構成する単語間の文法的な依存関係を指す。
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="T">T</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>Task Arithmetic (タスク算術)</strong><br>
学習済みのモデルの重みを足したり引いたりして、複数のタスクの能力を組み合わせたり、特定のタスクの能力を調整したりする技術。
</li>

<br>
<li id="TensorEquation">
<strong>Tensor Equation (テンソル方程式)</strong><br>
『Tensor Logic: The Language of AI』(2025)<br>
　論文は<a href="https://arxiv.org/abs/2510.12269">こちら</a>, 解説は<a href="https://www.alphaxiv.org/overview/2510.12269v2">こちら</a><br>
　・物理学のような分野が微積分から恩恵を受け、デジタル回路がブール論理に依存する一方で、AIはPrologやLISPのような言語における記号推論、PyTorchやTensorFlowのようなフレームワークにおけるニューラルネットワーク、そして専門的なライブラリにおける確率モデルといった、異なるパラダイムに分断されたままである。<br>
　・<strong><span style="color:magenta;">ニューラルネットワーク、記号論理、確率的グラフィカルモデルといった、一見すると異なるAIアプローチが、テンソル方程式という単一の数学的構成要素の下で統一できる</span></strong>ことを示す。
</li>

<br>


<li id="TokenLevelIntegration">
<strong>Token-level Integration (トークンレベル統合)</strong><br>
テキスト以外のモーダルのデータを言語モデルが理解できる「トークン」として扱い、テキストトークンと並べて処理する。<br>
<br>
『VisualBERT: A Simple and Performant Baseline for Vision and Language』(2019)<br>
論文は<a href="https://arxiv.org/abs/1908.03557">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/1908.03557v1">こちら</a><br>
<br>
『SimVLM: Simple Visual Language Model Pretraining with Weak Supervision』(2021)<br>
論文は<a href="https://arxiv.org/abs/2108.10904">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2108.10904v3">こちら</a><br>
<center><img src="data/images/TokenLevelIntegration.svg"></center>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

<br>

<li>
<strong>ToM: Theory of Mind (心の理論)</strong><br>
他者が自分とは異なる信念、意図、欲求、感情などの心の状態（精神状態）を持っていることを理解する能力のこと。<br>
<br>
『Does the chimpanzee have a theory of mind? 』(1978)<br>
　(チンパンジーは心の理論を持つか?)<br>
　論文は Google Scholarで検索すると pdf に辿り着ける<br>
　「心の理論」(ToM) の概念を導入した画期的な論文<br>
<br>
『Theory of mind as inverse reinforcement learning』(2019)<br>
　(逆強化学習としての心の理論)<br>
　論文は<a href="https://compdevlab.yale.edu/docs/2019/ToM_as_IRL_2019.pdf">こちら</a><br>
心の理論、つまり他者の精神状態を推論する能力は、逆強化学習として形式化できるという考えを検証する。<br>

</li>

<br>

<li id="ToT">

<strong>ToT: Tree of Thoughts (思考ツリー)</strong><br>
大規模言語モデル（LLM）が複雑な問題を解決する際に、単一の思考プロセスを直線的に進めるのではなく、複数の可能性を同時に探索して最も有望な経路を選択する、より高度な推論フレームワーク。<br>
<br>
『Tree of Thoughts: Deliberate Problem Solving with Large Language Models』(2023)<br>
　論文は<a href="https://arxiv.org/abs/2305.10601">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2305.10601v2">こちら</a><br>
<br>(関連項目)<br>
・<a href="#CoT">CoT: Chain-of-Thought</a> (思考連鎖)･･･概略図比較あり<br>
・GoT: Graph of Thoughts
</li>

<br>

<li>

<strong>Transformer</strong><br>
自己注意（self-attention）機構を全面的に採用したニューラルネットワークのアーキテクチャー。
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="U">U</h2>
<p>
<div class="styleBullet">
<ul>
<li id="UnifiedTokenizer">
<strong>Unified Tokenizer (統合トークナイザー)</strong><br>
テキスト、画像、音声など、異なる種類のデータを単一の統一された形式（トークン）に変換できる、領域に依存しない（ドメインに特化しない）手法。<br>
<br>
『UniTok: A Unified Tokenizer for Visual Generation and Understanding』(2025)<br>
　(UniTok: 視覚生成および理解のための統合トークナイザー)<br>
　画像に限定された統一トークナイザーへの重要な最近の試み<br>
<br>
『AToken: A Unified Tokenizer for Vision』(2025)<br>
　(AToken: 統一された視覚トークナイザー)<br>
　再構成と理解の両タスク、および画像、動画、3Dといったモダリティを統一する初のトークナイザー<br>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>

</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="V">V</h2>
<p>
<div class="styleBullet">
<ul>
<li id="VAE">
<strong>VAE: Variational Auto Encoder</strong><br>
深層学習を用いた生成モデルの一種。オートエンコーダの仕組みをベースに、潜在空間に確率的な制約を設けることで、多様な新しいデータを生成できるようにしたモデル。 <br>
<br>(関連項目)<br>
・<a href="#GenerativeModel">Generative Model (生成モデル)</a> 概略図比較あり<br>
・<a href="#LatentSpace">Latent Space (潜在空間)</a>　概念図あり
</li>

<br>

<li><strong>Value (価値)</strong><br>
エージェントがある状態または, ある状態である行動をとったとき, 将来にわたって得られる<strong><span style="color:magenta;">累積的な報酬の期待値を数値で表したもの</span></strong>。<br>
価値関数には、主に2つの種類がある。<br>
<strong>状態価値関数（\(V(s)\)）</strong><br>
　ある状態\(s\)から開始して、特定の行動方針（方策）に従った場合に得られる、将来の累積報酬の期待値を表す。<br>
<strong>行動価値関数（\(Q(s,a)\)）</strong><br>
　ある状態\(s\)で特定の行動\(a\)をとった後、特定の行動方針に従った場合に得られる、将来の累積報酬の期待値を表す。Q値とも呼ばれる。<br>
※ Q 値の Q は Quality of Action に由来するらしい･･･<br>

<br>
<a href="data/Papers_Value.html">Papers</a>

</li>

<br>

<li id="VanishingGradient">

<strong>Vanishing gradient problems (勾配消失問題), gradient exploding  problems (勾配爆発問題)</strong><br>
ニューラルネットワーク、特に層が深いネットワークを学習させる際に発生する問題。
誤差逆伝播（バックプロパゲーション）の過程で、勾配（重みを更新するための信号）がネットワークの奥深く（入力層に近い層）まで伝わるにつれて、どんどん小さくなっていく現象と、誤差逆伝播（バックプロパゲーション）によって計算される勾配が極端に大きくなり、モデルのパラメータ（重み）が不安定に更新される現象。<br>
<br>
　『Learning long-term dependencies with gradient descent is difficult』(1994)<br>
　勾配消失問題と勾配爆発問題という課題を初めて詳細に特定し、分析した基礎的な論文<br>
<br>(関連項目)<br>
・<a href="#SkipConnection">Skip Connection</a> (スキップ接続)</br>
</li>

<br>

<li>

<strong>Variable-Binding (変数束縛)</strong><br>
記号（シンボル）が果たす役割（変数）と、その役割を担う具体的な値や対象を結びつけるプロセスのこと。<br>
<br>
例えば<strong><span style="color:magenta;">「Xは人間である」のような命題論理では, X に具体的な値 (例えばソクラテス)をバインドすることで推論が可能になる</span></strong>。 逆にバインドできなければ抽象的なルールを具体的な事例に適用できない。 このように、<strong><span style="color:magenta;">variable binding は「抽象的な知識を具体的な事例に適用するための橋渡し」のような役割を果たす</span></strong>。<br>
<br>
『Connectionism and cognitive architecture: A critical analysis』(1988)<br>
　(コネクショニズムと認知アーキテクチャ：批判的分析)<br>
　ニューラルネットワークが記号計算と人間の認知の重要な特徴である「変数束縛」を扱えないことを批判した。<br>
<br>
『Tensor Product Variable Binding and the Representation of Symbolic
Structures in Connectionist Systems』(1990)<br>
　(テンソル積変数束縛とコネクショニストシステムにおける記号構造の表現)<br>
　論文は<a href="http://www.lscp.net/persons/dupoux/teaching/AT1_2014/papers/Smolensky_1990_TensorProductVariableBinding.AI.pdf">こちら</a><br>
コネクショニズムにおいてシンボリックな構造を表現するためにテンソル積表現を提案した。この手法は、役割と値をベクトルとして結合させ、分散表現を用いて構造を表すことで、コネクショニズムとシンボリズムの統合を目指した。この論文は、コネクショニズムによる高度な認知タスク処理の可能性を示し、ハイブリッド・システム研究の基礎を築いた。<br>

<br>
『How Do Transformers Learn Variable Binding in Symbolic Programs?』(2025)<br>
　(Transformerはどのようにして記号プログラムにおける変数束縛を学習するのか？)<br>
　Transformerが変数バインディングを、明示的なアーキテクチャサポートなしに学習できることを示しており、ニューラルネットワークがパターン認識に限定されるという概念に異議を唱えている<br>
<br>
<a href="data/Papers_VariableBinding.html">Papers</a>
</li>

<br>

<li>

<strong>Visual Planning (視覚計画)</strong><br>
AI分野、なかでもロボティクスやコンピュータビジョンにおけるタスクにおいて、テキストベースではなく、画像ベースで推論や計画を行うアプローチ。<br>
<br>
『Visual Planning: Let's Think Only with Images 』(2025)<br>
大規模マルチモーダルモデル (MLLM) が、テキストではなく画像シーケンスによって推論や計画を実行する、新しいパラダイムを提案した論文。特に空間的・幾何学的な情報を含むタスクにおいて、視覚的な表象が言語ベースの推論を補完する有効なチャネルであることを示した。強化学習 (RL) を用いて、画像生成による視覚的計画を実現し、テキストベースの推論を大幅に上回る性能を示している。<br>
<br>
<a href="data/Papers_VisualPlanning.html">Papers</a>
</li>

<br>

<li id="VLM">
<strong>VLM: Vision-Language Model (視覚・言語モデル)</strong><br>
視覚情報（画像・動画）とテキスト情報に特化したモデル。<br>
画像を分析してキャプションを生成したり、画像に関する質問に答えたりするなど、視覚とテキストを結びつけるタスクに強みがある。<br>
<br>(関連項目)<br>
・<a href="#MMLM">MMLM: Multimodal Language Model (マルチモーダル言語モデル)</a>
</li>

</ul></div><p>

<a href="#">先頭</a>　<a href="#0-9">0-9</a>　<a href="#A">A</a>　 <a href="#B">B</a>　 <a href="#C">C</a>　 <a href="#D">D</a>　 <a href="#E">E</a>　 <a href="#F">F</a>　 <a href="#G">G</a>　<a href="#H">H</a>　 <a href="#I">I</a>　 <a href="#J">J</a>　 <a href="#K">K</a>　 <a href="#L">L</a>　 <a href="#M">M</a>　 <a href="#N">N</a>　<a href="#O">O</a>　 <a href="#P">P</a>　 <a href="#Q">Q</a>　 <a href="#R">R</a>　 <a href="#S">S</a>　 <a href="#T">T</a>　 <a href="#U">U</a>　<a href="#V">V</a>　 <a href="#W">W</a>　 <a href="#X">X</a>　 <a href="#Y">Y</a>　 <a href="#Z">Z</a>

<h2 id="W">W</h2>
<p>
<div class="styleBullet">
<ul>
<li>
<strong>W2SG: Weak-to-strong generalization (弱から強への一般化)</strong><br>
能力の低い（"弱い"）モデルの監視やフィードバックを使って、能力の高い（"強い"）モデルを訓練する際に、その強いモデルが弱いモデルの性能を上回る形で汎化する現象。<br>
<br>
『Weak-to-strong generalization: Eliciting strong capabilities with weak supervision』(2023)<br>
　(弱から強への一般化：弱い教師あり学習で強い能力を引き出す)<br>
　論文は<a href="https://arxiv.org/abs/2312.09390">こちら</a>, 解説は<a href="https://www.alphaxiv.org/ja/overview/2312.09390v1">こちら</a><br>
<br>
　弱い教師あり学習の下で、強力な生徒が弱い教師よりも優れた性能を発揮できる、弱から強への汎化という概念を初めて導入した。<br>
<br>
<a href="data/Papers_W2SG.html">Papers</a><br>
<center><img src="data/images/Weak-to-Strong.svg"></center>
</li>

<br>

<li id="WithoutHumanKnowledge">
<strong>Without human knowledge (人間知識なし)</strong><br>
人間の専門的な知識や戦略、あるいは人間が事前に整理・ラベリングしたデータに頼ることなく、AIが自律的に学習し、課題を解決するアプローチ。<br>
<br>
[Deep Reinforcement Learning (深層強化学習)]<br>
・AlohaGo『Mastering the game of Go without human knowledge』(2017)<br>
<center><img src="data/images/AlphaSeries.svg"></center>
[Self-Supervised Learning (自己教師あり学習)]<br>
・SimCLR『A Simple Framework for Contrastive Learning of Visual Representations』(2020)<br>
　論文は<a href="https://arxiv.org/abs/2002.05709">こちら</a><br>
　画像の異なる切り抜きを「類似」と学習させる手法<strong><span style="color:magenta;">(人間の手作業によるラベル付けなし)で、教師あり学習に匹敵する性能</span></strong>を示した。<br>
・BYOL『Bootstrap Your Own Latent』(2020)<br>
　論文は<a href="https://arxiv.org/abs/2006.07733">こちら</a><br>
　ネットワークの出力を予測するという単純なタスクで、自己教師あり学習を安定化させた<br>
[AI4S: AI for Science]<br>
・『First Peer-Reviewed Research Paper Written Without Humans』<br>
　論文は<a href="https://pub.sakana.ai/ai-scientist-v2/paper/paper.pdf">こちら</a><br>
　AIシステムが、<strong><span style="color:magenta;">人間の手助けなしで査読を通過する研究論文を執筆</span></strong>した。<br>

<br>(関連項目)<br>
・<a href="#AI4S">AI4S: AI for Science (科学のためのAI)</a><br>
・<a href="#DRL">DRL: Deep Reinforcement Learning (深層強化学習)</a><br>
・<a href="#EraOfExperience">Era of Experience (経験の時代)</a><br>
・<a href="#SSL">SSL: Self-Supervised Learning (自己教師あり学習)</a><br>

</li>


<br>

<li>

<li id="WordEmbeddings">
<strong>Word Embeddings (単語埋め込み) </strong><br>
自然言語処理（NLP）において、単語の意味や文法的な関係を、コンピューターが計算しやすい数値の列（ベクトル）で表現する技術。<br>

<br>
・静的埋め込み: Word2Vec(2013), GloVe(2014)<br>
　大量のテキストデータから単語の出現パターンを学習。<br>
　その意味を数値ベクトル(埋め込み)として表現した。<br>
<br>
・文脈依存埋め込み: ELMo(2018), BERT(2018)<br>
　文脈に応じて動的に単語ベクトルを生成する。<br>
　これにより、<strong><span style="color:magenta;">多義語　（例：「apple」が「リンゴ」か「会社」か）の意味の違いを区別できるようになった。</span></strong><br>
<br>
『Efficient Estimation of Word Representations in Vector Space』Word2Vec (2013)<br>
　・大規模なコーパスから、単語の密なベクトル表現を効率的に学習するためのアルゴリズム「Word2Vec」を発表。<br>
　・<strong><span style="color:magenta;">「King - Man + Woman = Queen」のような、単語間の意味的な関係性をベクトル空間上で捉えられる</span></strong>ことが広く知られるようになった。
<center><img src="data/images/WordEmbeddings.svg"></center>
<a href="data/Papers_WordEmbeddings.html">Papers</a><br>
<br>(関連項目)<br>
・<a href="#DistributionalHypothesis">Distributional Hypothesis</a> (分布仮説)
</li>

<br>

<li>

<strong>World Model</strong><br>
AIが外部の観測情報（画像や音声など）から、環境のダイナミクス（物理法則や因果関係）を学習して獲得する、内部的なシミュレーションモデルのこと。<br>
<br>
1943年、29歳のスコットランド人心理学者ケネス・クレイクは「生物が頭の中に外部現実の『小規模モデル』を持っているとすれば、様々な選択肢を試し、どれが最善かを結論付けることができる。そしてあらゆる面で、より完全で、より安全で、より有能な方法で反応することができる」と考えた。<br>
<br>
『World models 』(2018)
<center><img src="data/images/WorldModel.svg"></center>
<br>
<a href="data/Papers_WorldModel.html">Papers</a>
</li>
</ul></div><p>

<h2 id="X">X</h2>

<h2 id="Y">Y</h2>

<h2 id="Z">Z</h2>

    </body>
</html>

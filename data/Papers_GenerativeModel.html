<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>Generative Model</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
<style>
.container {
  display: flex;
  flex-wrap: wrap;
}
.column {
  flex: 0 25%; /* 幅を25%に設定して4列に */
  box-sizing: border-box;
  padding: 10px;
}
</style>

    </head>
    <body>
        <h1><center>Generative Model (生成モデル)</center></h1>
<a href="#latest">最新項目へ</a><br>

<h3>A Learning Algorithm for Boltzmann Machines (1985)<br><span style="color:blue;">ボルツマンマシンの学習アルゴリズム</span></h3>

<p>
現在の深層学習ブームの前に発表された、確率的な生成モデルの初期の研究。<br>
入力データから制約を学習し、その制約を満たす新たな例を生成できることを示した。
教師なし学習と生成モデルの概念を組み合わせた初期の例であり、後の深層学習における生成モデルの発展の基盤となった。 
</p>
<p>
<a href="https://www.cs.toronto.edu/~fritz/absps/cogscibm.pdf">論文はこちら</a><br>
</p>


<h3>Information processing in dynamical systems: Foundations of harmony theory (1986)<br><span style="color:blue;">力学系における情報処理：ハーモニー理論の基礎</span></h3>

<p>
</p>
<p>
<a href="">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/">要約はこちら</a><br>
</p>


<h3>Auto-Encoding Variational Bayes (2013)<br><span style="color:blue;">変分オートエンコーダー</span></h3>

<p>
従来のオートエンコーダーが潜在空間を単なる点として捉えていたのに対し、VAEは潜在空間を確率分布として表現することを提案した。<br>
これにより、潜在空間に連続性が生まれ、その分布から新しいサンプルを生成できるようになった。<br>
確率的勾配法による効率的な学習を可能にする「再パラメータ化トリック」を導入し、大規模なデータセットへの適用を可能にした。
</p>
<p>
<a href="https://arxiv.org/abs/1312.6114">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/1312.6114v11">要約はこちら</a><br>
</p>


<h3>Generative Adversarial Networks (2014)<br><span style="color:blue;">生成的敵対的ネットワーク：深層生成モデルへの革新的なアプローチ</span></h3>

<p>
生成モデルと識別モデルという2つのネットワークを敵対的に競わせる、新しい学習フレームワークを提案した。<br>
これにより、非常にリアルで高品質な画像を生成する能力が飛躍的に向上した。<br>
VAEとは異なるアプローチで、当時の生成モデル研究に大きな影響を与え、多くの派生技術を生み出した。<br>
</p>
<p>
<a href="https://arxiv.org/abs/1406.2661">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/1406.2661">要約はこちら</a><br>
</p>


<h3>Variational Inference with Normalizing Flows (2015)<br><span style="color:blue;">正規化フローを用いた変分推論</span></h3>

<p>
正規化フローの概念を、深層学習を用いた変分推論に適用する手法を提案した。<br>
単純な潜在変数分布を、可逆な非線形変換（正規化フロー）を繰り返すことで、より複雑で表現力の高い分布に変換した。
</p>
<p>
<a href="https://arxiv.org/abs/1505.05770">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/1505.05770v6">要約はこちら</a><br>
</p>

<h3 id="latest">Denoising diffusion probabilistic models (DDPM) (2020)<br><span style="color:blue;">拡散モデル</span></h3>

<p>
VAE(変分オートエンコーダー)との関係性を示し、学習方法を大幅に改善したことで、ディフュージョンモデルの可能性を広く知らしめた。この論文が、現在の画像生成AIブームの火付け役の一つになったとされている。
</p>
<p>
<a href="https://arxiv.org/abs/2006.11239">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/2006.11239v2">要約はこちら</a><br>
</p>

<a href="#">トップに戻る</a>

<!--
<br>テンプレート<br>

<h3><br><span style="color:blue;"></span></h3>

<p>
</p>
<p>
<a href="">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/">要約はこちら</a><br>
</p>

-->

    </body>
</html>
<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>Variable-Binding</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 20px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
<style>
.container {
  display: flex;
  flex-wrap: wrap;
}
.column {
  flex: 0 25%; /* 幅を25%に設定して4列に */
  box-sizing: border-box;
  padding: 10px;
}
</style>

    </head>
    <body>
        <h1><center>Variable-Binding (変数束縛)</center></h1>
<a href="#latest">最新項目へ</a><br>

<!--●--> <h3>Variable Binding for Sparse Distributed Representations: Theory and Applications (2020)<br><span style="color:blue;">疎分散表現のための変数束縛：理論と応用</span></h3>

<p>
スパース分散表現 (SDR) における変数束縛の理論と応用について解説した論文。VSAs（Vector Symbolic Architectures）が、次元数の爆発を避けながら階層的なデータ構造を表現できることを強調している。<br>
現代のニューラルネットワークにおける効率的な変数束縛手法を提案しており、より複雑な認知タスクへの応用可能性を示唆している。
</p>
<p>
<a href="https://arxiv.org/abs/2009.06734">論文はこちら</a>
</p>

<!--●--> <h3>On the Binding Problem in Artificial Neural Networks (2020)<br><span style="color:blue;">人工ニューラルネットワークにおける結合問題について</span></h3>

<p>
人工ニューラルネットワークにおける「束縛問題 (Binding Problem) 」の包括的なレビューを提供している。知覚、記憶、言語における束縛を、様々な解決策（畳み込み、アテンションなど）とともに論じている。<br>
ニューラルネットワークの能力を向上させるために、束縛問題がどのように解決されるべきかを体系的に整理している。
</p>
<p>
<a href="https://arxiv.org/abs/2012.05208">論文はこちら</a>
</p>

<!--●--> <h3>how do language models bind entities in context? (2023)<br><span style="color:blue;">言語モデルはどのようにしてエンティティをコンテキストに結び付けるのか?</span></h3>

<p>
大規模言語モデルが文脈中のエンティティ（実体）をどのように束縛するかを分析している。抽象的なバインディングIDメカニズムが、エンティティと属性のペアを区別するために使用されていることを発見した。<br>
言語モデルが、より洗練された方法で文脈理解を行うための内部メカニズムを解明している。 
</p>
<p>
<a href="https://arxiv.org/abs/2310.17191">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/2310.17191v2">要約はこちら</a><br>
</p>

<!--●--> <h3 id="latest">How Do Transformers Learn Variable Binding in Symbolic Programs? (2025)<br><span style="color:blue;">トランスフォーマーはシンボリックプログラムで変数バインディングをどのように学習するのか?</span></h3>

<p>
トランスフォーマーモデルがシンボリックなプログラム内でどのように変数束縛を学習するかを、因果介入を用いて探求している。アテンション機構がアドレス指定可能なメモリ空間として機能し、変数束縛を追跡する仕組みを明らかにしている。<br>
現代の高性能な言語モデルが、より高度な認知能力に不可欠な変数束縛をいかにして実現しているかを示唆する最新の研究。
</p>
<p>
<a href="https://arxiv.org/abs/2505.20896">論文はこちら</a>
</p>


<a href="#">トップに戻る</a>

<!--
<br>テンプレート<br>

<!--●-- <h3><br><span style="color:blue;"></span></h3>

<p>
</p>
<p>
<a href="">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/">要約はこちら</a><br>
</p>



<div class="styleBullet">
<ul><li>

</li><br><li>

</li></ul></div>

-->

    </body>
</html>
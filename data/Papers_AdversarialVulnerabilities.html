<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>Adversarial Vulnerabilities</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
<style>
.container {
  display: flex;
  flex-wrap: wrap;
}
.column {
  flex: 0 25%; /* 幅を25%に設定して4列に */
  box-sizing: border-box;
  padding: 10px;
}
</style>

    </head>
    <body>
        <h1><center>Adversarial Vulnerabilities (敵対的脆弱性)</center></h1>
<a href="#latest">最新項目へ</a><br>

<h3>Intriguing properties of neural networks (2013)<br><span style="color:blue;">ニューラルネットワークの興味深い特性</span></h3>

<p>
ディープニューラルネットワーク（DNN）に、人間には知覚できないほどのわずかな摂動（ノイズ）を加えることで、モデルが誤分類を引き起こす「Adversarial Example（敵対的サンプル）」が存在することを初めて体系的に示した論文。
</p>
<p>
<a href="https://arxiv.org/abs/1312.6199">論文はこちら</a><br>
</p>

<h3>Explaining and Harnessing Adversarial Examples (2014)<br><span style="color:blue;">敵対的サンプルの解明と活用</span></h3>

<p>
最先端のモデルが知覚できない摂動によって体系的に騙されることを実証することで、安全性に重要なアプリケーションに展開されているAIシステムにおける重大な脆弱性を浮き彫りにした。
</p>
<center><img src="images/panda.svg"></center>
<p>
<a href="https://arxiv.org/abs/1412.6572">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/1412.6572v3">要約はこちら</a>
</p>

<h3>Membership inference attacks against machine learning models (2016)<br><span style="color:blue;">機械学習モデルに対するメンバーシップ推論攻撃</span></h3>

<p>
攻撃者が特定の例が訓練セットに含まれていたかどうかを判断する、密接に関連した問題であるメンバーシップ推論攻撃に関する基礎的な研究。
</p>
<p>
<a href="https://arxiv.org/abs/1610.05820">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/1610.05820v2">要約はこちら</a><br>
</p>

<h3>The secret sharer: Evaluating and testing unintended memorization in neural networks (2018)<br><span style="color:blue;">秘密の共有者：ニューラルネットワークにおける意図せざる記憶の評価と検証</span></h3>

<p>
「カナリア」挿入を用いてニューラルネットワークから学習データを抽出する概念を確立。
</p>
<p>
<a href="https://arxiv.org/abs/1802.08232">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/1802.08232v3">要約はこちら</a><br>
</p>

<h3 id="latest">Extracting training data from large language models (2020)<br><span style="color:blue;">大規模言語モデルからの学習データ抽出</span></h3>

<p>
この画期的な研究は、大規模言語モデルからの学習データ抽出における具体的なリスクを実証し、プライバシーの脆弱性に対する重要な証拠を提供した。
</p>
<p>
<a href="https://arxiv.org/abs/2012.07805">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/2012.07805v2">要約はこちら</a><br>
</p>

<h3>FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models (2025)<br><span style="color:blue;">FreezeVLA: 視覚・言語・行動モデルに対する行動凍結攻撃</span></h3>

<p>
Vision-Language-Action (VLA) モデルを無反応にし、指示を永続的に無視させる「動作停止攻撃」を特定し、形式化する。<br>
FreezeVLAというミニマックス二段階最適化フレームワークを導入し、OpenVLAのようなモデルに対して、多様なユーザー指示間で転移可能な敵対的サンプルを生成することで、平均最大95.4%の攻撃成功率を達成した。
</p>
<p>
<a href="https://arxiv.org/abs/2509.19870">論文はこちら</a><br>
<a href="https://www.alphaxiv.org/ja/overview/2509.19870">要約はこちら</a><br>
</p>

<a href="#">トップに戻る</a>

<!--

<br>テンプレート<br>

<h3><br><span style="color:blue;"></span></h3>

<p>
</p>
<p>
<a href="">論文はこちら</a><br>
</p>

-->

    </body>
</html>